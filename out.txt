Vocabulary Size: 14319
Train/Dev split: 1600/400
Writing to /Users/amrkoura/Documents/workspace/newYorkerChallenge/runs/1484055721

(1, '2017-01-10T14:42:03.184231: step 1, loss 2.62097, acc 0.5')
(1, '2017-01-10T14:42:04.452390: step 2, loss 2.1851, acc 0.484375')
(1, '2017-01-10T14:42:05.883035: step 3, loss 1.53896, acc 0.5625')
(1, '2017-01-10T14:42:07.106768: step 4, loss 2.92447, acc 0.453125')
(1, '2017-01-10T14:42:08.345219: step 5, loss 3.07412, acc 0.390625')
(1, '2017-01-10T14:42:09.846095: step 6, loss 2.71965, acc 0.484375')
(1, '2017-01-10T14:42:11.177668: step 7, loss 2.18841, acc 0.546875')
(1, '2017-01-10T14:42:12.470117: step 8, loss 2.28189, acc 0.484375')
(1, '2017-01-10T14:42:13.824271: step 9, loss 2.50668, acc 0.515625')
(1, '2017-01-10T14:42:15.360612: step 10, loss 1.89762, acc 0.546875')
(1, '2017-01-10T14:42:16.939635: step 11, loss 2.31188, acc 0.5')
(1, '2017-01-10T14:42:18.389028: step 12, loss 2.19312, acc 0.5')
(1, '2017-01-10T14:42:19.870342: step 13, loss 2.42397, acc 0.5625')
(1, '2017-01-10T14:42:21.191534: step 14, loss 1.76999, acc 0.5625')
(1, '2017-01-10T14:42:22.533832: step 15, loss 2.84724, acc 0.546875')
(1, '2017-01-10T14:42:24.006811: step 16, loss 1.58719, acc 0.53125')
(1, '2017-01-10T14:42:25.317286: step 17, loss 2.94836, acc 0.484375')
(1, '2017-01-10T14:42:26.633380: step 18, loss 1.8362, acc 0.59375')
(1, '2017-01-10T14:42:28.037415: step 19, loss 1.76963, acc 0.59375')
(1, '2017-01-10T14:42:29.341196: step 20, loss 2.40755, acc 0.484375')
(1, '2017-01-10T14:42:30.651754: step 21, loss 2.48585, acc 0.546875')
(1, '2017-01-10T14:42:32.089160: step 22, loss 2.18237, acc 0.578125')
(1, '2017-01-10T14:42:33.407718: step 23, loss 1.9979, acc 0.578125')
(1, '2017-01-10T14:42:34.713978: step 24, loss 2.88977, acc 0.453125')
(1, '2017-01-10T14:42:36.044134: step 25, loss 2.27275, acc 0.5')
(1, '2017-01-10T14:42:37.389865: step 26, loss 2.37361, acc 0.484375')
(1, '2017-01-10T14:42:38.723091: step 27, loss 2.43764, acc 0.484375')
(1, '2017-01-10T14:42:40.028665: step 28, loss 1.82536, acc 0.640625')
(1, '2017-01-10T14:42:41.355333: step 29, loss 1.47205, acc 0.65625')
(1, '2017-01-10T14:42:42.696708: step 30, loss 1.59804, acc 0.59375')
(1, '2017-01-10T14:42:44.025078: step 31, loss 1.97982, acc 0.578125')
(1, '2017-01-10T14:42:45.406220: step 32, loss 2.03859, acc 0.578125')
(1, '2017-01-10T14:42:46.774264: step 33, loss 2.30582, acc 0.5625')
(1, '2017-01-10T14:42:48.112409: step 34, loss 1.46515, acc 0.71875')
(1, '2017-01-10T14:42:49.480838: step 35, loss 2.0132, acc 0.453125')
(1, '2017-01-10T14:42:50.918316: step 36, loss 1.8409, acc 0.5625')
(1, '2017-01-10T14:42:52.289762: step 37, loss 2.33898, acc 0.4375')
(1, '2017-01-10T14:42:53.641594: step 38, loss 1.4978, acc 0.578125')
(1, '2017-01-10T14:42:55.050521: step 39, loss 2.2367, acc 0.59375')
(1, '2017-01-10T14:42:56.375697: step 40, loss 1.78497, acc 0.546875')
(1, '2017-01-10T14:42:57.714249: step 41, loss 2.12272, acc 0.578125')
(1, '2017-01-10T14:42:59.053120: step 42, loss 1.18696, acc 0.578125')
(1, '2017-01-10T14:43:00.388966: step 43, loss 1.69241, acc 0.578125')
(1, '2017-01-10T14:43:01.835789: step 44, loss 1.68579, acc 0.5625')
(1, '2017-01-10T14:43:03.236235: step 45, loss 1.8434, acc 0.578125')
(1, '2017-01-10T14:43:04.597610: step 46, loss 1.44767, acc 0.578125')
(1, '2017-01-10T14:43:05.982389: step 47, loss 1.52256, acc 0.625')
(1, '2017-01-10T14:43:07.392108: step 48, loss 2.09317, acc 0.484375')
(1, '2017-01-10T14:43:08.739167: step 49, loss 2.02215, acc 0.53125')
(1, '2017-01-10T14:43:10.074846: step 50, loss 1.69337, acc 0.625')
(1, '2017-01-10T14:43:11.404043: step 51, loss 1.24912, acc 0.6875')
(1, '2017-01-10T14:43:12.756393: step 52, loss 2.23765, acc 0.5625')
(1, '2017-01-10T14:43:14.081939: step 53, loss 1.24364, acc 0.625')
(1, '2017-01-10T14:43:15.659410: step 54, loss 1.42192, acc 0.578125')
(1, '2017-01-10T14:43:17.076980: step 55, loss 1.19637, acc 0.734375')
(1, '2017-01-10T14:43:18.451138: step 56, loss 1.80786, acc 0.515625')
(1, '2017-01-10T14:43:19.860396: step 57, loss 1.17265, acc 0.609375')
(1, '2017-01-10T14:43:21.213209: step 58, loss 1.28921, acc 0.6875')
(1, '2017-01-10T14:43:22.561929: step 59, loss 1.06647, acc 0.640625')
(1, '2017-01-10T14:43:23.886256: step 60, loss 1.74177, acc 0.609375')
(1, '2017-01-10T14:43:25.216373: step 61, loss 1.34557, acc 0.65625')
(1, '2017-01-10T14:43:26.550747: step 62, loss 1.2257, acc 0.609375')
(1, '2017-01-10T14:43:27.855934: step 63, loss 1.05524, acc 0.6875')
(1, '2017-01-10T14:43:29.170287: step 64, loss 0.800065, acc 0.78125')
(1, '2017-01-10T14:43:30.494803: step 65, loss 1.14896, acc 0.71875')
(1, '2017-01-10T14:43:31.813873: step 66, loss 1.15115, acc 0.640625')
(1, '2017-01-10T14:43:33.247589: step 67, loss 1.16204, acc 0.65625')
(1, '2017-01-10T14:43:34.598286: step 68, loss 1.34497, acc 0.578125')
(1, '2017-01-10T14:43:35.941394: step 69, loss 1.68929, acc 0.625')
(1, '2017-01-10T14:43:37.245574: step 70, loss 1.46909, acc 0.59375')
(1, '2017-01-10T14:43:38.577240: step 71, loss 1.24396, acc 0.6875')
(1, '2017-01-10T14:43:39.911477: step 72, loss 1.18158, acc 0.65625')
(1, '2017-01-10T14:43:41.220939: step 73, loss 1.50925, acc 0.546875')
(1, '2017-01-10T14:43:42.511935: step 74, loss 1.70521, acc 0.640625')
(1, '2017-01-10T14:43:43.906605: step 75, loss 1.56455, acc 0.546875')
(1, '2017-01-10T14:43:45.387714: step 76, loss 0.965042, acc 0.6875')
(1, '2017-01-10T14:43:46.903507: step 77, loss 1.63486, acc 0.5625')
(1, '2017-01-10T14:43:48.232451: step 78, loss 1.41254, acc 0.578125')
(1, '2017-01-10T14:43:49.525411: step 79, loss 1.03461, acc 0.6875')
(1, '2017-01-10T14:43:50.830751: step 80, loss 1.15458, acc 0.71875')
(1, '2017-01-10T14:43:52.142721: step 81, loss 1.12943, acc 0.625')
(1, '2017-01-10T14:43:53.449702: step 82, loss 1.12721, acc 0.6875')
(1, '2017-01-10T14:43:54.808682: step 83, loss 0.765829, acc 0.734375')
(1, '2017-01-10T14:43:56.115034: step 84, loss 0.733687, acc 0.734375')
(1, '2017-01-10T14:43:57.439776: step 85, loss 1.09182, acc 0.609375')
(1, '2017-01-10T14:43:58.726908: step 86, loss 1.16646, acc 0.6875')
(1, '2017-01-10T14:44:00.060227: step 87, loss 0.853047, acc 0.734375')
(1, '2017-01-10T14:44:01.347200: step 88, loss 1.21015, acc 0.65625')
(1, '2017-01-10T14:44:02.642513: step 89, loss 1.33695, acc 0.65625')
(1, '2017-01-10T14:44:03.977185: step 90, loss 1.23369, acc 0.671875')
(1, '2017-01-10T14:44:05.338320: step 91, loss 0.863592, acc 0.71875')
(1, '2017-01-10T14:44:06.623688: step 92, loss 1.08916, acc 0.640625')
(1, '2017-01-10T14:44:07.921951: step 93, loss 1.13736, acc 0.640625')
(1, '2017-01-10T14:44:09.240552: step 94, loss 1.32586, acc 0.5625')
(1, '2017-01-10T14:44:10.547310: step 95, loss 0.885281, acc 0.71875')
(1, '2017-01-10T14:44:11.844904: step 96, loss 1.3204, acc 0.703125')
(1, '2017-01-10T14:44:13.156506: step 97, loss 1.23202, acc 0.625')
(1, '2017-01-10T14:44:14.490717: step 98, loss 0.787212, acc 0.703125')
(1, '2017-01-10T14:44:15.974204: step 99, loss 0.916642, acc 0.734375')
(1, '2017-01-10T14:44:17.301574: step 100, loss 0.852526, acc 0.734375')

Evaluation:
(1, '2017-01-10T14:44:20.045609: step 100, loss 0.61055, acc 0.66')

(1, '2017-01-10T14:44:21.300241: step 101, loss 1.01204, acc 0.640625')
(1, '2017-01-10T14:44:22.600684: step 102, loss 0.904232, acc 0.75')
(1, '2017-01-10T14:44:23.916699: step 103, loss 1.1402, acc 0.703125')
(1, '2017-01-10T14:44:25.255902: step 104, loss 0.974255, acc 0.75')
(1, '2017-01-10T14:44:26.579511: step 105, loss 0.793537, acc 0.75')
(1, '2017-01-10T14:44:27.902810: step 106, loss 1.31518, acc 0.703125')
(1, '2017-01-10T14:44:29.203543: step 107, loss 0.301468, acc 0.890625')
(1, '2017-01-10T14:44:30.500957: step 108, loss 1.40253, acc 0.609375')
(1, '2017-01-10T14:44:31.818903: step 109, loss 1.18545, acc 0.625')
(1, '2017-01-10T14:44:33.117113: step 110, loss 1.03346, acc 0.765625')
(1, '2017-01-10T14:44:34.446217: step 111, loss 0.816473, acc 0.71875')
(1, '2017-01-10T14:44:35.770120: step 112, loss 1.00522, acc 0.671875')
(1, '2017-01-10T14:44:37.047614: step 113, loss 0.675861, acc 0.75')
(1, '2017-01-10T14:44:38.353068: step 114, loss 0.905647, acc 0.625')
(1, '2017-01-10T14:44:39.673604: step 115, loss 1.19948, acc 0.671875')
(1, '2017-01-10T14:44:40.956078: step 116, loss 0.736176, acc 0.734375')
(1, '2017-01-10T14:44:42.260313: step 117, loss 1.21695, acc 0.671875')
(1, '2017-01-10T14:44:43.618668: step 118, loss 0.78794, acc 0.703125')
(1, '2017-01-10T14:44:44.907288: step 119, loss 1.05284, acc 0.65625')
(1, '2017-01-10T14:44:46.230284: step 120, loss 1.06721, acc 0.6875')
(1, '2017-01-10T14:44:47.519177: step 121, loss 1.29057, acc 0.578125')
(1, '2017-01-10T14:44:48.823100: step 122, loss 1.12372, acc 0.703125')
(1, '2017-01-10T14:44:50.134373: step 123, loss 1.00529, acc 0.71875')
(1, '2017-01-10T14:44:51.424858: step 124, loss 0.927037, acc 0.671875')
(1, '2017-01-10T14:44:52.764000: step 125, loss 0.720068, acc 0.78125')
(1, '2017-01-10T14:44:54.060189: step 126, loss 0.563242, acc 0.796875')
(1, '2017-01-10T14:44:55.417684: step 127, loss 1.17134, acc 0.609375')
(1, '2017-01-10T14:44:56.696235: step 128, loss 0.943091, acc 0.75')
(1, '2017-01-10T14:44:58.033598: step 129, loss 1.4359, acc 0.609375')
(1, '2017-01-10T14:44:59.365788: step 130, loss 0.659441, acc 0.78125')
(1, '2017-01-10T14:45:00.652243: step 131, loss 0.59531, acc 0.796875')
(1, '2017-01-10T14:45:01.980571: step 132, loss 0.837588, acc 0.75')
(1, '2017-01-10T14:45:03.305093: step 133, loss 0.617154, acc 0.6875')
(1, '2017-01-10T14:45:04.618758: step 134, loss 0.624294, acc 0.8125')
(1, '2017-01-10T14:45:05.937814: step 135, loss 0.874747, acc 0.765625')
(1, '2017-01-10T14:45:07.276605: step 136, loss 0.678667, acc 0.734375')
(1, '2017-01-10T14:45:08.558862: step 137, loss 0.84977, acc 0.71875')
(1, '2017-01-10T14:45:09.874669: step 138, loss 0.90855, acc 0.65625')
(1, '2017-01-10T14:45:11.197328: step 139, loss 0.671763, acc 0.765625')
(1, '2017-01-10T14:45:12.506316: step 140, loss 0.819712, acc 0.703125')
(1, '2017-01-10T14:45:13.834383: step 141, loss 0.849977, acc 0.6875')
(1, '2017-01-10T14:45:15.319033: step 142, loss 0.998725, acc 0.71875')
(1, '2017-01-10T14:45:16.609202: step 143, loss 0.618401, acc 0.796875')
(1, '2017-01-10T14:45:17.927135: step 144, loss 0.610504, acc 0.75')
(1, '2017-01-10T14:45:19.251703: step 145, loss 0.718586, acc 0.65625')
(1, '2017-01-10T14:45:20.549304: step 146, loss 1.14157, acc 0.6875')
(1, '2017-01-10T14:45:21.891941: step 147, loss 0.873038, acc 0.734375')
(1, '2017-01-10T14:45:23.214457: step 148, loss 0.409128, acc 0.78125')
(1, '2017-01-10T14:45:24.500154: step 149, loss 0.764677, acc 0.671875')
(1, '2017-01-10T14:45:25.818272: step 150, loss 0.864389, acc 0.78125')
(1, '2017-01-10T14:45:27.150063: step 151, loss 0.770348, acc 0.71875')
(1, '2017-01-10T14:45:28.479169: step 152, loss 1.08062, acc 0.625')
(1, '2017-01-10T14:45:29.759210: step 153, loss 0.95639, acc 0.671875')
(1, '2017-01-10T14:45:31.096704: step 154, loss 0.581872, acc 0.75')
(1, '2017-01-10T14:45:32.437129: step 155, loss 0.981814, acc 0.640625')
(1, '2017-01-10T14:45:33.743277: step 156, loss 0.713511, acc 0.6875')
(1, '2017-01-10T14:45:35.030103: step 157, loss 0.742658, acc 0.6875')
(1, '2017-01-10T14:45:36.365257: step 158, loss 0.864448, acc 0.671875')
(1, '2017-01-10T14:45:37.683262: step 159, loss 0.631767, acc 0.796875')
(1, '2017-01-10T14:45:38.998597: step 160, loss 1.01025, acc 0.65625')
(1, '2017-01-10T14:45:40.287378: step 161, loss 1.07942, acc 0.625')
(1, '2017-01-10T14:45:41.592678: step 162, loss 0.501775, acc 0.796875')
(1, '2017-01-10T14:45:42.933560: step 163, loss 0.87275, acc 0.734375')
(1, '2017-01-10T14:45:44.226352: step 164, loss 0.683031, acc 0.75')
(1, '2017-01-10T14:45:45.554147: step 165, loss 0.585032, acc 0.78125')
(1, '2017-01-10T14:45:46.905329: step 166, loss 0.770094, acc 0.796875')
(1, '2017-01-10T14:45:48.222872: step 167, loss 0.979835, acc 0.6875')
(1, '2017-01-10T14:45:49.531996: step 168, loss 0.618105, acc 0.8125')
(1, '2017-01-10T14:45:50.817740: step 169, loss 0.860054, acc 0.734375')
(1, '2017-01-10T14:45:52.169293: step 170, loss 0.547669, acc 0.765625')
(1, '2017-01-10T14:45:53.472332: step 171, loss 0.739248, acc 0.65625')
(1, '2017-01-10T14:45:54.782874: step 172, loss 0.60833, acc 0.78125')
(1, '2017-01-10T14:45:56.101399: step 173, loss 0.556305, acc 0.828125')
(1, '2017-01-10T14:45:57.431186: step 174, loss 1.0493, acc 0.671875')
(1, '2017-01-10T14:45:58.723106: step 175, loss 0.978593, acc 0.703125')
(1, '2017-01-10T14:46:00.046020: step 176, loss 0.801624, acc 0.6875')
(1, '2017-01-10T14:46:01.373894: step 177, loss 0.55764, acc 0.84375')
(1, '2017-01-10T14:46:02.691273: step 178, loss 0.342707, acc 0.828125')
(1, '2017-01-10T14:46:04.007158: step 179, loss 0.805723, acc 0.703125')
(1, '2017-01-10T14:46:05.327925: step 180, loss 0.794554, acc 0.703125')
(1, '2017-01-10T14:46:06.650838: step 181, loss 0.539272, acc 0.734375')
(1, '2017-01-10T14:46:07.930459: step 182, loss 1.32075, acc 0.609375')
(1, '2017-01-10T14:46:09.231972: step 183, loss 0.831286, acc 0.71875')
(1, '2017-01-10T14:46:10.550540: step 184, loss 0.703413, acc 0.71875')
(1, '2017-01-10T14:46:11.849947: step 185, loss 0.778067, acc 0.734375')
(1, '2017-01-10T14:46:13.192091: step 186, loss 0.693688, acc 0.734375')
(1, '2017-01-10T14:46:14.516716: step 187, loss 0.685931, acc 0.765625')
(1, '2017-01-10T14:46:16.007851: step 188, loss 0.806223, acc 0.75')
(1, '2017-01-10T14:46:17.294528: step 189, loss 0.61618, acc 0.734375')
(1, '2017-01-10T14:46:18.620855: step 190, loss 0.742213, acc 0.703125')
(1, '2017-01-10T14:46:19.914215: step 191, loss 0.425579, acc 0.859375')
(1, '2017-01-10T14:46:21.212890: step 192, loss 0.761409, acc 0.703125')
(1, '2017-01-10T14:46:22.536568: step 193, loss 0.928475, acc 0.65625')
(1, '2017-01-10T14:46:23.891094: step 194, loss 0.638559, acc 0.8125')
(1, '2017-01-10T14:46:25.176334: step 195, loss 0.586456, acc 0.765625')
(1, '2017-01-10T14:46:26.491793: step 196, loss 0.887224, acc 0.71875')
(1, '2017-01-10T14:46:27.820295: step 197, loss 0.585221, acc 0.8125')
(1, '2017-01-10T14:46:29.128599: step 198, loss 0.648271, acc 0.734375')
(1, '2017-01-10T14:46:30.420506: step 199, loss 0.504577, acc 0.8125')
(1, '2017-01-10T14:46:31.742288: step 200, loss 0.415151, acc 0.828125')

Evaluation:
(1, '2017-01-10T14:46:34.528552: step 200, loss 0.583355, acc 0.6725')

(1, '2017-01-10T14:46:35.841173: step 201, loss 0.601525, acc 0.765625')
(1, '2017-01-10T14:46:37.160471: step 202, loss 0.545402, acc 0.765625')
(1, '2017-01-10T14:46:38.476657: step 203, loss 0.458355, acc 0.796875')
(1, '2017-01-10T14:46:39.799655: step 204, loss 0.52764, acc 0.875')
(1, '2017-01-10T14:46:41.109323: step 205, loss 0.396048, acc 0.875')
(1, '2017-01-10T14:46:42.395123: step 206, loss 0.525952, acc 0.765625')
(1, '2017-01-10T14:46:43.694468: step 207, loss 0.360186, acc 0.84375')
(1, '2017-01-10T14:46:45.012965: step 208, loss 0.587089, acc 0.78125')
(1, '2017-01-10T14:46:46.333077: step 209, loss 0.638441, acc 0.765625')
(1, '2017-01-10T14:46:47.615239: step 210, loss 0.349939, acc 0.859375')
(1, '2017-01-10T14:46:48.902185: step 211, loss 0.564447, acc 0.78125')
(1, '2017-01-10T14:46:50.222953: step 212, loss 0.584635, acc 0.765625')
(1, '2017-01-10T14:46:51.541880: step 213, loss 0.697521, acc 0.734375')
(1, '2017-01-10T14:46:52.827808: step 214, loss 0.563427, acc 0.765625')
(1, '2017-01-10T14:46:54.136313: step 215, loss 0.469776, acc 0.8125')
(1, '2017-01-10T14:46:55.494852: step 216, loss 0.484363, acc 0.859375')
(1, '2017-01-10T14:46:56.814389: step 217, loss 0.661775, acc 0.734375')
(1, '2017-01-10T14:46:58.097953: step 218, loss 0.369952, acc 0.8125')
(1, '2017-01-10T14:46:59.397890: step 219, loss 0.867048, acc 0.78125')
(1, '2017-01-10T14:47:00.706575: step 220, loss 0.440232, acc 0.8125')
(1, '2017-01-10T14:47:02.031492: step 221, loss 0.857257, acc 0.671875')
(1, '2017-01-10T14:47:03.323206: step 222, loss 0.412156, acc 0.84375')
(1, '2017-01-10T14:47:04.638367: step 223, loss 0.308912, acc 0.875')
(1, '2017-01-10T14:47:05.979745: step 224, loss 0.731335, acc 0.703125')
(1, '2017-01-10T14:47:07.267651: step 225, loss 0.502254, acc 0.765625')
(1, '2017-01-10T14:47:08.581683: step 226, loss 0.422138, acc 0.859375')
(1, '2017-01-10T14:47:09.889477: step 227, loss 0.640523, acc 0.75')
(1, '2017-01-10T14:47:11.219422: step 228, loss 0.702987, acc 0.734375')
(1, '2017-01-10T14:47:12.537311: step 229, loss 0.41084, acc 0.8125')
(1, '2017-01-10T14:47:13.847840: step 230, loss 0.589401, acc 0.765625')
(1, '2017-01-10T14:47:15.302799: step 231, loss 0.450716, acc 0.8125')
(1, '2017-01-10T14:47:16.638377: step 232, loss 0.530325, acc 0.78125')
(1, '2017-01-10T14:47:17.935672: step 233, loss 0.503229, acc 0.8125')
(1, '2017-01-10T14:47:19.224464: step 234, loss 0.556815, acc 0.796875')
(1, '2017-01-10T14:47:20.556155: step 235, loss 0.443305, acc 0.84375')
(1, '2017-01-10T14:47:21.844442: step 236, loss 0.425441, acc 0.84375')
(1, '2017-01-10T14:47:23.161574: step 237, loss 0.410587, acc 0.84375')
(1, '2017-01-10T14:47:24.456462: step 238, loss 0.385301, acc 0.84375')
(1, '2017-01-10T14:47:25.780043: step 239, loss 0.538645, acc 0.765625')
(1, '2017-01-10T14:47:27.099034: step 240, loss 0.663051, acc 0.765625')
(1, '2017-01-10T14:47:28.434165: step 241, loss 0.82281, acc 0.75')
(1, '2017-01-10T14:47:29.714938: step 242, loss 0.377793, acc 0.84375')
(1, '2017-01-10T14:47:31.034905: step 243, loss 0.434796, acc 0.8125')
(1, '2017-01-10T14:47:32.347787: step 244, loss 0.775104, acc 0.765625')
(1, '2017-01-10T14:47:33.648084: step 245, loss 0.261572, acc 0.90625')
(1, '2017-01-10T14:47:34.940386: step 246, loss 0.340809, acc 0.84375')
(1, '2017-01-10T14:47:36.296839: step 247, loss 0.609857, acc 0.796875')
(1, '2017-01-10T14:47:37.615179: step 248, loss 0.287855, acc 0.890625')
(1, '2017-01-10T14:47:38.894534: step 249, loss 0.485257, acc 0.796875')
(1, '2017-01-10T14:47:40.216524: step 250, loss 0.4172, acc 0.859375')
(1, '2017-01-10T14:47:41.538313: step 251, loss 0.48584, acc 0.796875')
(1, '2017-01-10T14:47:42.813115: step 252, loss 0.340039, acc 0.84375')
(1, '2017-01-10T14:47:44.117755: step 253, loss 0.800555, acc 0.765625')
(1, '2017-01-10T14:47:45.441207: step 254, loss 0.384624, acc 0.859375')
(1, '2017-01-10T14:47:46.851673: step 255, loss 0.63774, acc 0.75')
(1, '2017-01-10T14:47:48.136566: step 256, loss 0.502311, acc 0.78125')
(1, '2017-01-10T14:47:49.433245: step 257, loss 0.361569, acc 0.84375')
(1, '2017-01-10T14:47:50.753320: step 258, loss 0.59828, acc 0.8125')
(1, '2017-01-10T14:47:52.075318: step 259, loss 0.486746, acc 0.84375')
(1, '2017-01-10T14:47:53.353768: step 260, loss 0.35648, acc 0.859375')
(1, '2017-01-10T14:47:54.656541: step 261, loss 0.560558, acc 0.84375')
(1, '2017-01-10T14:47:55.981202: step 262, loss 0.641195, acc 0.78125')
(1, '2017-01-10T14:47:57.338916: step 263, loss 0.335743, acc 0.90625')
(1, '2017-01-10T14:47:58.638887: step 264, loss 0.503057, acc 0.78125')
(1, '2017-01-10T14:47:59.962362: step 265, loss 0.502628, acc 0.765625')
(1, '2017-01-10T14:48:01.277080: step 266, loss 0.734892, acc 0.78125')
(1, '2017-01-10T14:48:02.594858: step 267, loss 0.554582, acc 0.8125')
(1, '2017-01-10T14:48:03.917586: step 268, loss 0.518883, acc 0.796875')
(1, '2017-01-10T14:48:05.235567: step 269, loss 0.30657, acc 0.90625')
(1, '2017-01-10T14:48:06.525046: step 270, loss 0.618348, acc 0.796875')
(1, '2017-01-10T14:48:07.856787: step 271, loss 0.598352, acc 0.8125')
(1, '2017-01-10T14:48:09.180940: step 272, loss 0.517776, acc 0.84375')
(1, '2017-01-10T14:48:10.483367: step 273, loss 0.233693, acc 0.890625')
(1, '2017-01-10T14:48:11.807208: step 274, loss 0.502995, acc 0.78125')
(1, '2017-01-10T14:48:13.106012: step 275, loss 0.346345, acc 0.828125')
(1, '2017-01-10T14:48:14.441868: step 276, loss 0.334059, acc 0.875')
(1, '2017-01-10T14:48:15.925245: step 277, loss 0.618901, acc 0.765625')
(1, '2017-01-10T14:48:17.239674: step 278, loss 0.420614, acc 0.859375')
(1, '2017-01-10T14:48:18.551831: step 279, loss 0.340272, acc 0.875')
(1, '2017-01-10T14:48:19.843938: step 280, loss 0.477958, acc 0.828125')
(1, '2017-01-10T14:48:21.148409: step 281, loss 0.425972, acc 0.859375')
(1, '2017-01-10T14:48:22.462584: step 282, loss 0.373224, acc 0.875')
(1, '2017-01-10T14:48:23.783754: step 283, loss 0.495959, acc 0.828125')
(1, '2017-01-10T14:48:25.061639: step 284, loss 0.590989, acc 0.78125')
(1, '2017-01-10T14:48:26.416598: step 285, loss 0.517705, acc 0.78125')
(1, '2017-01-10T14:48:27.737334: step 286, loss 0.429305, acc 0.859375')
(1, '2017-01-10T14:48:29.018957: step 287, loss 0.398071, acc 0.796875')
(1, '2017-01-10T14:48:30.346831: step 288, loss 0.380714, acc 0.875')
(1, '2017-01-10T14:48:31.670881: step 289, loss 0.475713, acc 0.8125')
(1, '2017-01-10T14:48:32.997276: step 290, loss 0.44314, acc 0.828125')
(1, '2017-01-10T14:48:34.284577: step 291, loss 0.3526, acc 0.8125')
(1, '2017-01-10T14:48:35.603865: step 292, loss 0.230558, acc 0.890625')
(1, '2017-01-10T14:48:36.953623: step 293, loss 0.516984, acc 0.78125')
(1, '2017-01-10T14:48:38.273475: step 294, loss 0.288375, acc 0.859375')
(1, '2017-01-10T14:48:39.573963: step 295, loss 0.252646, acc 0.921875')
(1, '2017-01-10T14:48:40.888392: step 296, loss 0.444414, acc 0.8125')
(1, '2017-01-10T14:48:42.210659: step 297, loss 0.441513, acc 0.8125')
(1, '2017-01-10T14:48:43.534264: step 298, loss 0.397481, acc 0.875')
(1, '2017-01-10T14:48:44.833554: step 299, loss 0.470888, acc 0.796875')
(1, '2017-01-10T14:48:46.158824: step 300, loss 0.321956, acc 0.84375')

Evaluation:
(1, '2017-01-10T14:48:48.976873: step 300, loss 0.539301, acc 0.73')

(1, '2017-01-10T14:48:50.292828: step 301, loss 0.20396, acc 0.90625')
(1, '2017-01-10T14:48:51.603450: step 302, loss 0.342656, acc 0.84375')
(1, '2017-01-10T14:48:52.923633: step 303, loss 0.413005, acc 0.796875')
(1, '2017-01-10T14:48:54.257099: step 304, loss 0.448039, acc 0.859375')
(1, '2017-01-10T14:48:55.606792: step 305, loss 0.305119, acc 0.90625')
(1, '2017-01-10T14:48:56.902863: step 306, loss 0.510818, acc 0.796875')
(1, '2017-01-10T14:48:58.234620: step 307, loss 0.410864, acc 0.828125')
(1, '2017-01-10T14:48:59.556804: step 308, loss 0.438157, acc 0.8125')
(1, '2017-01-10T14:49:00.867994: step 309, loss 0.483374, acc 0.875')
(1, '2017-01-10T14:49:02.162068: step 310, loss 0.372131, acc 0.890625')
(1, '2017-01-10T14:49:03.480053: step 311, loss 0.206281, acc 0.890625')
(1, '2017-01-10T14:49:04.795287: step 312, loss 0.278212, acc 0.921875')
(1, '2017-01-10T14:49:06.145300: step 313, loss 0.380779, acc 0.875')
(1, '2017-01-10T14:49:07.453980: step 314, loss 0.549521, acc 0.8125')
(1, '2017-01-10T14:49:08.777886: step 315, loss 0.33559, acc 0.859375')
(1, '2017-01-10T14:49:10.063306: step 316, loss 0.542524, acc 0.796875')
(1, '2017-01-10T14:49:11.380608: step 317, loss 0.342254, acc 0.875')
(1, '2017-01-10T14:49:12.698392: step 318, loss 0.205154, acc 0.921875')
(1, '2017-01-10T14:49:14.020258: step 319, loss 0.388825, acc 0.859375')
(1, '2017-01-10T14:49:15.485431: step 320, loss 0.465948, acc 0.828125')
(1, '2017-01-10T14:49:16.832052: step 321, loss 0.323981, acc 0.859375')
(1, '2017-01-10T14:49:18.143125: step 322, loss 0.279195, acc 0.859375')
(1, '2017-01-10T14:49:19.463145: step 323, loss 0.388267, acc 0.828125')
(1, '2017-01-10T14:49:20.756907: step 324, loss 0.346581, acc 0.90625')
(1, '2017-01-10T14:49:22.073403: step 325, loss 0.447133, acc 0.8125')
(1, '2017-01-10T14:49:23.366845: step 326, loss 0.421379, acc 0.828125')
(1, '2017-01-10T14:49:24.679946: step 327, loss 0.319705, acc 0.859375')
(1, '2017-01-10T14:49:26.002221: step 328, loss 0.208938, acc 0.921875')
(1, '2017-01-10T14:49:27.325263: step 329, loss 0.366381, acc 0.859375')
(1, '2017-01-10T14:49:28.651459: step 330, loss 0.432792, acc 0.8125')
(1, '2017-01-10T14:49:29.977281: step 331, loss 0.203853, acc 0.890625')
(1, '2017-01-10T14:49:31.256351: step 332, loss 0.466427, acc 0.8125')
(1, '2017-01-10T14:49:32.547606: step 333, loss 0.333388, acc 0.859375')
(1, '2017-01-10T14:49:33.870379: step 334, loss 0.339349, acc 0.890625')
(1, '2017-01-10T14:49:35.162157: step 335, loss 0.296836, acc 0.859375')
(1, '2017-01-10T14:49:36.484220: step 336, loss 0.283433, acc 0.890625')
(1, '2017-01-10T14:49:37.793433: step 337, loss 0.401136, acc 0.8125')
(1, '2017-01-10T14:49:39.122926: step 338, loss 0.213898, acc 0.890625')
(1, '2017-01-10T14:49:40.451558: step 339, loss 0.511331, acc 0.8125')
(1, '2017-01-10T14:49:41.723120: step 340, loss 0.251543, acc 0.921875')
(1, '2017-01-10T14:49:43.016345: step 341, loss 0.398395, acc 0.796875')
(1, '2017-01-10T14:49:44.335891: step 342, loss 0.324101, acc 0.875')
(1, '2017-01-10T14:49:45.669353: step 343, loss 0.417055, acc 0.828125')
(1, '2017-01-10T14:49:47.014555: step 344, loss 0.500536, acc 0.765625')
(1, '2017-01-10T14:49:48.321459: step 345, loss 0.286739, acc 0.921875')
(1, '2017-01-10T14:49:49.676182: step 346, loss 0.250735, acc 0.859375')
(1, '2017-01-10T14:49:50.972535: step 347, loss 0.292687, acc 0.9375')
(1, '2017-01-10T14:49:52.266511: step 348, loss 0.501075, acc 0.765625')
(1, '2017-01-10T14:49:53.587536: step 349, loss 0.275252, acc 0.875')
(1, '2017-01-10T14:49:54.922067: step 350, loss 0.220063, acc 0.921875')
(1, '2017-01-10T14:49:56.218650: step 351, loss 0.255253, acc 0.90625')
(1, '2017-01-10T14:49:57.550060: step 352, loss 0.69384, acc 0.796875')
(1, '2017-01-10T14:49:58.880933: step 353, loss 0.432097, acc 0.84375')
(1, '2017-01-10T14:50:00.201076: step 354, loss 0.373631, acc 0.875')
(1, '2017-01-10T14:50:01.513266: step 355, loss 0.360452, acc 0.84375')
(1, '2017-01-10T14:50:02.862611: step 356, loss 0.185279, acc 0.96875')
(1, '2017-01-10T14:50:04.180272: step 357, loss 0.404952, acc 0.859375')
(1, '2017-01-10T14:50:05.469737: step 358, loss 0.467659, acc 0.828125')
(1, '2017-01-10T14:50:06.788242: step 359, loss 0.27196, acc 0.921875')
(1, '2017-01-10T14:50:08.124782: step 360, loss 0.204543, acc 0.90625')
(1, '2017-01-10T14:50:09.453790: step 361, loss 0.206318, acc 0.890625')
(1, '2017-01-10T14:50:10.789364: step 362, loss 0.262111, acc 0.875')
(1, '2017-01-10T14:50:12.135518: step 363, loss 0.397028, acc 0.84375')
(1, '2017-01-10T14:50:13.480137: step 364, loss 0.254439, acc 0.890625')
(1, '2017-01-10T14:50:14.911794: step 365, loss 0.388751, acc 0.84375')
(1, '2017-01-10T14:50:16.260250: step 366, loss 0.24661, acc 0.9375')
(1, '2017-01-10T14:50:17.570588: step 367, loss 0.458981, acc 0.859375')
(1, '2017-01-10T14:50:18.890528: step 368, loss 0.341993, acc 0.84375')
(1, '2017-01-10T14:50:20.215760: step 369, loss 0.22898, acc 0.953125')
(1, '2017-01-10T14:50:21.531504: step 370, loss 0.53398, acc 0.8125')
(1, '2017-01-10T14:50:22.829216: step 371, loss 0.333679, acc 0.875')
(1, '2017-01-10T14:50:24.147463: step 372, loss 0.358894, acc 0.859375')
(1, '2017-01-10T14:50:25.464768: step 373, loss 0.319878, acc 0.921875')
(1, '2017-01-10T14:50:26.787396: step 374, loss 0.25485, acc 0.84375')
(1, '2017-01-10T14:50:28.085692: step 375, loss 0.376695, acc 0.859375')
(1, '2017-01-10T14:50:29.420841: step 376, loss 0.249352, acc 0.90625')
(1, '2017-01-10T14:50:30.729878: step 377, loss 0.186108, acc 0.890625')
(1, '2017-01-10T14:50:32.024121: step 378, loss 0.232934, acc 0.921875')
(1, '2017-01-10T14:50:33.350309: step 379, loss 0.375766, acc 0.859375')
(1, '2017-01-10T14:50:34.668225: step 380, loss 0.366986, acc 0.859375')
(1, '2017-01-10T14:50:35.993121: step 381, loss 0.193674, acc 0.921875')
(1, '2017-01-10T14:50:37.309519: step 382, loss 0.268537, acc 0.890625')
(1, '2017-01-10T14:50:38.611640: step 383, loss 0.189108, acc 0.890625')
(1, '2017-01-10T14:50:39.954910: step 384, loss 0.188823, acc 0.9375')
(1, '2017-01-10T14:50:41.245815: step 385, loss 0.365211, acc 0.890625')
(1, '2017-01-10T14:50:42.563138: step 386, loss 0.168069, acc 0.96875')
(1, '2017-01-10T14:50:43.880139: step 387, loss 0.259588, acc 0.890625')
(1, '2017-01-10T14:50:45.177154: step 388, loss 0.253372, acc 0.890625')
(1, '2017-01-10T14:50:46.529513: step 389, loss 0.323334, acc 0.875')
(1, '2017-01-10T14:50:47.913653: step 390, loss 0.261278, acc 0.84375')
(1, '2017-01-10T14:50:49.236024: step 391, loss 0.282261, acc 0.875')
(1, '2017-01-10T14:50:50.581935: step 392, loss 0.250332, acc 0.875')
(1, '2017-01-10T14:50:51.910974: step 393, loss 0.143346, acc 0.9375')
(1, '2017-01-10T14:50:53.245409: step 394, loss 0.282654, acc 0.84375')
(1, '2017-01-10T14:50:54.543330: step 395, loss 0.251104, acc 0.90625')
(1, '2017-01-10T14:50:55.909624: step 396, loss 0.515663, acc 0.828125')
(1, '2017-01-10T14:50:57.233409: step 397, loss 0.392704, acc 0.8125')
(1, '2017-01-10T14:50:58.632612: step 398, loss 0.454014, acc 0.859375')
(1, '2017-01-10T14:51:00.003018: step 399, loss 0.361176, acc 0.84375')
(1, '2017-01-10T14:51:01.344256: step 400, loss 0.177463, acc 0.9375')

Evaluation:
(1, '2017-01-10T14:51:04.148275: step 400, loss 0.527846, acc 0.7325')

(1, '2017-01-10T14:51:05.433840: step 401, loss 0.305409, acc 0.828125')
(1, '2017-01-10T14:51:06.765479: step 402, loss 0.234122, acc 0.921875')
(1, '2017-01-10T14:51:08.122203: step 403, loss 0.298414, acc 0.828125')
(1, '2017-01-10T14:51:09.508307: step 404, loss 0.248697, acc 0.890625')
(1, '2017-01-10T14:51:10.825411: step 405, loss 0.360542, acc 0.875')
(1, '2017-01-10T14:51:12.141671: step 406, loss 0.425318, acc 0.8125')
(1, '2017-01-10T14:51:13.434717: step 407, loss 0.368425, acc 0.8125')
(1, '2017-01-10T14:51:14.826590: step 408, loss 0.49748, acc 0.78125')
(1, '2017-01-10T14:51:16.205013: step 409, loss 0.195889, acc 0.921875')
(1, '2017-01-10T14:51:17.547149: step 410, loss 0.237675, acc 0.9375')
(1, '2017-01-10T14:51:18.885380: step 411, loss 0.230749, acc 0.9375')
(1, '2017-01-10T14:51:20.199952: step 412, loss 0.404204, acc 0.828125')
(1, '2017-01-10T14:51:21.484767: step 413, loss 0.134957, acc 0.9375')
(1, '2017-01-10T14:51:22.801332: step 414, loss 0.299863, acc 0.890625')
(1, '2017-01-10T14:51:24.114304: step 415, loss 0.202711, acc 0.9375')
(1, '2017-01-10T14:51:25.425656: step 416, loss 0.430378, acc 0.796875')
(1, '2017-01-10T14:51:26.735101: step 417, loss 0.225098, acc 0.921875')
(1, '2017-01-10T14:51:28.079265: step 418, loss 0.351727, acc 0.8125')
(1, '2017-01-10T14:51:29.368302: step 419, loss 0.361145, acc 0.84375')
(1, '2017-01-10T14:51:30.681663: step 420, loss 0.229831, acc 0.890625')
(1, '2017-01-10T14:51:31.993853: step 421, loss 0.338205, acc 0.90625')
(1, '2017-01-10T14:51:33.320367: step 422, loss 0.461006, acc 0.78125')
(1, '2017-01-10T14:51:34.664323: step 423, loss 0.150867, acc 0.9375')
(1, '2017-01-10T14:51:35.956027: step 424, loss 0.143016, acc 0.921875')
(1, '2017-01-10T14:51:37.298515: step 425, loss 0.25703, acc 0.875')
(1, '2017-01-10T14:51:38.625399: step 426, loss 0.21388, acc 0.875')
(1, '2017-01-10T14:51:39.905684: step 427, loss 0.238805, acc 0.953125')
(1, '2017-01-10T14:51:41.225490: step 428, loss 0.225094, acc 0.921875')
(1, '2017-01-10T14:51:42.576836: step 429, loss 0.412533, acc 0.859375')
(1, '2017-01-10T14:51:43.929409: step 430, loss 0.236638, acc 0.875')
(1, '2017-01-10T14:51:45.213288: step 431, loss 0.194076, acc 0.9375')
(1, '2017-01-10T14:51:46.573726: step 432, loss 0.226591, acc 0.90625')
(1, '2017-01-10T14:51:47.937271: step 433, loss 0.354375, acc 0.859375')
(1, '2017-01-10T14:51:49.255488: step 434, loss 0.363042, acc 0.90625')
(1, '2017-01-10T14:51:50.567421: step 435, loss 0.286854, acc 0.90625')
(1, '2017-01-10T14:51:51.861939: step 436, loss 0.238323, acc 0.90625')
(1, '2017-01-10T14:51:53.168596: step 437, loss 0.182706, acc 0.90625')
(1, '2017-01-10T14:51:54.486705: step 438, loss 0.164817, acc 0.96875')
(1, '2017-01-10T14:51:55.767896: step 439, loss 0.195479, acc 0.890625')
(1, '2017-01-10T14:51:57.096016: step 440, loss 0.273585, acc 0.90625')
(1, '2017-01-10T14:51:58.457765: step 441, loss 0.189518, acc 0.9375')
(1, '2017-01-10T14:51:59.794223: step 442, loss 0.287673, acc 0.875')
(1, '2017-01-10T14:52:01.112658: step 443, loss 0.10946, acc 0.9375')
(1, '2017-01-10T14:52:02.406227: step 444, loss 0.342793, acc 0.84375')
(1, '2017-01-10T14:52:03.736700: step 445, loss 0.239062, acc 0.890625')
(1, '2017-01-10T14:52:05.053678: step 446, loss 0.230479, acc 0.921875')
(1, '2017-01-10T14:52:06.356741: step 447, loss 0.374739, acc 0.8125')
(1, '2017-01-10T14:52:07.682259: step 448, loss 0.227488, acc 0.890625')
(1, '2017-01-10T14:52:09.005296: step 449, loss 0.41956, acc 0.84375')
(1, '2017-01-10T14:52:10.319851: step 450, loss 0.315394, acc 0.875')
(1, '2017-01-10T14:52:11.647302: step 451, loss 0.166373, acc 0.921875')
(1, '2017-01-10T14:52:12.967433: step 452, loss 0.145492, acc 0.9375')
(1, '2017-01-10T14:52:14.294548: step 453, loss 0.0929978, acc 0.953125')
(1, '2017-01-10T14:52:15.742501: step 454, loss 0.330252, acc 0.84375')
(1, '2017-01-10T14:52:17.069357: step 455, loss 0.318244, acc 0.875')
(1, '2017-01-10T14:52:18.393786: step 456, loss 0.21027, acc 0.890625')
(1, '2017-01-10T14:52:19.665713: step 457, loss 0.248045, acc 0.890625')
(1, '2017-01-10T14:52:21.040655: step 458, loss 0.539558, acc 0.765625')
(1, '2017-01-10T14:52:22.359993: step 459, loss 0.368178, acc 0.84375')
(1, '2017-01-10T14:52:23.653572: step 460, loss 0.362471, acc 0.875')
(1, '2017-01-10T14:52:24.978390: step 461, loss 0.177778, acc 0.9375')
(1, '2017-01-10T14:52:26.276738: step 462, loss 0.437326, acc 0.84375')
(1, '2017-01-10T14:52:27.582946: step 463, loss 0.240096, acc 0.890625')
(1, '2017-01-10T14:52:28.897660: step 464, loss 0.431544, acc 0.84375')
(1, '2017-01-10T14:52:30.231208: step 465, loss 0.442634, acc 0.8125')
(1, '2017-01-10T14:52:31.554771: step 466, loss 0.367145, acc 0.796875')
(1, '2017-01-10T14:52:32.872322: step 467, loss 0.231807, acc 0.859375')
(1, '2017-01-10T14:52:34.174639: step 468, loss 0.137233, acc 0.96875')
(1, '2017-01-10T14:52:35.495518: step 469, loss 0.265972, acc 0.890625')
(1, '2017-01-10T14:52:36.780930: step 470, loss 0.289226, acc 0.859375')
(1, '2017-01-10T14:52:38.105216: step 471, loss 0.380391, acc 0.875')
(1, '2017-01-10T14:52:39.424963: step 472, loss 0.219124, acc 0.890625')
(1, '2017-01-10T14:52:40.776254: step 473, loss 0.332536, acc 0.859375')
(1, '2017-01-10T14:52:42.106003: step 474, loss 0.246743, acc 0.890625')
(1, '2017-01-10T14:52:43.434917: step 475, loss 0.147501, acc 0.953125')
(1, '2017-01-10T14:52:44.723013: step 476, loss 0.299376, acc 0.859375')
(1, '2017-01-10T14:52:46.027936: step 477, loss 0.222029, acc 0.90625')
(1, '2017-01-10T14:52:47.323586: step 478, loss 0.214739, acc 0.890625')
(1, '2017-01-10T14:52:48.646816: step 479, loss 0.243983, acc 0.9375')
(1, '2017-01-10T14:52:49.957938: step 480, loss 0.298616, acc 0.890625')
(1, '2017-01-10T14:52:51.244705: step 481, loss 0.119372, acc 0.9375')
(1, '2017-01-10T14:52:52.588503: step 482, loss 0.239953, acc 0.921875')
(1, '2017-01-10T14:52:53.899570: step 483, loss 0.27736, acc 0.890625')
(1, '2017-01-10T14:52:55.174407: step 484, loss 0.281053, acc 0.890625')
(1, '2017-01-10T14:52:56.487219: step 485, loss 0.220072, acc 0.859375')
(1, '2017-01-10T14:52:57.820557: step 486, loss 0.129913, acc 0.953125')
(1, '2017-01-10T14:52:59.149275: step 487, loss 0.333053, acc 0.875')
(1, '2017-01-10T14:53:00.446515: step 488, loss 0.170628, acc 0.9375')
(1, '2017-01-10T14:53:01.771328: step 489, loss 0.117559, acc 0.953125')
(1, '2017-01-10T14:53:03.082431: step 490, loss 0.263062, acc 0.90625')
(1, '2017-01-10T14:53:04.398760: step 491, loss 0.104998, acc 0.984375')
(1, '2017-01-10T14:53:05.727636: step 492, loss 0.150519, acc 0.9375')
(1, '2017-01-10T14:53:07.030664: step 493, loss 0.368656, acc 0.859375')
(1, '2017-01-10T14:53:08.346711: step 494, loss 0.184233, acc 0.921875')
(1, '2017-01-10T14:53:09.638129: step 495, loss 0.176078, acc 0.96875')
(1, '2017-01-10T14:53:10.942449: step 496, loss 0.139831, acc 0.953125')
(1, '2017-01-10T14:53:12.284949: step 497, loss 0.292936, acc 0.890625')
(1, '2017-01-10T14:53:13.590466: step 498, loss 0.464322, acc 0.84375')
(1, '2017-01-10T14:53:15.072238: step 499, loss 0.183483, acc 0.921875')
(1, '2017-01-10T14:53:16.392434: step 500, loss 0.335999, acc 0.8125')

Evaluation:
(1, '2017-01-10T14:53:19.004579: step 500, loss 0.560547, acc 0.7375')

(1, '2017-01-10T14:53:22.138836: step 500, loss 0.560547, acc 0.7375')
Vocabulary Size: 14319
Train/Dev split: 1600/400
Writing to /Users/amrkoura/Documents/workspace/newYorkerChallenge/runs/1484056402

(2, '2017-01-10T14:53:24.389188: step 1, loss 2.02849, acc 0.484375')
(2, '2017-01-10T14:53:25.642456: step 2, loss 2.24063, acc 0.453125')
(2, '2017-01-10T14:53:26.940767: step 3, loss 1.78794, acc 0.609375')
(2, '2017-01-10T14:53:28.322030: step 4, loss 2.13849, acc 0.59375')
(2, '2017-01-10T14:53:29.644789: step 5, loss 1.92283, acc 0.65625')
(2, '2017-01-10T14:53:30.980548: step 6, loss 1.55579, acc 0.609375')
(2, '2017-01-10T14:53:32.305463: step 7, loss 3.06851, acc 0.40625')
(2, '2017-01-10T14:53:33.630558: step 8, loss 2.06064, acc 0.609375')
(2, '2017-01-10T14:53:34.955320: step 9, loss 2.63846, acc 0.5')
(2, '2017-01-10T14:53:36.291073: step 10, loss 2.82469, acc 0.5625')
(2, '2017-01-10T14:53:37.642956: step 11, loss 2.41115, acc 0.515625')
(2, '2017-01-10T14:53:39.070524: step 12, loss 2.2862, acc 0.484375')
(2, '2017-01-10T14:53:40.658501: step 13, loss 1.8659, acc 0.484375')
(2, '2017-01-10T14:53:42.303748: step 14, loss 2.28226, acc 0.546875')
(2, '2017-01-10T14:53:43.774662: step 15, loss 2.4736, acc 0.421875')
(2, '2017-01-10T14:53:45.243196: step 16, loss 1.5825, acc 0.609375')
(2, '2017-01-10T14:53:46.680973: step 17, loss 1.85494, acc 0.5625')
(2, '2017-01-10T14:53:48.029193: step 18, loss 1.76501, acc 0.59375')
(2, '2017-01-10T14:53:49.300759: step 19, loss 1.98818, acc 0.578125')
(2, '2017-01-10T14:53:50.615147: step 20, loss 2.46748, acc 0.53125')
(2, '2017-01-10T14:53:51.966201: step 21, loss 1.76876, acc 0.625')
(2, '2017-01-10T14:53:53.259300: step 22, loss 1.97567, acc 0.4375')
(2, '2017-01-10T14:53:54.587132: step 23, loss 2.59927, acc 0.515625')
(2, '2017-01-10T14:53:55.879052: step 24, loss 1.64632, acc 0.625')
(2, '2017-01-10T14:53:57.188210: step 25, loss 1.97645, acc 0.5625')
(2, '2017-01-10T14:53:58.689578: step 26, loss 2.54222, acc 0.484375')
(2, '2017-01-10T14:54:00.084217: step 27, loss 1.77138, acc 0.5')
(2, '2017-01-10T14:54:01.631637: step 28, loss 1.53709, acc 0.640625')
(2, '2017-01-10T14:54:03.204115: step 29, loss 1.61414, acc 0.609375')
(2, '2017-01-10T14:54:04.707571: step 30, loss 1.41066, acc 0.59375')
(2, '2017-01-10T14:54:06.040959: step 31, loss 1.80206, acc 0.578125')
(2, '2017-01-10T14:54:07.352381: step 32, loss 2.00578, acc 0.59375')
(2, '2017-01-10T14:54:08.723470: step 33, loss 1.75453, acc 0.53125')
(2, '2017-01-10T14:54:10.144690: step 34, loss 1.93213, acc 0.53125')
(2, '2017-01-10T14:54:11.505339: step 35, loss 2.00357, acc 0.546875')
(2, '2017-01-10T14:54:12.824862: step 36, loss 1.27113, acc 0.671875')
(2, '2017-01-10T14:54:14.182470: step 37, loss 1.63498, acc 0.640625')
(2, '2017-01-10T14:54:15.739513: step 38, loss 1.35105, acc 0.625')
(2, '2017-01-10T14:54:17.090729: step 39, loss 1.93528, acc 0.59375')
(2, '2017-01-10T14:54:18.503022: step 40, loss 1.4874, acc 0.640625')
(2, '2017-01-10T14:54:19.854070: step 41, loss 1.18538, acc 0.703125')
(2, '2017-01-10T14:54:21.319508: step 42, loss 1.25875, acc 0.640625')
(2, '2017-01-10T14:54:22.819035: step 43, loss 1.46724, acc 0.546875')
(2, '2017-01-10T14:54:24.117254: step 44, loss 1.6888, acc 0.65625')
(2, '2017-01-10T14:54:25.481815: step 45, loss 1.95263, acc 0.640625')
(2, '2017-01-10T14:54:26.908713: step 46, loss 1.59028, acc 0.5625')
(2, '2017-01-10T14:54:28.294986: step 47, loss 1.30434, acc 0.640625')
(2, '2017-01-10T14:54:29.626694: step 48, loss 2.65372, acc 0.46875')
(2, '2017-01-10T14:54:31.101014: step 49, loss 1.57919, acc 0.65625')
(2, '2017-01-10T14:54:32.446199: step 50, loss 2.4432, acc 0.53125')
(2, '2017-01-10T14:54:33.783793: step 51, loss 1.72961, acc 0.59375')
(2, '2017-01-10T14:54:35.213026: step 52, loss 1.97532, acc 0.546875')
(2, '2017-01-10T14:54:36.614917: step 53, loss 1.68971, acc 0.59375')
(2, '2017-01-10T14:54:37.948259: step 54, loss 2.06406, acc 0.53125')
(2, '2017-01-10T14:54:39.309879: step 55, loss 1.89786, acc 0.53125')
(2, '2017-01-10T14:54:40.651835: step 56, loss 1.74032, acc 0.703125')
(2, '2017-01-10T14:54:42.049195: step 57, loss 1.9335, acc 0.546875')
(2, '2017-01-10T14:54:43.511774: step 58, loss 1.56192, acc 0.59375')
(2, '2017-01-10T14:54:44.854581: step 59, loss 2.01046, acc 0.53125')
(2, '2017-01-10T14:54:46.165596: step 60, loss 1.22628, acc 0.671875')
(2, '2017-01-10T14:54:47.493925: step 61, loss 0.948374, acc 0.671875')
(2, '2017-01-10T14:54:48.820684: step 62, loss 1.78096, acc 0.578125')
(2, '2017-01-10T14:54:50.142065: step 63, loss 1.41798, acc 0.671875')
(2, '2017-01-10T14:54:51.448620: step 64, loss 1.37227, acc 0.671875')
(2, '2017-01-10T14:54:52.825512: step 65, loss 1.5552, acc 0.671875')
(2, '2017-01-10T14:54:54.225810: step 66, loss 1.74655, acc 0.546875')
(2, '2017-01-10T14:54:55.645493: step 67, loss 1.2445, acc 0.640625')
(2, '2017-01-10T14:54:57.000470: step 68, loss 1.46771, acc 0.578125')
(2, '2017-01-10T14:54:58.336644: step 69, loss 1.35596, acc 0.609375')
(2, '2017-01-10T14:54:59.637077: step 70, loss 1.67361, acc 0.515625')
(2, '2017-01-10T14:55:00.958997: step 71, loss 1.67243, acc 0.59375')
(2, '2017-01-10T14:55:02.274596: step 72, loss 1.55286, acc 0.625')
(2, '2017-01-10T14:55:03.641207: step 73, loss 1.05339, acc 0.6875')
(2, '2017-01-10T14:55:05.065739: step 74, loss 1.75234, acc 0.59375')
(2, '2017-01-10T14:55:06.634133: step 75, loss 0.945491, acc 0.6875')
(2, '2017-01-10T14:55:08.206770: step 76, loss 1.4966, acc 0.625')
(2, '2017-01-10T14:55:09.569648: step 77, loss 1.01797, acc 0.6875')
(2, '2017-01-10T14:55:10.935541: step 78, loss 1.50556, acc 0.625')
(2, '2017-01-10T14:55:12.243012: step 79, loss 0.945796, acc 0.75')
(2, '2017-01-10T14:55:13.572710: step 80, loss 1.62577, acc 0.640625')
(2, '2017-01-10T14:55:15.026485: step 81, loss 1.52378, acc 0.65625')
(2, '2017-01-10T14:55:16.505374: step 82, loss 1.43349, acc 0.609375')
(2, '2017-01-10T14:55:17.868617: step 83, loss 1.33399, acc 0.6875')
(2, '2017-01-10T14:55:19.205112: step 84, loss 0.901639, acc 0.671875')
(2, '2017-01-10T14:55:20.554670: step 85, loss 1.47493, acc 0.609375')
(2, '2017-01-10T14:55:21.871634: step 86, loss 0.990812, acc 0.703125')
(2, '2017-01-10T14:55:23.217786: step 87, loss 1.00593, acc 0.6875')
(2, '2017-01-10T14:55:24.571525: step 88, loss 1.21131, acc 0.65625')
(2, '2017-01-10T14:55:25.933611: step 89, loss 1.15257, acc 0.703125')
(2, '2017-01-10T14:55:27.346506: step 90, loss 1.97682, acc 0.484375')
(2, '2017-01-10T14:55:28.672086: step 91, loss 0.836786, acc 0.703125')
(2, '2017-01-10T14:55:30.019813: step 92, loss 1.3214, acc 0.640625')
(2, '2017-01-10T14:55:31.361263: step 93, loss 1.15256, acc 0.640625')
(2, '2017-01-10T14:55:32.681050: step 94, loss 0.884848, acc 0.75')
(2, '2017-01-10T14:55:33.973103: step 95, loss 0.99311, acc 0.75')
(2, '2017-01-10T14:55:35.293960: step 96, loss 1.51293, acc 0.640625')
(2, '2017-01-10T14:55:36.630732: step 97, loss 1.71791, acc 0.59375')
(2, '2017-01-10T14:55:37.985394: step 98, loss 1.23301, acc 0.71875')
(2, '2017-01-10T14:55:39.345907: step 99, loss 1.08544, acc 0.609375')
(2, '2017-01-10T14:55:40.707234: step 100, loss 1.07717, acc 0.625')

Evaluation:
(2, '2017-01-10T14:55:43.371287: step 100, loss 0.627885, acc 0.64')

(2, '2017-01-10T14:55:44.725295: step 101, loss 0.769941, acc 0.78125')
(2, '2017-01-10T14:55:46.075035: step 102, loss 0.978961, acc 0.6875')
(2, '2017-01-10T14:55:47.524276: step 103, loss 0.862313, acc 0.71875')
(2, '2017-01-10T14:55:48.997737: step 104, loss 1.01223, acc 0.640625')
(2, '2017-01-10T14:55:50.348835: step 105, loss 0.86345, acc 0.75')
(2, '2017-01-10T14:55:51.670832: step 106, loss 0.904003, acc 0.71875')
(2, '2017-01-10T14:55:53.030831: step 107, loss 0.774454, acc 0.8125')
(2, '2017-01-10T14:55:54.413095: step 108, loss 1.29266, acc 0.671875')
(2, '2017-01-10T14:55:55.728836: step 109, loss 1.0647, acc 0.640625')
(2, '2017-01-10T14:55:57.075523: step 110, loss 1.08048, acc 0.75')
(2, '2017-01-10T14:55:58.418279: step 111, loss 0.788397, acc 0.765625')
(2, '2017-01-10T14:55:59.829153: step 112, loss 1.10396, acc 0.71875')
(2, '2017-01-10T14:56:01.156380: step 113, loss 0.763418, acc 0.734375')
(2, '2017-01-10T14:56:02.740650: step 114, loss 0.939344, acc 0.734375')
(2, '2017-01-10T14:56:04.186604: step 115, loss 0.999844, acc 0.671875')
(2, '2017-01-10T14:56:05.657422: step 116, loss 0.895589, acc 0.734375')
(2, '2017-01-10T14:56:06.967335: step 117, loss 0.662337, acc 0.703125')
(2, '2017-01-10T14:56:08.263149: step 118, loss 1.25477, acc 0.671875')
(2, '2017-01-10T14:56:09.591738: step 119, loss 0.704935, acc 0.734375')
(2, '2017-01-10T14:56:10.958377: step 120, loss 0.97822, acc 0.734375')
(2, '2017-01-10T14:56:12.283239: step 121, loss 0.688047, acc 0.765625')
(2, '2017-01-10T14:56:13.590480: step 122, loss 1.49173, acc 0.5625')
(2, '2017-01-10T14:56:15.079085: step 123, loss 1.4847, acc 0.671875')
(2, '2017-01-10T14:56:16.368846: step 124, loss 0.598041, acc 0.78125')
(2, '2017-01-10T14:56:17.749846: step 125, loss 0.641199, acc 0.8125')
(2, '2017-01-10T14:56:19.108906: step 126, loss 0.923232, acc 0.734375')
(2, '2017-01-10T14:56:20.431206: step 127, loss 0.836061, acc 0.75')
(2, '2017-01-10T14:56:21.770568: step 128, loss 0.850535, acc 0.703125')
(2, '2017-01-10T14:56:23.092477: step 129, loss 0.943061, acc 0.65625')
(2, '2017-01-10T14:56:24.420387: step 130, loss 0.574471, acc 0.78125')
(2, '2017-01-10T14:56:25.732191: step 131, loss 0.643765, acc 0.78125')
(2, '2017-01-10T14:56:27.031937: step 132, loss 1.08455, acc 0.703125')
(2, '2017-01-10T14:56:28.371382: step 133, loss 0.670371, acc 0.78125')
(2, '2017-01-10T14:56:29.657160: step 134, loss 1.01058, acc 0.671875')
(2, '2017-01-10T14:56:31.047114: step 135, loss 1.13911, acc 0.625')
(2, '2017-01-10T14:56:32.676726: step 136, loss 0.678989, acc 0.78125')
(2, '2017-01-10T14:56:34.246764: step 137, loss 0.761439, acc 0.78125')
(2, '2017-01-10T14:56:35.658957: step 138, loss 1.11883, acc 0.59375')
(2, '2017-01-10T14:56:37.056331: step 139, loss 1.01002, acc 0.6875')
(2, '2017-01-10T14:56:38.613208: step 140, loss 0.842916, acc 0.6875')
(2, '2017-01-10T14:56:40.071941: step 141, loss 1.2125, acc 0.65625')
(2, '2017-01-10T14:56:41.509561: step 142, loss 0.762984, acc 0.734375')
(2, '2017-01-10T14:56:42.861966: step 143, loss 0.912408, acc 0.765625')
(2, '2017-01-10T14:56:44.277108: step 144, loss 1.12504, acc 0.640625')
(2, '2017-01-10T14:56:45.619032: step 145, loss 0.765524, acc 0.765625')
(2, '2017-01-10T14:56:46.966723: step 146, loss 0.775351, acc 0.75')
(2, '2017-01-10T14:56:48.384395: step 147, loss 0.815297, acc 0.71875')
(2, '2017-01-10T14:56:49.898029: step 148, loss 0.735186, acc 0.75')
(2, '2017-01-10T14:56:51.391529: step 149, loss 1.13098, acc 0.640625')
(2, '2017-01-10T14:56:52.719504: step 150, loss 0.94463, acc 0.734375')
(2, '2017-01-10T14:56:54.099205: step 151, loss 1.07404, acc 0.65625')
(2, '2017-01-10T14:56:55.448570: step 152, loss 0.999442, acc 0.640625')
(2, '2017-01-10T14:56:56.758968: step 153, loss 0.916561, acc 0.71875')
(2, '2017-01-10T14:56:58.154300: step 154, loss 0.557604, acc 0.8125')
(2, '2017-01-10T14:56:59.513386: step 155, loss 0.623264, acc 0.734375')
(2, '2017-01-10T14:57:00.888968: step 156, loss 0.437267, acc 0.859375')
(2, '2017-01-10T14:57:02.263016: step 157, loss 0.530475, acc 0.796875')
(2, '2017-01-10T14:57:03.594192: step 158, loss 0.587169, acc 0.71875')
(2, '2017-01-10T14:57:04.958576: step 159, loss 0.673421, acc 0.71875')
(2, '2017-01-10T14:57:06.289274: step 160, loss 0.650733, acc 0.78125')
(2, '2017-01-10T14:57:07.639181: step 161, loss 0.454655, acc 0.828125')
(2, '2017-01-10T14:57:08.964624: step 162, loss 0.611506, acc 0.78125')
(2, '2017-01-10T14:57:10.286943: step 163, loss 0.699309, acc 0.734375')
(2, '2017-01-10T14:57:11.671895: step 164, loss 1.07088, acc 0.734375')
(2, '2017-01-10T14:57:13.109884: step 165, loss 0.760637, acc 0.734375')
(2, '2017-01-10T14:57:14.483051: step 166, loss 0.448712, acc 0.796875')
(2, '2017-01-10T14:57:16.021850: step 167, loss 0.605662, acc 0.8125')
(2, '2017-01-10T14:57:17.354929: step 168, loss 0.672042, acc 0.765625')
(2, '2017-01-10T14:57:18.702261: step 169, loss 0.841761, acc 0.703125')
(2, '2017-01-10T14:57:20.031600: step 170, loss 0.582591, acc 0.734375')
(2, '2017-01-10T14:57:21.377147: step 171, loss 0.894191, acc 0.765625')
(2, '2017-01-10T14:57:22.670476: step 172, loss 0.532512, acc 0.765625')
(2, '2017-01-10T14:57:23.989478: step 173, loss 0.635709, acc 0.796875')
(2, '2017-01-10T14:57:25.321344: step 174, loss 1.00874, acc 0.703125')
(2, '2017-01-10T14:57:26.640974: step 175, loss 0.833119, acc 0.703125')
(2, '2017-01-10T14:57:27.954453: step 176, loss 0.616102, acc 0.8125')
(2, '2017-01-10T14:57:29.301565: step 177, loss 0.752053, acc 0.75')
(2, '2017-01-10T14:57:30.643703: step 178, loss 0.936353, acc 0.734375')
(2, '2017-01-10T14:57:32.026754: step 179, loss 0.836328, acc 0.765625')
(2, '2017-01-10T14:57:33.363787: step 180, loss 0.670002, acc 0.765625')
(2, '2017-01-10T14:57:34.696181: step 181, loss 0.736942, acc 0.71875')
(2, '2017-01-10T14:57:36.035301: step 182, loss 0.799631, acc 0.765625')
(2, '2017-01-10T14:57:37.356849: step 183, loss 0.574281, acc 0.84375')
(2, '2017-01-10T14:57:38.696505: step 184, loss 0.576525, acc 0.703125')
(2, '2017-01-10T14:57:40.010093: step 185, loss 0.653912, acc 0.6875')
(2, '2017-01-10T14:57:41.374122: step 186, loss 0.500771, acc 0.8125')
(2, '2017-01-10T14:57:42.735681: step 187, loss 0.510295, acc 0.796875')
(2, '2017-01-10T14:57:44.109488: step 188, loss 0.595153, acc 0.734375')
(2, '2017-01-10T14:57:45.460795: step 189, loss 0.479941, acc 0.84375')
(2, '2017-01-10T14:57:46.887788: step 190, loss 0.510487, acc 0.84375')
(2, '2017-01-10T14:57:48.257021: step 191, loss 0.954876, acc 0.71875')
(2, '2017-01-10T14:57:49.609922: step 192, loss 0.558763, acc 0.765625')
(2, '2017-01-10T14:57:50.963402: step 193, loss 0.442473, acc 0.828125')
(2, '2017-01-10T14:57:52.324934: step 194, loss 0.901082, acc 0.640625')
(2, '2017-01-10T14:57:53.643094: step 195, loss 0.578034, acc 0.828125')
(2, '2017-01-10T14:57:54.983901: step 196, loss 0.547968, acc 0.734375')
(2, '2017-01-10T14:57:56.341598: step 197, loss 0.793341, acc 0.71875')
(2, '2017-01-10T14:57:57.730813: step 198, loss 0.923352, acc 0.6875')
(2, '2017-01-10T14:57:59.079461: step 199, loss 0.536004, acc 0.78125')
(2, '2017-01-10T14:58:00.464210: step 200, loss 0.640156, acc 0.765625')

Evaluation:
(2, '2017-01-10T14:58:03.408863: step 200, loss 0.577848, acc 0.695')

(2, '2017-01-10T14:58:04.761288: step 201, loss 0.87514, acc 0.734375')
(2, '2017-01-10T14:58:06.099429: step 202, loss 0.426653, acc 0.859375')
(2, '2017-01-10T14:58:07.445454: step 203, loss 0.673698, acc 0.828125')
(2, '2017-01-10T14:58:08.753899: step 204, loss 0.669811, acc 0.78125')
(2, '2017-01-10T14:58:10.115836: step 205, loss 0.278914, acc 0.890625')
(2, '2017-01-10T14:58:11.471210: step 206, loss 0.873166, acc 0.671875')
(2, '2017-01-10T14:58:12.843277: step 207, loss 0.740586, acc 0.703125')
(2, '2017-01-10T14:58:14.148201: step 208, loss 0.54799, acc 0.78125')
(2, '2017-01-10T14:58:15.689643: step 209, loss 0.631136, acc 0.84375')
(2, '2017-01-10T14:58:17.035971: step 210, loss 0.466081, acc 0.828125')
(2, '2017-01-10T14:58:18.357262: step 211, loss 0.583656, acc 0.796875')
(2, '2017-01-10T14:58:19.711269: step 212, loss 0.326258, acc 0.921875')
(2, '2017-01-10T14:58:20.996284: step 213, loss 0.560878, acc 0.78125')
(2, '2017-01-10T14:58:22.320091: step 214, loss 0.526179, acc 0.71875')
(2, '2017-01-10T14:58:23.632881: step 215, loss 0.412028, acc 0.8125')
(2, '2017-01-10T14:58:24.946163: step 216, loss 0.426805, acc 0.859375')
(2, '2017-01-10T14:58:26.282610: step 217, loss 0.54528, acc 0.78125')
(2, '2017-01-10T14:58:27.622300: step 218, loss 0.710687, acc 0.6875')
(2, '2017-01-10T14:58:28.959758: step 219, loss 0.705434, acc 0.71875')
(2, '2017-01-10T14:58:30.382081: step 220, loss 0.72207, acc 0.75')
(2, '2017-01-10T14:58:31.813918: step 221, loss 0.527531, acc 0.75')
(2, '2017-01-10T14:58:33.186019: step 222, loss 0.48089, acc 0.84375')
(2, '2017-01-10T14:58:34.549810: step 223, loss 0.645692, acc 0.734375')
(2, '2017-01-10T14:58:35.880434: step 224, loss 0.629139, acc 0.765625')
(2, '2017-01-10T14:58:37.180967: step 225, loss 0.524639, acc 0.8125')
(2, '2017-01-10T14:58:38.485580: step 226, loss 0.59371, acc 0.75')
(2, '2017-01-10T14:58:39.882339: step 227, loss 0.372969, acc 0.84375')
(2, '2017-01-10T14:58:41.253034: step 228, loss 0.576345, acc 0.78125')
(2, '2017-01-10T14:58:42.660563: step 229, loss 0.425639, acc 0.828125')
(2, '2017-01-10T14:58:44.089620: step 230, loss 0.475261, acc 0.828125')
(2, '2017-01-10T14:58:45.512632: step 231, loss 0.276848, acc 0.90625')
(2, '2017-01-10T14:58:46.945429: step 232, loss 0.415274, acc 0.875')
(2, '2017-01-10T14:58:48.327809: step 233, loss 0.431936, acc 0.8125')
(2, '2017-01-10T14:58:49.692460: step 234, loss 0.387281, acc 0.890625')
(2, '2017-01-10T14:58:51.029329: step 235, loss 0.370184, acc 0.875')
(2, '2017-01-10T14:58:52.357302: step 236, loss 0.91497, acc 0.6875')
(2, '2017-01-10T14:58:53.679233: step 237, loss 0.530589, acc 0.8125')
(2, '2017-01-10T14:58:55.001551: step 238, loss 0.539472, acc 0.765625')
(2, '2017-01-10T14:58:56.318046: step 239, loss 0.805463, acc 0.75')
(2, '2017-01-10T14:58:57.700563: step 240, loss 0.583951, acc 0.796875')
(2, '2017-01-10T14:58:59.147085: step 241, loss 0.708166, acc 0.765625')
(2, '2017-01-10T14:59:00.786167: step 242, loss 0.605188, acc 0.78125')
(2, '2017-01-10T14:59:02.263894: step 243, loss 0.738104, acc 0.78125')
(2, '2017-01-10T14:59:03.677377: step 244, loss 0.848152, acc 0.765625')
(2, '2017-01-10T14:59:04.983608: step 245, loss 0.548461, acc 0.78125')
(2, '2017-01-10T14:59:06.272511: step 246, loss 0.436757, acc 0.828125')
(2, '2017-01-10T14:59:07.575730: step 247, loss 0.477097, acc 0.828125')
(2, '2017-01-10T14:59:08.951257: step 248, loss 0.569758, acc 0.78125')
(2, '2017-01-10T14:59:10.336437: step 249, loss 0.617817, acc 0.75')
(2, '2017-01-10T14:59:11.722053: step 250, loss 0.697351, acc 0.765625')
(2, '2017-01-10T14:59:13.053008: step 251, loss 0.399365, acc 0.84375')
(2, '2017-01-10T14:59:14.395987: step 252, loss 0.81567, acc 0.765625')
(2, '2017-01-10T14:59:15.899307: step 253, loss 0.358133, acc 0.84375')
(2, '2017-01-10T14:59:17.228321: step 254, loss 0.564754, acc 0.828125')
(2, '2017-01-10T14:59:18.559107: step 255, loss 0.349246, acc 0.890625')
(2, '2017-01-10T14:59:19.937617: step 256, loss 0.594875, acc 0.78125')
(2, '2017-01-10T14:59:21.284336: step 257, loss 0.488158, acc 0.78125')
(2, '2017-01-10T14:59:22.636937: step 258, loss 0.299291, acc 0.859375')
(2, '2017-01-10T14:59:23.934815: step 259, loss 0.603768, acc 0.75')
(2, '2017-01-10T14:59:25.265502: step 260, loss 0.386583, acc 0.828125')
(2, '2017-01-10T14:59:26.640300: step 261, loss 0.231306, acc 0.875')
(2, '2017-01-10T14:59:27.949933: step 262, loss 0.561649, acc 0.796875')
(2, '2017-01-10T14:59:29.286469: step 263, loss 0.585161, acc 0.796875')
(2, '2017-01-10T14:59:30.612010: step 264, loss 0.522894, acc 0.859375')
(2, '2017-01-10T14:59:31.920228: step 265, loss 0.670408, acc 0.734375')
(2, '2017-01-10T14:59:33.268293: step 266, loss 0.175733, acc 0.875')
(2, '2017-01-10T14:59:34.592885: step 267, loss 0.715759, acc 0.734375')
(2, '2017-01-10T14:59:35.918875: step 268, loss 0.637313, acc 0.828125')
(2, '2017-01-10T14:59:37.231388: step 269, loss 0.454299, acc 0.78125')
(2, '2017-01-10T14:59:38.547567: step 270, loss 0.706547, acc 0.734375')
(2, '2017-01-10T14:59:39.849352: step 271, loss 0.571454, acc 0.75')
(2, '2017-01-10T14:59:41.161343: step 272, loss 0.369786, acc 0.84375')
(2, '2017-01-10T14:59:42.510172: step 273, loss 0.666148, acc 0.75')
(2, '2017-01-10T14:59:43.820345: step 274, loss 0.479482, acc 0.796875')
(2, '2017-01-10T14:59:45.142146: step 275, loss 0.529464, acc 0.8125')
(2, '2017-01-10T14:59:46.484737: step 276, loss 0.411205, acc 0.84375')
(2, '2017-01-10T14:59:47.835725: step 277, loss 0.556647, acc 0.796875')
(2, '2017-01-10T14:59:49.123072: step 278, loss 0.449817, acc 0.859375')
(2, '2017-01-10T14:59:50.426523: step 279, loss 0.820025, acc 0.734375')
(2, '2017-01-10T14:59:51.782367: step 280, loss 0.558131, acc 0.796875')
(2, '2017-01-10T14:59:53.105816: step 281, loss 0.740378, acc 0.796875')
(2, '2017-01-10T14:59:54.454472: step 282, loss 0.297381, acc 0.875')
(2, '2017-01-10T14:59:55.785901: step 283, loss 0.27892, acc 0.90625')
(2, '2017-01-10T14:59:57.105891: step 284, loss 0.328794, acc 0.921875')
(2, '2017-01-10T14:59:58.418160: step 285, loss 0.614613, acc 0.71875')
(2, '2017-01-10T14:59:59.742747: step 286, loss 0.39958, acc 0.8125')
(2, '2017-01-10T15:00:01.102515: step 287, loss 0.649686, acc 0.75')
(2, '2017-01-10T15:00:02.424989: step 288, loss 0.30306, acc 0.84375')
(2, '2017-01-10T15:00:03.750792: step 289, loss 0.669432, acc 0.703125')
(2, '2017-01-10T15:00:05.044389: step 290, loss 0.486377, acc 0.859375')
(2, '2017-01-10T15:00:06.400817: step 291, loss 0.453069, acc 0.84375')
(2, '2017-01-10T15:00:07.792870: step 292, loss 0.630354, acc 0.71875')
(2, '2017-01-10T15:00:09.196718: step 293, loss 0.454625, acc 0.875')
(2, '2017-01-10T15:00:10.503096: step 294, loss 0.406211, acc 0.8125')
(2, '2017-01-10T15:00:11.826670: step 295, loss 0.305691, acc 0.890625')
(2, '2017-01-10T15:00:13.144393: step 296, loss 0.305053, acc 0.84375')
(2, '2017-01-10T15:00:14.442230: step 297, loss 0.599234, acc 0.828125')
(2, '2017-01-10T15:00:15.902500: step 298, loss 0.403309, acc 0.828125')
(2, '2017-01-10T15:00:17.226425: step 299, loss 0.466569, acc 0.828125')
(2, '2017-01-10T15:00:18.554489: step 300, loss 0.429389, acc 0.765625')

Evaluation:
(2, '2017-01-10T15:00:21.206258: step 300, loss 0.588862, acc 0.7175')

(2, '2017-01-10T15:00:22.569143: step 301, loss 0.429089, acc 0.8125')
(2, '2017-01-10T15:00:23.953176: step 302, loss 0.426884, acc 0.8125')
(2, '2017-01-10T15:00:25.292907: step 303, loss 0.358226, acc 0.875')
(2, '2017-01-10T15:00:26.617976: step 304, loss 0.291494, acc 0.890625')
(2, '2017-01-10T15:00:27.914508: step 305, loss 0.419522, acc 0.828125')
(2, '2017-01-10T15:00:29.222065: step 306, loss 0.334207, acc 0.890625')
(2, '2017-01-10T15:00:30.570173: step 307, loss 0.249395, acc 0.921875')
(2, '2017-01-10T15:00:31.899927: step 308, loss 0.517161, acc 0.8125')
(2, '2017-01-10T15:00:33.280820: step 309, loss 0.469151, acc 0.859375')
(2, '2017-01-10T15:00:34.649357: step 310, loss 0.282381, acc 0.859375')
(2, '2017-01-10T15:00:35.976180: step 311, loss 0.562367, acc 0.78125')
(2, '2017-01-10T15:00:37.258573: step 312, loss 0.591062, acc 0.78125')
(2, '2017-01-10T15:00:38.614525: step 313, loss 0.713381, acc 0.765625')
(2, '2017-01-10T15:00:40.010702: step 314, loss 0.3508, acc 0.875')
(2, '2017-01-10T15:00:41.352222: step 315, loss 0.581747, acc 0.78125')
(2, '2017-01-10T15:00:42.673453: step 316, loss 0.348159, acc 0.875')
(2, '2017-01-10T15:00:44.016661: step 317, loss 0.435926, acc 0.828125')
(2, '2017-01-10T15:00:45.323995: step 318, loss 0.252697, acc 0.890625')
(2, '2017-01-10T15:00:46.631379: step 319, loss 0.379033, acc 0.84375')
(2, '2017-01-10T15:00:47.918027: step 320, loss 0.543569, acc 0.75')
(2, '2017-01-10T15:00:49.294875: step 321, loss 0.230841, acc 0.90625')
(2, '2017-01-10T15:00:50.670522: step 322, loss 0.378429, acc 0.796875')
(2, '2017-01-10T15:00:52.047252: step 323, loss 0.266104, acc 0.875')
(2, '2017-01-10T15:00:53.436522: step 324, loss 0.449706, acc 0.859375')
(2, '2017-01-10T15:00:54.726412: step 325, loss 0.597827, acc 0.796875')
(2, '2017-01-10T15:00:56.011368: step 326, loss 0.455156, acc 0.84375')
(2, '2017-01-10T15:00:57.327603: step 327, loss 0.437234, acc 0.84375')
(2, '2017-01-10T15:00:58.647869: step 328, loss 0.278073, acc 0.890625')
(2, '2017-01-10T15:00:59.946041: step 329, loss 0.321439, acc 0.890625')
(2, '2017-01-10T15:01:01.296063: step 330, loss 0.331965, acc 0.890625')
(2, '2017-01-10T15:01:02.613860: step 331, loss 0.475943, acc 0.84375')
(2, '2017-01-10T15:01:03.951507: step 332, loss 0.360029, acc 0.890625')
(2, '2017-01-10T15:01:05.346501: step 333, loss 0.160493, acc 0.875')
(2, '2017-01-10T15:01:06.805334: step 334, loss 0.361693, acc 0.875')
(2, '2017-01-10T15:01:08.258782: step 335, loss 0.340994, acc 0.875')
(2, '2017-01-10T15:01:09.740914: step 336, loss 0.381027, acc 0.890625')
(2, '2017-01-10T15:01:11.196510: step 337, loss 0.382038, acc 0.84375')
(2, '2017-01-10T15:01:12.618601: step 338, loss 0.468444, acc 0.859375')
(2, '2017-01-10T15:01:14.032156: step 339, loss 0.479404, acc 0.765625')
(2, '2017-01-10T15:01:15.498675: step 340, loss 0.304839, acc 0.921875')
(2, '2017-01-10T15:01:16.830439: step 341, loss 0.285954, acc 0.859375')
(2, '2017-01-10T15:01:18.131985: step 342, loss 0.552884, acc 0.84375')
(2, '2017-01-10T15:01:19.493970: step 343, loss 0.326843, acc 0.875')
(2, '2017-01-10T15:01:20.889399: step 344, loss 0.280503, acc 0.859375')
(2, '2017-01-10T15:01:22.170305: step 345, loss 0.433157, acc 0.8125')
(2, '2017-01-10T15:01:23.559331: step 346, loss 0.400166, acc 0.859375')
(2, '2017-01-10T15:01:24.908864: step 347, loss 0.294586, acc 0.890625')
(2, '2017-01-10T15:01:26.580611: step 348, loss 0.295034, acc 0.84375')
(2, '2017-01-10T15:01:28.351395: step 349, loss 0.37867, acc 0.84375')
(2, '2017-01-10T15:01:30.006531: step 350, loss 0.406918, acc 0.828125')
(2, '2017-01-10T15:01:31.365935: step 351, loss 0.469464, acc 0.859375')
(2, '2017-01-10T15:01:32.732796: step 352, loss 0.172903, acc 0.9375')
(2, '2017-01-10T15:01:34.114392: step 353, loss 0.217088, acc 0.921875')
(2, '2017-01-10T15:01:35.520658: step 354, loss 0.32491, acc 0.859375')
(2, '2017-01-10T15:01:36.930358: step 355, loss 0.617986, acc 0.78125')
(2, '2017-01-10T15:01:38.303982: step 356, loss 0.501959, acc 0.8125')
(2, '2017-01-10T15:01:39.709430: step 357, loss 0.326557, acc 0.875')
(2, '2017-01-10T15:01:41.086473: step 358, loss 0.140081, acc 0.953125')
(2, '2017-01-10T15:01:42.464618: step 359, loss 0.506362, acc 0.828125')
(2, '2017-01-10T15:01:43.815782: step 360, loss 0.54149, acc 0.828125')
(2, '2017-01-10T15:01:45.377062: step 361, loss 0.329259, acc 0.859375')
(2, '2017-01-10T15:01:46.833877: step 362, loss 0.454006, acc 0.828125')
(2, '2017-01-10T15:01:48.223186: step 363, loss 0.329147, acc 0.84375')
(2, '2017-01-10T15:01:49.706269: step 364, loss 0.218662, acc 0.890625')
(2, '2017-01-10T15:01:51.065786: step 365, loss 0.40368, acc 0.875')
(2, '2017-01-10T15:01:52.442231: step 366, loss 0.333627, acc 0.859375')
(2, '2017-01-10T15:01:53.815885: step 367, loss 0.322643, acc 0.890625')
(2, '2017-01-10T15:01:55.242689: step 368, loss 0.346841, acc 0.828125')
(2, '2017-01-10T15:01:56.609231: step 369, loss 0.407694, acc 0.875')
(2, '2017-01-10T15:01:58.018026: step 370, loss 0.376639, acc 0.859375')
(2, '2017-01-10T15:01:59.351026: step 371, loss 0.29905, acc 0.84375')
(2, '2017-01-10T15:02:00.647966: step 372, loss 0.387358, acc 0.859375')
(2, '2017-01-10T15:02:02.010137: step 373, loss 0.654276, acc 0.78125')
(2, '2017-01-10T15:02:03.505101: step 374, loss 0.361719, acc 0.90625')
(2, '2017-01-10T15:02:04.918212: step 375, loss 0.249941, acc 0.921875')
(2, '2017-01-10T15:02:06.336068: step 376, loss 0.302139, acc 0.859375')
(2, '2017-01-10T15:02:07.755868: step 377, loss 0.254448, acc 0.90625')
(2, '2017-01-10T15:02:09.089572: step 378, loss 0.456556, acc 0.875')
(2, '2017-01-10T15:02:10.445653: step 379, loss 0.291916, acc 0.875')
(2, '2017-01-10T15:02:11.784167: step 380, loss 0.212413, acc 0.90625')
(2, '2017-01-10T15:02:13.146852: step 381, loss 0.357407, acc 0.890625')
(2, '2017-01-10T15:02:14.503120: step 382, loss 0.469467, acc 0.828125')
(2, '2017-01-10T15:02:16.024793: step 383, loss 0.236426, acc 0.90625')
(2, '2017-01-10T15:02:17.381101: step 384, loss 0.210814, acc 0.9375')
(2, '2017-01-10T15:02:18.711379: step 385, loss 0.215947, acc 0.90625')
(2, '2017-01-10T15:02:20.103288: step 386, loss 0.401924, acc 0.875')
(2, '2017-01-10T15:02:21.500733: step 387, loss 0.325737, acc 0.90625')
(2, '2017-01-10T15:02:22.846784: step 388, loss 0.292974, acc 0.859375')
(2, '2017-01-10T15:02:24.184278: step 389, loss 0.32737, acc 0.875')
(2, '2017-01-10T15:02:25.557562: step 390, loss 0.251719, acc 0.890625')
(2, '2017-01-10T15:02:26.939261: step 391, loss 0.27577, acc 0.875')
(2, '2017-01-10T15:02:28.377822: step 392, loss 0.19533, acc 0.90625')
(2, '2017-01-10T15:02:29.813434: step 393, loss 0.257266, acc 0.921875')
(2, '2017-01-10T15:02:31.178402: step 394, loss 0.336847, acc 0.859375')
(2, '2017-01-10T15:02:32.501224: step 395, loss 0.444517, acc 0.765625')
(2, '2017-01-10T15:02:33.810151: step 396, loss 0.243808, acc 0.9375')
(2, '2017-01-10T15:02:35.163681: step 397, loss 0.352457, acc 0.859375')
(2, '2017-01-10T15:02:36.499583: step 398, loss 0.24616, acc 0.921875')
(2, '2017-01-10T15:02:37.825485: step 399, loss 0.262068, acc 0.875')
(2, '2017-01-10T15:02:39.145272: step 400, loss 0.384931, acc 0.859375')

Evaluation:
(2, '2017-01-10T15:02:41.747150: step 400, loss 0.57221, acc 0.705')

(2, '2017-01-10T15:02:43.115826: step 401, loss 0.173612, acc 0.921875')
(2, '2017-01-10T15:02:44.474756: step 402, loss 0.439065, acc 0.859375')
(2, '2017-01-10T15:02:45.804365: step 403, loss 0.289598, acc 0.875')
(2, '2017-01-10T15:02:47.124496: step 404, loss 0.156898, acc 0.9375')
(2, '2017-01-10T15:02:48.469957: step 405, loss 0.31354, acc 0.875')
(2, '2017-01-10T15:02:49.796297: step 406, loss 0.361169, acc 0.859375')
(2, '2017-01-10T15:02:51.122248: step 407, loss 0.184947, acc 0.921875')
(2, '2017-01-10T15:02:52.435045: step 408, loss 0.271941, acc 0.890625')
(2, '2017-01-10T15:02:53.741281: step 409, loss 0.218846, acc 0.953125')
(2, '2017-01-10T15:02:55.068131: step 410, loss 0.34017, acc 0.859375')
(2, '2017-01-10T15:02:56.397968: step 411, loss 0.323186, acc 0.875')
(2, '2017-01-10T15:02:57.804492: step 412, loss 0.549698, acc 0.796875')
(2, '2017-01-10T15:02:59.159217: step 413, loss 0.214988, acc 0.90625')
(2, '2017-01-10T15:03:00.494254: step 414, loss 0.283537, acc 0.859375')
(2, '2017-01-10T15:03:01.818894: step 415, loss 0.285609, acc 0.875')
(2, '2017-01-10T15:03:03.146737: step 416, loss 0.226537, acc 0.921875')
(2, '2017-01-10T15:03:04.472678: step 417, loss 0.20392, acc 0.90625')
(2, '2017-01-10T15:03:05.813458: step 418, loss 0.516052, acc 0.828125')
(2, '2017-01-10T15:03:07.127059: step 419, loss 0.491807, acc 0.828125')
(2, '2017-01-10T15:03:08.456173: step 420, loss 0.246472, acc 0.90625')
(2, '2017-01-10T15:03:09.823221: step 421, loss 0.166537, acc 0.9375')
(2, '2017-01-10T15:03:11.111900: step 422, loss 0.252855, acc 0.890625')
(2, '2017-01-10T15:03:12.435176: step 423, loss 0.155099, acc 0.9375')
(2, '2017-01-10T15:03:13.773444: step 424, loss 0.337928, acc 0.84375')
(2, '2017-01-10T15:03:15.345164: step 425, loss 0.20965, acc 0.9375')
(2, '2017-01-10T15:03:16.759464: step 426, loss 0.178623, acc 0.9375')
(2, '2017-01-10T15:03:18.209936: step 427, loss 0.37673, acc 0.859375')
(2, '2017-01-10T15:03:19.621308: step 428, loss 0.176408, acc 0.9375')
(2, '2017-01-10T15:03:21.018551: step 429, loss 0.381685, acc 0.84375')
(2, '2017-01-10T15:03:22.401065: step 430, loss 0.354412, acc 0.875')
(2, '2017-01-10T15:03:23.770720: step 431, loss 0.321915, acc 0.890625')
(2, '2017-01-10T15:03:25.155270: step 432, loss 0.149009, acc 0.953125')
(2, '2017-01-10T15:03:26.477742: step 433, loss 0.253307, acc 0.90625')
(2, '2017-01-10T15:03:27.795176: step 434, loss 0.293684, acc 0.890625')
(2, '2017-01-10T15:03:29.112101: step 435, loss 0.228862, acc 0.90625')
(2, '2017-01-10T15:03:30.404143: step 436, loss 0.497465, acc 0.8125')
(2, '2017-01-10T15:03:31.760998: step 437, loss 0.271869, acc 0.90625')
(2, '2017-01-10T15:03:33.105910: step 438, loss 0.306369, acc 0.90625')
(2, '2017-01-10T15:03:34.407256: step 439, loss 0.26339, acc 0.90625')
(2, '2017-01-10T15:03:35.710491: step 440, loss 0.275517, acc 0.90625')
(2, '2017-01-10T15:03:37.062346: step 441, loss 0.115158, acc 0.9375')
(2, '2017-01-10T15:03:38.394642: step 442, loss 0.24615, acc 0.9375')
(2, '2017-01-10T15:03:39.712570: step 443, loss 0.260281, acc 0.921875')
(2, '2017-01-10T15:03:40.998839: step 444, loss 0.445153, acc 0.828125')
(2, '2017-01-10T15:03:42.401758: step 445, loss 0.422585, acc 0.90625')
(2, '2017-01-10T15:03:43.744687: step 446, loss 0.168755, acc 0.9375')
(2, '2017-01-10T15:03:45.082589: step 447, loss 0.162298, acc 0.9375')
(2, '2017-01-10T15:03:46.427570: step 448, loss 0.394895, acc 0.828125')
(2, '2017-01-10T15:03:47.784466: step 449, loss 0.21058, acc 0.921875')
(2, '2017-01-10T15:03:49.109960: step 450, loss 0.299419, acc 0.890625')
(2, '2017-01-10T15:03:50.439917: step 451, loss 0.361094, acc 0.84375')
(2, '2017-01-10T15:03:51.759830: step 452, loss 0.302922, acc 0.875')
(2, '2017-01-10T15:03:53.118334: step 453, loss 0.135547, acc 0.953125')
(2, '2017-01-10T15:03:54.436107: step 454, loss 0.166209, acc 0.921875')
(2, '2017-01-10T15:03:55.719355: step 455, loss 0.28872, acc 0.859375')
(2, '2017-01-10T15:03:57.023973: step 456, loss 0.185434, acc 0.953125')
(2, '2017-01-10T15:03:58.365362: step 457, loss 0.183028, acc 0.953125')
(2, '2017-01-10T15:03:59.688897: step 458, loss 0.19051, acc 0.9375')
(2, '2017-01-10T15:04:00.992305: step 459, loss 0.466357, acc 0.828125')
(2, '2017-01-10T15:04:02.302968: step 460, loss 0.204296, acc 0.953125')
(2, '2017-01-10T15:04:03.651371: step 461, loss 0.199954, acc 0.90625')
(2, '2017-01-10T15:04:04.970158: step 462, loss 0.223428, acc 0.890625')
(2, '2017-01-10T15:04:06.257173: step 463, loss 0.380766, acc 0.875')
(2, '2017-01-10T15:04:07.579222: step 464, loss 0.235714, acc 0.859375')
(2, '2017-01-10T15:04:08.905035: step 465, loss 0.0848696, acc 0.96875')
(2, '2017-01-10T15:04:10.192757: step 466, loss 0.279305, acc 0.890625')
(2, '2017-01-10T15:04:11.510943: step 467, loss 0.319805, acc 0.875')
(2, '2017-01-10T15:04:12.855319: step 468, loss 0.166197, acc 0.921875')
(2, '2017-01-10T15:04:14.197813: step 469, loss 0.17564, acc 0.921875')
(2, '2017-01-10T15:04:15.694527: step 470, loss 0.338836, acc 0.84375')
(2, '2017-01-10T15:04:17.015502: step 471, loss 0.173249, acc 0.953125')
(2, '2017-01-10T15:04:18.307273: step 472, loss 0.31837, acc 0.890625')
(2, '2017-01-10T15:04:19.679261: step 473, loss 0.265423, acc 0.890625')
(2, '2017-01-10T15:04:21.017307: step 474, loss 0.126683, acc 0.953125')
(2, '2017-01-10T15:04:22.337908: step 475, loss 0.158791, acc 0.953125')
(2, '2017-01-10T15:04:23.631212: step 476, loss 0.292085, acc 0.859375')
(2, '2017-01-10T15:04:25.063943: step 477, loss 0.13424, acc 0.953125')
(2, '2017-01-10T15:04:26.392457: step 478, loss 0.175814, acc 0.921875')
(2, '2017-01-10T15:04:27.733638: step 479, loss 0.195427, acc 0.953125')
(2, '2017-01-10T15:04:29.085171: step 480, loss 0.22424, acc 0.921875')
(2, '2017-01-10T15:04:30.460859: step 481, loss 0.242243, acc 0.890625')
(2, '2017-01-10T15:04:31.765557: step 482, loss 0.335143, acc 0.890625')
(2, '2017-01-10T15:04:33.110411: step 483, loss 0.283725, acc 0.90625')
(2, '2017-01-10T15:04:34.463946: step 484, loss 0.0836825, acc 0.96875')
(2, '2017-01-10T15:04:35.885215: step 485, loss 0.24459, acc 0.90625')
(2, '2017-01-10T15:04:37.258914: step 486, loss 0.237435, acc 0.921875')
(2, '2017-01-10T15:04:38.636712: step 487, loss 0.18114, acc 0.921875')
(2, '2017-01-10T15:04:39.998155: step 488, loss 0.269452, acc 0.875')
(2, '2017-01-10T15:04:41.401528: step 489, loss 0.170385, acc 0.9375')
(2, '2017-01-10T15:04:42.789487: step 490, loss 0.146054, acc 0.953125')
(2, '2017-01-10T15:04:44.192359: step 491, loss 0.192826, acc 0.921875')
(2, '2017-01-10T15:04:45.525134: step 492, loss 0.180955, acc 0.921875')
(2, '2017-01-10T15:04:46.964275: step 493, loss 0.291545, acc 0.890625')
(2, '2017-01-10T15:04:48.344520: step 494, loss 0.145724, acc 0.9375')
(2, '2017-01-10T15:04:49.663199: step 495, loss 0.164837, acc 0.90625')
(2, '2017-01-10T15:04:51.018615: step 496, loss 0.432946, acc 0.84375')
(2, '2017-01-10T15:04:52.386916: step 497, loss 0.32871, acc 0.890625')
(2, '2017-01-10T15:04:53.711791: step 498, loss 0.172513, acc 0.9375')
(2, '2017-01-10T15:04:55.081585: step 499, loss 0.331976, acc 0.84375')
(2, '2017-01-10T15:04:56.418435: step 500, loss 0.195322, acc 0.90625')

Evaluation:
(2, '2017-01-10T15:04:59.309756: step 500, loss 0.567757, acc 0.7125')

(2, '2017-01-10T15:05:02.916109: step 500, loss 0.567757, acc 0.7125')
Vocabulary Size: 14319
Train/Dev split: 1600/400
Writing to /Users/amrkoura/Documents/workspace/newYorkerChallenge/runs/1484057103

(3, '2017-01-10T15:05:05.315315: step 1, loss 2.67563, acc 0.4375')
(3, '2017-01-10T15:05:06.589873: step 2, loss 2.84414, acc 0.46875')
(3, '2017-01-10T15:05:07.914534: step 3, loss 2.4461, acc 0.46875')
(3, '2017-01-10T15:05:09.353870: step 4, loss 2.05367, acc 0.53125')
(3, '2017-01-10T15:05:10.796472: step 5, loss 2.17109, acc 0.609375')
(3, '2017-01-10T15:05:12.147381: step 6, loss 2.94174, acc 0.453125')
(3, '2017-01-10T15:05:13.492783: step 7, loss 2.41057, acc 0.484375')
(3, '2017-01-10T15:05:15.126911: step 8, loss 2.756, acc 0.453125')
(3, '2017-01-10T15:05:16.553843: step 9, loss 2.69952, acc 0.453125')
(3, '2017-01-10T15:05:17.893397: step 10, loss 2.08968, acc 0.5')
(3, '2017-01-10T15:05:19.339492: step 11, loss 3.10417, acc 0.515625')
(3, '2017-01-10T15:05:20.748073: step 12, loss 2.67013, acc 0.5')
(3, '2017-01-10T15:05:22.177431: step 13, loss 2.71991, acc 0.46875')
(3, '2017-01-10T15:05:23.527473: step 14, loss 3.27314, acc 0.40625')
(3, '2017-01-10T15:05:24.864780: step 15, loss 2.48039, acc 0.515625')
(3, '2017-01-10T15:05:26.237428: step 16, loss 2.26921, acc 0.390625')
(3, '2017-01-10T15:05:27.615287: step 17, loss 2.40052, acc 0.4375')
(3, '2017-01-10T15:05:28.984703: step 18, loss 2.32698, acc 0.390625')
(3, '2017-01-10T15:05:30.404481: step 19, loss 1.95728, acc 0.546875')
(3, '2017-01-10T15:05:31.744937: step 20, loss 1.87078, acc 0.5625')
(3, '2017-01-10T15:05:33.204255: step 21, loss 2.19955, acc 0.578125')
(3, '2017-01-10T15:05:34.596471: step 22, loss 1.88537, acc 0.515625')
(3, '2017-01-10T15:05:35.920267: step 23, loss 1.94521, acc 0.578125')
(3, '2017-01-10T15:05:37.206164: step 24, loss 2.27084, acc 0.546875')
(3, '2017-01-10T15:05:38.552963: step 25, loss 2.71889, acc 0.4375')
(3, '2017-01-10T15:05:39.908410: step 26, loss 1.88626, acc 0.59375')
(3, '2017-01-10T15:05:41.259164: step 27, loss 1.98929, acc 0.625')
(3, '2017-01-10T15:05:42.581418: step 28, loss 2.28326, acc 0.515625')
(3, '2017-01-10T15:05:43.917259: step 29, loss 1.1001, acc 0.765625')
(3, '2017-01-10T15:05:45.210091: step 30, loss 1.78171, acc 0.625')
(3, '2017-01-10T15:05:46.531130: step 31, loss 2.60445, acc 0.546875')
(3, '2017-01-10T15:05:47.838678: step 32, loss 1.17954, acc 0.703125')
(3, '2017-01-10T15:05:49.189903: step 33, loss 1.30918, acc 0.703125')
(3, '2017-01-10T15:05:50.530769: step 34, loss 1.32011, acc 0.6875')
(3, '2017-01-10T15:05:51.900069: step 35, loss 1.7241, acc 0.5625')
(3, '2017-01-10T15:05:53.204356: step 36, loss 1.29902, acc 0.578125')
(3, '2017-01-10T15:05:54.531466: step 37, loss 2.00576, acc 0.546875')
(3, '2017-01-10T15:05:55.850844: step 38, loss 1.43272, acc 0.609375')
(3, '2017-01-10T15:05:57.129520: step 39, loss 1.59118, acc 0.59375')
(3, '2017-01-10T15:05:58.454677: step 40, loss 1.83277, acc 0.53125')
(3, '2017-01-10T15:05:59.776881: step 41, loss 2.47891, acc 0.484375')
(3, '2017-01-10T15:06:01.117626: step 42, loss 2.02709, acc 0.578125')
(3, '2017-01-10T15:06:02.477468: step 43, loss 1.86693, acc 0.546875')
(3, '2017-01-10T15:06:03.865793: step 44, loss 1.78654, acc 0.59375')
(3, '2017-01-10T15:06:05.195041: step 45, loss 1.61656, acc 0.625')
(3, '2017-01-10T15:06:06.483875: step 46, loss 1.85128, acc 0.53125')
(3, '2017-01-10T15:06:07.850863: step 47, loss 1.7603, acc 0.578125')
(3, '2017-01-10T15:06:09.211495: step 48, loss 2.096, acc 0.5')
(3, '2017-01-10T15:06:10.502243: step 49, loss 2.40485, acc 0.59375')
(3, '2017-01-10T15:06:11.867925: step 50, loss 1.44664, acc 0.625')
(3, '2017-01-10T15:06:13.258349: step 51, loss 1.08635, acc 0.71875')
(3, '2017-01-10T15:06:14.997955: step 52, loss 1.89122, acc 0.609375')
(3, '2017-01-10T15:06:16.566584: step 53, loss 1.58879, acc 0.625')
(3, '2017-01-10T15:06:17.936153: step 54, loss 1.60972, acc 0.65625')
(3, '2017-01-10T15:06:19.260848: step 55, loss 1.76245, acc 0.5')
(3, '2017-01-10T15:06:20.618576: step 56, loss 1.64045, acc 0.609375')
(3, '2017-01-10T15:06:21.980374: step 57, loss 1.12905, acc 0.65625')
(3, '2017-01-10T15:06:23.323224: step 58, loss 0.970695, acc 0.71875')
(3, '2017-01-10T15:06:24.682296: step 59, loss 1.05218, acc 0.703125')
(3, '2017-01-10T15:06:26.000808: step 60, loss 2.12721, acc 0.5')
(3, '2017-01-10T15:06:27.376521: step 61, loss 1.53489, acc 0.640625')
(3, '2017-01-10T15:06:28.715007: step 62, loss 1.08668, acc 0.71875')
(3, '2017-01-10T15:06:30.050789: step 63, loss 2.14186, acc 0.515625')
(3, '2017-01-10T15:06:31.387811: step 64, loss 1.26405, acc 0.59375')
(3, '2017-01-10T15:06:32.743794: step 65, loss 1.38048, acc 0.640625')
(3, '2017-01-10T15:06:34.079427: step 66, loss 1.27153, acc 0.65625')
(3, '2017-01-10T15:06:35.419986: step 67, loss 1.01732, acc 0.6875')
(3, '2017-01-10T15:06:36.759177: step 68, loss 1.91957, acc 0.609375')
(3, '2017-01-10T15:06:38.059862: step 69, loss 1.47334, acc 0.515625')
(3, '2017-01-10T15:06:39.424497: step 70, loss 1.8571, acc 0.609375')
(3, '2017-01-10T15:06:40.823865: step 71, loss 0.986681, acc 0.671875')
(3, '2017-01-10T15:06:42.173873: step 72, loss 1.44873, acc 0.609375')
(3, '2017-01-10T15:06:43.570443: step 73, loss 1.68872, acc 0.59375')
(3, '2017-01-10T15:06:44.937303: step 74, loss 1.80695, acc 0.546875')
(3, '2017-01-10T15:06:46.311436: step 75, loss 1.55787, acc 0.59375')
(3, '2017-01-10T15:06:47.640506: step 76, loss 1.87453, acc 0.625')
(3, '2017-01-10T15:06:49.000012: step 77, loss 0.983758, acc 0.734375')
(3, '2017-01-10T15:06:50.327028: step 78, loss 1.47725, acc 0.609375')
(3, '2017-01-10T15:06:51.641035: step 79, loss 1.18836, acc 0.71875')
(3, '2017-01-10T15:06:52.933867: step 80, loss 1.37669, acc 0.640625')
(3, '2017-01-10T15:06:54.259367: step 81, loss 0.960753, acc 0.65625')
(3, '2017-01-10T15:06:55.611913: step 82, loss 1.26605, acc 0.671875')
(3, '2017-01-10T15:06:56.959310: step 83, loss 1.52206, acc 0.578125')
(3, '2017-01-10T15:06:58.483169: step 84, loss 1.00069, acc 0.71875')
(3, '2017-01-10T15:07:00.097869: step 85, loss 1.19135, acc 0.71875')
(3, '2017-01-10T15:07:01.512269: step 86, loss 1.2108, acc 0.625')
(3, '2017-01-10T15:07:02.839527: step 87, loss 1.77846, acc 0.59375')
(3, '2017-01-10T15:07:04.173172: step 88, loss 1.13701, acc 0.65625')
(3, '2017-01-10T15:07:05.561527: step 89, loss 1.39499, acc 0.59375')
(3, '2017-01-10T15:07:06.858997: step 90, loss 1.38715, acc 0.71875')
(3, '2017-01-10T15:07:08.185694: step 91, loss 0.825168, acc 0.71875')
(3, '2017-01-10T15:07:09.531221: step 92, loss 1.43462, acc 0.671875')
(3, '2017-01-10T15:07:10.897437: step 93, loss 1.46241, acc 0.640625')
(3, '2017-01-10T15:07:12.235064: step 94, loss 1.1774, acc 0.640625')
(3, '2017-01-10T15:07:13.586670: step 95, loss 1.33147, acc 0.609375')
(3, '2017-01-10T15:07:15.013165: step 96, loss 1.10689, acc 0.6875')
(3, '2017-01-10T15:07:16.360730: step 97, loss 1.02593, acc 0.671875')
(3, '2017-01-10T15:07:17.681412: step 98, loss 1.23906, acc 0.625')
(3, '2017-01-10T15:07:19.007316: step 99, loss 1.26263, acc 0.578125')
(3, '2017-01-10T15:07:20.339979: step 100, loss 1.25122, acc 0.625')

Evaluation:
(3, '2017-01-10T15:07:22.955226: step 100, loss 0.609409, acc 0.6675')

(3, '2017-01-10T15:07:24.249175: step 101, loss 0.963455, acc 0.71875')
(3, '2017-01-10T15:07:25.577517: step 102, loss 1.08256, acc 0.703125')
(3, '2017-01-10T15:07:26.938725: step 103, loss 0.909357, acc 0.703125')
(3, '2017-01-10T15:07:28.270997: step 104, loss 0.838318, acc 0.78125')
(3, '2017-01-10T15:07:29.612365: step 105, loss 1.01264, acc 0.765625')
(3, '2017-01-10T15:07:30.911329: step 106, loss 1.21629, acc 0.609375')
(3, '2017-01-10T15:07:32.279574: step 107, loss 1.14207, acc 0.671875')
(3, '2017-01-10T15:07:33.605473: step 108, loss 0.924929, acc 0.625')
(3, '2017-01-10T15:07:34.924108: step 109, loss 0.993143, acc 0.71875')
(3, '2017-01-10T15:07:36.222855: step 110, loss 0.637693, acc 0.8125')
(3, '2017-01-10T15:07:37.594932: step 111, loss 1.06245, acc 0.671875')
(3, '2017-01-10T15:07:38.919563: step 112, loss 1.09566, acc 0.703125')
(3, '2017-01-10T15:07:40.249137: step 113, loss 0.745419, acc 0.734375')
(3, '2017-01-10T15:07:41.567810: step 114, loss 1.04998, acc 0.671875')
(3, '2017-01-10T15:07:42.896234: step 115, loss 1.27973, acc 0.59375')
(3, '2017-01-10T15:07:44.182083: step 116, loss 1.3055, acc 0.65625')
(3, '2017-01-10T15:07:45.542194: step 117, loss 1.40374, acc 0.640625')
(3, '2017-01-10T15:07:46.871562: step 118, loss 0.977601, acc 0.734375')
(3, '2017-01-10T15:07:48.176366: step 119, loss 0.769393, acc 0.765625')
(3, '2017-01-10T15:07:49.545321: step 120, loss 1.01901, acc 0.671875')
(3, '2017-01-10T15:07:50.878118: step 121, loss 1.031, acc 0.703125')
(3, '2017-01-10T15:07:52.196934: step 122, loss 0.626648, acc 0.734375')
(3, '2017-01-10T15:07:53.497854: step 123, loss 0.814066, acc 0.75')
(3, '2017-01-10T15:07:54.814551: step 124, loss 0.760962, acc 0.703125')
(3, '2017-01-10T15:07:56.176727: step 125, loss 0.784777, acc 0.75')
(3, '2017-01-10T15:07:57.531763: step 126, loss 0.9666, acc 0.671875')
(3, '2017-01-10T15:07:58.881740: step 127, loss 0.823919, acc 0.75')
(3, '2017-01-10T15:08:00.205369: step 128, loss 0.638289, acc 0.765625')
(3, '2017-01-10T15:08:01.515019: step 129, loss 0.491693, acc 0.78125')
(3, '2017-01-10T15:08:02.844098: step 130, loss 1.06414, acc 0.71875')
(3, '2017-01-10T15:08:04.123345: step 131, loss 0.63541, acc 0.78125')
(3, '2017-01-10T15:08:05.494051: step 132, loss 0.674049, acc 0.796875')
(3, '2017-01-10T15:08:06.861261: step 133, loss 0.792703, acc 0.765625')
(3, '2017-01-10T15:08:08.216625: step 134, loss 1.12371, acc 0.671875')
(3, '2017-01-10T15:08:09.546018: step 135, loss 1.22246, acc 0.734375')
(3, '2017-01-10T15:08:10.862557: step 136, loss 0.926308, acc 0.78125')
(3, '2017-01-10T15:08:12.173938: step 137, loss 0.749147, acc 0.78125')
(3, '2017-01-10T15:08:13.507412: step 138, loss 0.6127, acc 0.75')
(3, '2017-01-10T15:08:14.944076: step 139, loss 0.578913, acc 0.78125')
(3, '2017-01-10T15:08:16.322575: step 140, loss 0.675834, acc 0.765625')
(3, '2017-01-10T15:08:17.648844: step 141, loss 0.886209, acc 0.765625')
(3, '2017-01-10T15:08:18.985184: step 142, loss 0.94727, acc 0.734375')
(3, '2017-01-10T15:08:20.339249: step 143, loss 0.860475, acc 0.703125')
(3, '2017-01-10T15:08:21.656740: step 144, loss 0.913498, acc 0.703125')
(3, '2017-01-10T15:08:22.978211: step 145, loss 0.553539, acc 0.8125')
(3, '2017-01-10T15:08:24.318363: step 146, loss 0.836247, acc 0.734375')
(3, '2017-01-10T15:08:25.635872: step 147, loss 0.827699, acc 0.703125')
(3, '2017-01-10T15:08:26.964294: step 148, loss 0.839437, acc 0.765625')
(3, '2017-01-10T15:08:28.296933: step 149, loss 0.705647, acc 0.78125')
(3, '2017-01-10T15:08:29.603078: step 150, loss 1.09938, acc 0.65625')
(3, '2017-01-10T15:08:30.926441: step 151, loss 0.792173, acc 0.6875')
(3, '2017-01-10T15:08:32.245358: step 152, loss 0.759134, acc 0.765625')
(3, '2017-01-10T15:08:33.536629: step 153, loss 0.7812, acc 0.6875')
(3, '2017-01-10T15:08:34.830759: step 154, loss 1.03033, acc 0.703125')
(3, '2017-01-10T15:08:36.168791: step 155, loss 0.693428, acc 0.796875')
(3, '2017-01-10T15:08:37.487851: step 156, loss 0.821417, acc 0.75')
(3, '2017-01-10T15:08:38.801038: step 157, loss 0.782398, acc 0.703125')
(3, '2017-01-10T15:08:40.118157: step 158, loss 0.709602, acc 0.703125')
(3, '2017-01-10T15:08:41.414442: step 159, loss 0.929575, acc 0.71875')
(3, '2017-01-10T15:08:42.740706: step 160, loss 0.591517, acc 0.828125')
(3, '2017-01-10T15:08:44.050570: step 161, loss 1.11648, acc 0.640625')
(3, '2017-01-10T15:08:45.375090: step 162, loss 0.972101, acc 0.6875')
(3, '2017-01-10T15:08:46.708687: step 163, loss 0.962934, acc 0.75')
(3, '2017-01-10T15:08:47.993138: step 164, loss 0.639786, acc 0.796875')
(3, '2017-01-10T15:08:49.283150: step 165, loss 1.2134, acc 0.59375')
(3, '2017-01-10T15:08:50.613359: step 166, loss 0.813254, acc 0.765625')
(3, '2017-01-10T15:08:51.935927: step 167, loss 0.780434, acc 0.703125')
(3, '2017-01-10T15:08:53.297150: step 168, loss 0.983028, acc 0.65625')
(3, '2017-01-10T15:08:54.674158: step 169, loss 0.885445, acc 0.65625')
(3, '2017-01-10T15:08:56.019184: step 170, loss 0.844081, acc 0.765625')
(3, '2017-01-10T15:08:57.306712: step 171, loss 0.975244, acc 0.6875')
(3, '2017-01-10T15:08:58.628652: step 172, loss 0.998883, acc 0.640625')
(3, '2017-01-10T15:08:59.960307: step 173, loss 0.714787, acc 0.71875')
(3, '2017-01-10T15:09:01.258344: step 174, loss 0.948452, acc 0.703125')
(3, '2017-01-10T15:09:02.549179: step 175, loss 0.841014, acc 0.765625')
(3, '2017-01-10T15:09:03.899627: step 176, loss 0.773243, acc 0.75')
(3, '2017-01-10T15:09:05.219729: step 177, loss 0.665076, acc 0.765625')
(3, '2017-01-10T15:09:06.515331: step 178, loss 0.497954, acc 0.828125')
(3, '2017-01-10T15:09:07.811707: step 179, loss 0.727103, acc 0.78125')
(3, '2017-01-10T15:09:09.121955: step 180, loss 0.674843, acc 0.75')
(3, '2017-01-10T15:09:10.445449: step 181, loss 0.992434, acc 0.65625')
(3, '2017-01-10T15:09:11.740042: step 182, loss 0.631255, acc 0.765625')
(3, '2017-01-10T15:09:13.057131: step 183, loss 0.940393, acc 0.703125')
(3, '2017-01-10T15:09:14.414908: step 184, loss 0.778119, acc 0.78125')
(3, '2017-01-10T15:09:15.876258: step 185, loss 0.512374, acc 0.796875')
(3, '2017-01-10T15:09:17.215825: step 186, loss 1.07133, acc 0.65625')
(3, '2017-01-10T15:09:18.541893: step 187, loss 0.708566, acc 0.734375')
(3, '2017-01-10T15:09:19.815131: step 188, loss 0.449905, acc 0.828125')
(3, '2017-01-10T15:09:21.137410: step 189, loss 0.617071, acc 0.78125')
(3, '2017-01-10T15:09:22.462539: step 190, loss 0.596264, acc 0.78125')
(3, '2017-01-10T15:09:23.785116: step 191, loss 0.592765, acc 0.828125')
(3, '2017-01-10T15:09:25.106906: step 192, loss 0.440033, acc 0.859375')
(3, '2017-01-10T15:09:26.453841: step 193, loss 0.44125, acc 0.84375')
(3, '2017-01-10T15:09:27.778222: step 194, loss 0.919968, acc 0.671875')
(3, '2017-01-10T15:09:29.099587: step 195, loss 0.60381, acc 0.78125')
(3, '2017-01-10T15:09:30.399583: step 196, loss 0.579177, acc 0.734375')
(3, '2017-01-10T15:09:31.719891: step 197, loss 0.894459, acc 0.734375')
(3, '2017-01-10T15:09:33.042896: step 198, loss 0.566112, acc 0.796875')
(3, '2017-01-10T15:09:34.375735: step 199, loss 0.677447, acc 0.75')
(3, '2017-01-10T15:09:35.743486: step 200, loss 0.453085, acc 0.765625')

Evaluation:
(3, '2017-01-10T15:09:38.443571: step 200, loss 0.547625, acc 0.72')

(3, '2017-01-10T15:09:39.791301: step 201, loss 0.342673, acc 0.875')
(3, '2017-01-10T15:09:41.178202: step 202, loss 0.395725, acc 0.8125')
(3, '2017-01-10T15:09:42.496101: step 203, loss 0.628234, acc 0.828125')
(3, '2017-01-10T15:09:43.856500: step 204, loss 0.343082, acc 0.859375')
(3, '2017-01-10T15:09:45.196233: step 205, loss 0.581649, acc 0.8125')
(3, '2017-01-10T15:09:46.643854: step 206, loss 0.486656, acc 0.84375')
(3, '2017-01-10T15:09:48.292965: step 207, loss 0.611528, acc 0.75')
(3, '2017-01-10T15:09:49.744693: step 208, loss 0.445135, acc 0.828125')
(3, '2017-01-10T15:09:51.096974: step 209, loss 0.49342, acc 0.8125')
(3, '2017-01-10T15:09:52.446812: step 210, loss 0.59193, acc 0.78125')
(3, '2017-01-10T15:09:53.762961: step 211, loss 0.625162, acc 0.734375')
(3, '2017-01-10T15:09:55.105087: step 212, loss 0.359515, acc 0.8125')
(3, '2017-01-10T15:09:56.408710: step 213, loss 0.342586, acc 0.828125')
(3, '2017-01-10T15:09:57.786730: step 214, loss 0.378088, acc 0.84375')
(3, '2017-01-10T15:09:59.111631: step 215, loss 0.585239, acc 0.78125')
(3, '2017-01-10T15:10:00.411540: step 216, loss 0.591757, acc 0.75')
(3, '2017-01-10T15:10:01.733432: step 217, loss 0.457392, acc 0.796875')
(3, '2017-01-10T15:10:03.019885: step 218, loss 0.623585, acc 0.796875')
(3, '2017-01-10T15:10:04.364453: step 219, loss 0.731858, acc 0.734375')
(3, '2017-01-10T15:10:05.730657: step 220, loss 0.900366, acc 0.6875')
(3, '2017-01-10T15:10:07.053100: step 221, loss 0.65138, acc 0.734375')
(3, '2017-01-10T15:10:08.453103: step 222, loss 0.412733, acc 0.796875')
(3, '2017-01-10T15:10:09.789881: step 223, loss 0.495319, acc 0.8125')
(3, '2017-01-10T15:10:11.191397: step 224, loss 0.812948, acc 0.734375')
(3, '2017-01-10T15:10:12.617817: step 225, loss 0.826815, acc 0.6875')
(3, '2017-01-10T15:10:13.983111: step 226, loss 0.495058, acc 0.8125')
(3, '2017-01-10T15:10:15.518283: step 227, loss 0.480042, acc 0.78125')
(3, '2017-01-10T15:10:16.993370: step 228, loss 0.419058, acc 0.890625')
(3, '2017-01-10T15:10:18.332518: step 229, loss 0.540212, acc 0.84375')
(3, '2017-01-10T15:10:19.725488: step 230, loss 0.263528, acc 0.875')
(3, '2017-01-10T15:10:21.138947: step 231, loss 0.434568, acc 0.8125')
(3, '2017-01-10T15:10:22.435033: step 232, loss 0.446955, acc 0.875')
(3, '2017-01-10T15:10:23.759809: step 233, loss 0.417401, acc 0.84375')
(3, '2017-01-10T15:10:25.079437: step 234, loss 0.586889, acc 0.78125')
(3, '2017-01-10T15:10:26.364461: step 235, loss 0.527122, acc 0.796875')
(3, '2017-01-10T15:10:27.725673: step 236, loss 0.564981, acc 0.828125')
(3, '2017-01-10T15:10:29.066017: step 237, loss 0.306028, acc 0.890625')
(3, '2017-01-10T15:10:30.434532: step 238, loss 0.551399, acc 0.765625')
(3, '2017-01-10T15:10:31.725776: step 239, loss 0.488353, acc 0.828125')
(3, '2017-01-10T15:10:33.049335: step 240, loss 0.698863, acc 0.6875')
(3, '2017-01-10T15:10:34.371885: step 241, loss 0.290793, acc 0.90625')
(3, '2017-01-10T15:10:35.649020: step 242, loss 0.492598, acc 0.796875')
(3, '2017-01-10T15:10:36.949290: step 243, loss 0.587675, acc 0.828125')
(3, '2017-01-10T15:10:38.296789: step 244, loss 0.534226, acc 0.78125')
(3, '2017-01-10T15:10:39.619540: step 245, loss 0.533241, acc 0.78125')
(3, '2017-01-10T15:10:40.900640: step 246, loss 0.744478, acc 0.765625')
(3, '2017-01-10T15:10:42.403213: step 247, loss 0.526905, acc 0.75')
(3, '2017-01-10T15:10:44.029891: step 248, loss 0.660808, acc 0.859375')
(3, '2017-01-10T15:10:45.388569: step 249, loss 0.653416, acc 0.78125')
(3, '2017-01-10T15:10:46.699085: step 250, loss 0.436944, acc 0.828125')
(3, '2017-01-10T15:10:48.012403: step 251, loss 0.317958, acc 0.859375')
(3, '2017-01-10T15:10:49.362593: step 252, loss 0.469571, acc 0.78125')
(3, '2017-01-10T15:10:50.713498: step 253, loss 0.517805, acc 0.78125')
(3, '2017-01-10T15:10:52.092132: step 254, loss 0.509398, acc 0.75')
(3, '2017-01-10T15:10:53.428577: step 255, loss 0.477085, acc 0.8125')
(3, '2017-01-10T15:10:54.776214: step 256, loss 0.493251, acc 0.78125')
(3, '2017-01-10T15:10:56.106236: step 257, loss 0.942756, acc 0.71875')
(3, '2017-01-10T15:10:57.433818: step 258, loss 0.357004, acc 0.84375')
(3, '2017-01-10T15:10:58.761953: step 259, loss 0.51478, acc 0.859375')
(3, '2017-01-10T15:11:00.095584: step 260, loss 0.354265, acc 0.84375')
(3, '2017-01-10T15:11:01.447848: step 261, loss 0.640582, acc 0.796875')
(3, '2017-01-10T15:11:02.765173: step 262, loss 0.388784, acc 0.875')
(3, '2017-01-10T15:11:04.050236: step 263, loss 0.659435, acc 0.703125')
(3, '2017-01-10T15:11:05.366303: step 264, loss 0.279394, acc 0.921875')
(3, '2017-01-10T15:11:06.656270: step 265, loss 0.313107, acc 0.890625')
(3, '2017-01-10T15:11:07.977149: step 266, loss 0.517675, acc 0.8125')
(3, '2017-01-10T15:11:09.325865: step 267, loss 0.524982, acc 0.78125')
(3, '2017-01-10T15:11:10.614634: step 268, loss 0.611898, acc 0.78125')
(3, '2017-01-10T15:11:11.933758: step 269, loss 0.466422, acc 0.859375')
(3, '2017-01-10T15:11:13.252643: step 270, loss 0.824922, acc 0.75')
(3, '2017-01-10T15:11:14.548130: step 271, loss 0.25241, acc 0.9375')
(3, '2017-01-10T15:11:16.054846: step 272, loss 0.831617, acc 0.734375')
(3, '2017-01-10T15:11:17.374435: step 273, loss 0.50184, acc 0.828125')
(3, '2017-01-10T15:11:18.667410: step 274, loss 0.621101, acc 0.765625')
(3, '2017-01-10T15:11:20.015323: step 275, loss 0.755798, acc 0.765625')
(3, '2017-01-10T15:11:21.342302: step 276, loss 0.551932, acc 0.8125')
(3, '2017-01-10T15:11:22.661203: step 277, loss 0.566654, acc 0.796875')
(3, '2017-01-10T15:11:23.986280: step 278, loss 0.428611, acc 0.828125')
(3, '2017-01-10T15:11:25.304586: step 279, loss 0.502, acc 0.828125')
(3, '2017-01-10T15:11:26.627098: step 280, loss 0.399233, acc 0.8125')
(3, '2017-01-10T15:11:27.951678: step 281, loss 0.215148, acc 0.90625')
(3, '2017-01-10T15:11:29.256984: step 282, loss 0.864932, acc 0.6875')
(3, '2017-01-10T15:11:30.603801: step 283, loss 0.364607, acc 0.859375')
(3, '2017-01-10T15:11:31.947386: step 284, loss 0.446482, acc 0.8125')
(3, '2017-01-10T15:11:33.266543: step 285, loss 0.346217, acc 0.875')
(3, '2017-01-10T15:11:34.565959: step 286, loss 0.351051, acc 0.90625')
(3, '2017-01-10T15:11:35.893963: step 287, loss 0.525939, acc 0.828125')
(3, '2017-01-10T15:11:37.172705: step 288, loss 0.874076, acc 0.71875')
(3, '2017-01-10T15:11:38.489699: step 289, loss 0.472324, acc 0.828125')
(3, '2017-01-10T15:11:39.808463: step 290, loss 0.345903, acc 0.859375')
(3, '2017-01-10T15:11:41.160787: step 291, loss 0.36279, acc 0.828125')
(3, '2017-01-10T15:11:42.450641: step 292, loss 0.466701, acc 0.875')
(3, '2017-01-10T15:11:43.792671: step 293, loss 0.394553, acc 0.796875')
(3, '2017-01-10T15:11:45.096701: step 294, loss 0.55789, acc 0.75')
(3, '2017-01-10T15:11:46.414381: step 295, loss 0.529088, acc 0.828125')
(3, '2017-01-10T15:11:47.736389: step 296, loss 0.47517, acc 0.765625')
(3, '2017-01-10T15:11:49.099943: step 297, loss 0.408794, acc 0.8125')
(3, '2017-01-10T15:11:50.441252: step 298, loss 0.363979, acc 0.8125')
(3, '2017-01-10T15:11:51.768962: step 299, loss 0.284871, acc 0.90625')
(3, '2017-01-10T15:11:53.091765: step 300, loss 0.281869, acc 0.875')

Evaluation:
(3, '2017-01-10T15:11:56.053933: step 300, loss 0.528667, acc 0.7375')

(3, '2017-01-10T15:11:57.333516: step 301, loss 0.332187, acc 0.828125')
(3, '2017-01-10T15:11:58.655943: step 302, loss 0.378992, acc 0.90625')
(3, '2017-01-10T15:12:00.011729: step 303, loss 0.22519, acc 0.921875')
(3, '2017-01-10T15:12:01.369129: step 304, loss 0.349925, acc 0.828125')
(3, '2017-01-10T15:12:02.688783: step 305, loss 0.374397, acc 0.875')
(3, '2017-01-10T15:12:03.982857: step 306, loss 0.207406, acc 0.921875')
(3, '2017-01-10T15:12:05.318427: step 307, loss 0.29546, acc 0.890625')
(3, '2017-01-10T15:12:06.642841: step 308, loss 0.41417, acc 0.828125')
(3, '2017-01-10T15:12:07.971902: step 309, loss 0.425871, acc 0.84375')
(3, '2017-01-10T15:12:09.291802: step 310, loss 0.467241, acc 0.84375')
(3, '2017-01-10T15:12:10.614651: step 311, loss 0.27167, acc 0.90625')
(3, '2017-01-10T15:12:11.936334: step 312, loss 0.254148, acc 0.90625')
(3, '2017-01-10T15:12:13.265650: step 313, loss 0.330993, acc 0.875')
(3, '2017-01-10T15:12:14.562877: step 314, loss 0.503502, acc 0.84375')
(3, '2017-01-10T15:12:16.060590: step 315, loss 0.505013, acc 0.8125')
(3, '2017-01-10T15:12:17.389164: step 316, loss 0.31619, acc 0.875')
(3, '2017-01-10T15:12:18.733554: step 317, loss 0.478721, acc 0.890625')
(3, '2017-01-10T15:12:20.056347: step 318, loss 0.356598, acc 0.859375')
(3, '2017-01-10T15:12:21.341118: step 319, loss 0.432095, acc 0.859375')
(3, '2017-01-10T15:12:22.659642: step 320, loss 0.498552, acc 0.859375')
(3, '2017-01-10T15:12:23.986798: step 321, loss 0.456164, acc 0.8125')
(3, '2017-01-10T15:12:25.312457: step 322, loss 0.516422, acc 0.796875')
(3, '2017-01-10T15:12:26.656965: step 323, loss 0.275972, acc 0.875')
(3, '2017-01-10T15:12:27.989111: step 324, loss 0.170536, acc 0.90625')
(3, '2017-01-10T15:12:29.313144: step 325, loss 0.338853, acc 0.890625')
(3, '2017-01-10T15:12:30.618605: step 326, loss 0.264542, acc 0.890625')
(3, '2017-01-10T15:12:31.966302: step 327, loss 0.282392, acc 0.890625')
(3, '2017-01-10T15:12:33.287005: step 328, loss 0.435341, acc 0.859375')
(3, '2017-01-10T15:12:34.578895: step 329, loss 0.498643, acc 0.78125')
(3, '2017-01-10T15:12:35.900342: step 330, loss 0.426153, acc 0.875')
(3, '2017-01-10T15:12:37.237838: step 331, loss 0.24049, acc 0.90625')
(3, '2017-01-10T15:12:38.553631: step 332, loss 0.294093, acc 0.890625')
(3, '2017-01-10T15:12:39.876695: step 333, loss 0.356437, acc 0.859375')
(3, '2017-01-10T15:12:41.200534: step 334, loss 0.29771, acc 0.90625')
(3, '2017-01-10T15:12:42.524115: step 335, loss 0.198194, acc 0.921875')
(3, '2017-01-10T15:12:43.844354: step 336, loss 0.511916, acc 0.75')
(3, '2017-01-10T15:12:45.186547: step 337, loss 0.613827, acc 0.75')
(3, '2017-01-10T15:12:46.507568: step 338, loss 0.340473, acc 0.890625')
(3, '2017-01-10T15:12:47.800284: step 339, loss 0.321625, acc 0.828125')
(3, '2017-01-10T15:12:49.123760: step 340, loss 0.434543, acc 0.828125')
(3, '2017-01-10T15:12:50.445096: step 341, loss 0.389461, acc 0.8125')
(3, '2017-01-10T15:12:51.770614: step 342, loss 0.249596, acc 0.921875')
(3, '2017-01-10T15:12:53.044986: step 343, loss 0.366496, acc 0.828125')
(3, '2017-01-10T15:12:54.359584: step 344, loss 0.29095, acc 0.859375')
(3, '2017-01-10T15:12:55.718217: step 345, loss 0.500781, acc 0.8125')
(3, '2017-01-10T15:12:57.022977: step 346, loss 0.431941, acc 0.84375')
(3, '2017-01-10T15:12:58.353881: step 347, loss 0.352577, acc 0.828125')
(3, '2017-01-10T15:12:59.669573: step 348, loss 0.557022, acc 0.75')
(3, '2017-01-10T15:13:00.982491: step 349, loss 0.486256, acc 0.796875')
(3, '2017-01-10T15:13:02.312292: step 350, loss 0.424386, acc 0.875')
(3, '2017-01-10T15:13:03.664214: step 351, loss 0.434953, acc 0.828125')
(3, '2017-01-10T15:13:04.950359: step 352, loss 0.359463, acc 0.859375')
(3, '2017-01-10T15:13:06.294985: step 353, loss 0.511224, acc 0.84375')
(3, '2017-01-10T15:13:07.617044: step 354, loss 0.444769, acc 0.8125')
(3, '2017-01-10T15:13:08.933902: step 355, loss 0.426789, acc 0.859375')
(3, '2017-01-10T15:13:10.268663: step 356, loss 0.377061, acc 0.828125')
(3, '2017-01-10T15:13:11.548325: step 357, loss 0.457515, acc 0.765625')
(3, '2017-01-10T15:13:12.873277: step 358, loss 0.354324, acc 0.890625')
(3, '2017-01-10T15:13:14.200424: step 359, loss 0.409738, acc 0.84375')
(3, '2017-01-10T15:13:15.695994: step 360, loss 0.499042, acc 0.828125')
(3, '2017-01-10T15:13:17.048003: step 361, loss 0.334983, acc 0.890625')
(3, '2017-01-10T15:13:18.371336: step 362, loss 0.307548, acc 0.921875')
(3, '2017-01-10T15:13:19.657888: step 363, loss 0.468802, acc 0.78125')
(3, '2017-01-10T15:13:20.971986: step 364, loss 0.282764, acc 0.890625')
(3, '2017-01-10T15:13:22.288933: step 365, loss 0.410968, acc 0.828125')
(3, '2017-01-10T15:13:23.617209: step 366, loss 0.252644, acc 0.890625')
(3, '2017-01-10T15:13:24.929961: step 367, loss 0.502027, acc 0.828125')
(3, '2017-01-10T15:13:26.257442: step 368, loss 0.339685, acc 0.875')
(3, '2017-01-10T15:13:27.592697: step 369, loss 0.439191, acc 0.84375')
(3, '2017-01-10T15:13:28.913650: step 370, loss 0.516184, acc 0.75')
(3, '2017-01-10T15:13:30.237060: step 371, loss 0.442014, acc 0.8125')
(3, '2017-01-10T15:13:31.553048: step 372, loss 0.379505, acc 0.859375')
(3, '2017-01-10T15:13:32.835510: step 373, loss 0.465908, acc 0.796875')
(3, '2017-01-10T15:13:34.139010: step 374, loss 0.464961, acc 0.796875')
(3, '2017-01-10T15:13:35.465500: step 375, loss 0.251068, acc 0.90625')
(3, '2017-01-10T15:13:36.790615: step 376, loss 0.343078, acc 0.859375')
(3, '2017-01-10T15:13:38.133166: step 377, loss 0.197235, acc 0.9375')
(3, '2017-01-10T15:13:39.459743: step 378, loss 0.467851, acc 0.875')
(3, '2017-01-10T15:13:40.751189: step 379, loss 0.313056, acc 0.84375')
(3, '2017-01-10T15:13:42.077981: step 380, loss 0.0921539, acc 0.984375')
(3, '2017-01-10T15:13:43.361938: step 381, loss 0.143073, acc 0.90625')
(3, '2017-01-10T15:13:44.673189: step 382, loss 0.416291, acc 0.890625')
(3, '2017-01-10T15:13:45.992083: step 383, loss 0.25721, acc 0.875')
(3, '2017-01-10T15:13:47.321500: step 384, loss 0.456917, acc 0.828125')
(3, '2017-01-10T15:13:48.684018: step 385, loss 0.43498, acc 0.8125')
(3, '2017-01-10T15:13:50.024169: step 386, loss 0.403068, acc 0.859375')
(3, '2017-01-10T15:13:51.348733: step 387, loss 0.248997, acc 0.90625')
(3, '2017-01-10T15:13:52.632510: step 388, loss 0.434314, acc 0.859375')
(3, '2017-01-10T15:13:53.963603: step 389, loss 0.340288, acc 0.875')
(3, '2017-01-10T15:13:55.292891: step 390, loss 0.281702, acc 0.828125')
(3, '2017-01-10T15:13:56.618658: step 391, loss 0.146218, acc 0.921875')
(3, '2017-01-10T15:13:57.927092: step 392, loss 0.363427, acc 0.859375')
(3, '2017-01-10T15:13:59.273289: step 393, loss 0.422306, acc 0.875')
(3, '2017-01-10T15:14:00.613104: step 394, loss 0.227459, acc 0.890625')
(3, '2017-01-10T15:14:01.941252: step 395, loss 0.152218, acc 0.9375')
(3, '2017-01-10T15:14:03.221735: step 396, loss 0.240907, acc 0.921875')
(3, '2017-01-10T15:14:04.544133: step 397, loss 0.381652, acc 0.875')
(3, '2017-01-10T15:14:05.833960: step 398, loss 0.200863, acc 0.90625')
(3, '2017-01-10T15:14:07.152457: step 399, loss 0.20986, acc 0.921875')
(3, '2017-01-10T15:14:08.492280: step 400, loss 0.246385, acc 0.890625')

Evaluation:
(3, '2017-01-10T15:14:11.098311: step 400, loss 0.553944, acc 0.7225')

(3, '2017-01-10T15:14:12.436630: step 401, loss 0.204101, acc 0.921875')
(3, '2017-01-10T15:14:13.772162: step 402, loss 0.405204, acc 0.84375')
(3, '2017-01-10T15:14:15.265818: step 403, loss 0.200586, acc 0.90625')
(3, '2017-01-10T15:14:16.588526: step 404, loss 0.293347, acc 0.875')
(3, '2017-01-10T15:14:17.932481: step 405, loss 0.425309, acc 0.875')
(3, '2017-01-10T15:14:19.261948: step 406, loss 0.230386, acc 0.90625')
(3, '2017-01-10T15:14:20.579343: step 407, loss 0.389146, acc 0.859375')
(3, '2017-01-10T15:14:21.879564: step 408, loss 0.158849, acc 0.9375')
(3, '2017-01-10T15:14:23.211184: step 409, loss 0.321829, acc 0.84375')
(3, '2017-01-10T15:14:24.494552: step 410, loss 0.250597, acc 0.90625')
(3, '2017-01-10T15:14:25.815437: step 411, loss 0.226562, acc 0.890625')
(3, '2017-01-10T15:14:27.134452: step 412, loss 0.172097, acc 0.921875')
(3, '2017-01-10T15:14:28.444300: step 413, loss 0.326876, acc 0.890625')
(3, '2017-01-10T15:14:29.777390: step 414, loss 0.301124, acc 0.84375')
(3, '2017-01-10T15:14:31.112918: step 415, loss 0.315151, acc 0.859375')
(3, '2017-01-10T15:14:32.402817: step 416, loss 0.32174, acc 0.828125')
(3, '2017-01-10T15:14:33.719850: step 417, loss 0.443545, acc 0.84375')
(3, '2017-01-10T15:14:35.032638: step 418, loss 0.237825, acc 0.9375')
(3, '2017-01-10T15:14:36.353045: step 419, loss 0.233793, acc 0.90625')
(3, '2017-01-10T15:14:37.674403: step 420, loss 0.291776, acc 0.875')
(3, '2017-01-10T15:14:38.991733: step 421, loss 0.248721, acc 0.875')
(3, '2017-01-10T15:14:40.301908: step 422, loss 0.276944, acc 0.875')
(3, '2017-01-10T15:14:41.601166: step 423, loss 0.18362, acc 0.9375')
(3, '2017-01-10T15:14:42.920482: step 424, loss 0.29205, acc 0.875')
(3, '2017-01-10T15:14:44.242704: step 425, loss 0.207841, acc 0.90625')
(3, '2017-01-10T15:14:45.538763: step 426, loss 0.297463, acc 0.859375')
(3, '2017-01-10T15:14:46.891645: step 427, loss 0.355933, acc 0.828125')
(3, '2017-01-10T15:14:48.220501: step 428, loss 0.171853, acc 0.9375')
(3, '2017-01-10T15:14:49.506193: step 429, loss 0.202312, acc 0.875')
(3, '2017-01-10T15:14:50.806746: step 430, loss 0.385907, acc 0.828125')
(3, '2017-01-10T15:14:52.122939: step 431, loss 0.320536, acc 0.890625')
(3, '2017-01-10T15:14:53.445391: step 432, loss 0.212597, acc 0.890625')
(3, '2017-01-10T15:14:54.740875: step 433, loss 0.440982, acc 0.859375')
(3, '2017-01-10T15:14:56.043375: step 434, loss 0.167962, acc 0.953125')
(3, '2017-01-10T15:14:57.404724: step 435, loss 0.347765, acc 0.875')
(3, '2017-01-10T15:14:58.724406: step 436, loss 0.413516, acc 0.875')
(3, '2017-01-10T15:15:00.012465: step 437, loss 0.251508, acc 0.875')
(3, '2017-01-10T15:15:01.357444: step 438, loss 0.129035, acc 0.984375')
(3, '2017-01-10T15:15:02.689681: step 439, loss 0.310623, acc 0.890625')
(3, '2017-01-10T15:15:03.982154: step 440, loss 0.304439, acc 0.890625')
(3, '2017-01-10T15:15:05.301765: step 441, loss 0.179533, acc 0.9375')
(3, '2017-01-10T15:15:06.601300: step 442, loss 0.243348, acc 0.953125')
(3, '2017-01-10T15:15:07.925715: step 443, loss 0.265301, acc 0.875')
(3, '2017-01-10T15:15:09.253798: step 444, loss 0.13768, acc 0.90625')
(3, '2017-01-10T15:15:10.579401: step 445, loss 0.292256, acc 0.890625')
(3, '2017-01-10T15:15:11.897084: step 446, loss 0.465903, acc 0.84375')
(3, '2017-01-10T15:15:13.188429: step 447, loss 0.308816, acc 0.859375')
(3, '2017-01-10T15:15:14.489350: step 448, loss 0.259496, acc 0.890625')
(3, '2017-01-10T15:15:15.983569: step 449, loss 0.153967, acc 0.953125')
(3, '2017-01-10T15:15:17.346817: step 450, loss 0.185483, acc 0.90625')
(3, '2017-01-10T15:15:18.707520: step 451, loss 0.302585, acc 0.84375')
(3, '2017-01-10T15:15:20.069389: step 452, loss 0.342431, acc 0.90625')
(3, '2017-01-10T15:15:21.348484: step 453, loss 0.260396, acc 0.875')
(3, '2017-01-10T15:15:22.654986: step 454, loss 0.470293, acc 0.84375')
(3, '2017-01-10T15:15:23.975494: step 455, loss 0.188007, acc 0.90625')
(3, '2017-01-10T15:15:25.276811: step 456, loss 0.236912, acc 0.90625')
(3, '2017-01-10T15:15:26.569914: step 457, loss 0.345372, acc 0.828125')
(3, '2017-01-10T15:15:27.903608: step 458, loss 0.209215, acc 0.90625')
(3, '2017-01-10T15:15:29.263370: step 459, loss 0.218523, acc 0.90625')
(3, '2017-01-10T15:15:30.559901: step 460, loss 0.211461, acc 0.890625')
(3, '2017-01-10T15:15:31.872310: step 461, loss 0.20724, acc 0.90625')
(3, '2017-01-10T15:15:33.229852: step 462, loss 0.287982, acc 0.875')
(3, '2017-01-10T15:15:34.536269: step 463, loss 0.412946, acc 0.8125')
(3, '2017-01-10T15:15:35.855601: step 464, loss 0.264656, acc 0.890625')
(3, '2017-01-10T15:15:37.161794: step 465, loss 0.138322, acc 0.953125')
(3, '2017-01-10T15:15:38.498238: step 466, loss 0.345884, acc 0.84375')
(3, '2017-01-10T15:15:39.832011: step 467, loss 0.175369, acc 0.9375')
(3, '2017-01-10T15:15:41.217200: step 468, loss 0.196413, acc 0.921875')
(3, '2017-01-10T15:15:42.569327: step 469, loss 0.324695, acc 0.875')
(3, '2017-01-10T15:15:43.907367: step 470, loss 0.0956011, acc 0.984375')
(3, '2017-01-10T15:15:45.205981: step 471, loss 0.315305, acc 0.875')
(3, '2017-01-10T15:15:46.546744: step 472, loss 0.292503, acc 0.90625')
(3, '2017-01-10T15:15:47.882987: step 473, loss 0.183266, acc 0.921875')
(3, '2017-01-10T15:15:49.217078: step 474, loss 0.194238, acc 0.859375')
(3, '2017-01-10T15:15:50.596608: step 475, loss 0.148639, acc 0.9375')
(3, '2017-01-10T15:15:51.926541: step 476, loss 0.49582, acc 0.84375')
(3, '2017-01-10T15:15:53.210097: step 477, loss 0.193684, acc 0.921875')
(3, '2017-01-10T15:15:54.505986: step 478, loss 0.365607, acc 0.875')
(3, '2017-01-10T15:15:55.837763: step 479, loss 0.178388, acc 0.9375')
(3, '2017-01-10T15:15:57.154332: step 480, loss 0.197072, acc 0.953125')
(3, '2017-01-10T15:15:58.465662: step 481, loss 0.294285, acc 0.890625')
(3, '2017-01-10T15:15:59.783064: step 482, loss 0.377786, acc 0.8125')
(3, '2017-01-10T15:16:01.140227: step 483, loss 0.309768, acc 0.875')
(3, '2017-01-10T15:16:02.454618: step 484, loss 0.342787, acc 0.859375')
(3, '2017-01-10T15:16:03.752329: step 485, loss 0.223078, acc 0.9375')
(3, '2017-01-10T15:16:05.082887: step 486, loss 0.308173, acc 0.859375')
(3, '2017-01-10T15:16:06.369633: step 487, loss 0.397229, acc 0.84375')
(3, '2017-01-10T15:16:07.692507: step 488, loss 0.340818, acc 0.859375')
(3, '2017-01-10T15:16:09.008552: step 489, loss 0.360815, acc 0.890625')
(3, '2017-01-10T15:16:10.306210: step 490, loss 0.268214, acc 0.890625')
(3, '2017-01-10T15:16:11.642608: step 491, loss 0.237648, acc 0.875')
(3, '2017-01-10T15:16:12.962613: step 492, loss 0.146444, acc 0.9375')
(3, '2017-01-10T15:16:14.255113: step 493, loss 0.182793, acc 0.90625')
(3, '2017-01-10T15:16:15.731821: step 494, loss 0.148808, acc 0.953125')
(3, '2017-01-10T15:16:17.016128: step 495, loss 0.225541, acc 0.90625')
(3, '2017-01-10T15:16:18.359860: step 496, loss 0.340378, acc 0.875')
(3, '2017-01-10T15:16:19.645680: step 497, loss 0.199116, acc 0.9375')
(3, '2017-01-10T15:16:20.943959: step 498, loss 0.260711, acc 0.90625')
(3, '2017-01-10T15:16:22.299311: step 499, loss 0.256217, acc 0.875')
(3, '2017-01-10T15:16:23.619163: step 500, loss 0.270035, acc 0.890625')

Evaluation:
(3, '2017-01-10T15:16:26.229915: step 500, loss 0.511797, acc 0.7475')

(3, '2017-01-10T15:16:29.400034: step 500, loss 0.511797, acc 0.7475')
Vocabulary Size: 14319
Train/Dev split: 1600/400
Writing to /Users/amrkoura/Documents/workspace/newYorkerChallenge/runs/1484057789

(4, '2017-01-10T15:16:31.722725: step 1, loss 2.55923, acc 0.578125')
(4, '2017-01-10T15:16:33.019953: step 2, loss 2.63781, acc 0.453125')
(4, '2017-01-10T15:16:34.311245: step 3, loss 2.98995, acc 0.46875')
(4, '2017-01-10T15:16:35.659885: step 4, loss 2.31178, acc 0.546875')
(4, '2017-01-10T15:16:37.003193: step 5, loss 3.0208, acc 0.484375')
(4, '2017-01-10T15:16:38.311528: step 6, loss 3.10636, acc 0.453125')
(4, '2017-01-10T15:16:39.654006: step 7, loss 2.33905, acc 0.484375')
(4, '2017-01-10T15:16:40.989301: step 8, loss 2.20252, acc 0.53125')
(4, '2017-01-10T15:16:42.279934: step 9, loss 2.21836, acc 0.5625')
(4, '2017-01-10T15:16:43.613557: step 10, loss 2.53386, acc 0.421875')
(4, '2017-01-10T15:16:44.933495: step 11, loss 2.57959, acc 0.515625')
(4, '2017-01-10T15:16:46.265196: step 12, loss 2.54672, acc 0.515625')
(4, '2017-01-10T15:16:47.547022: step 13, loss 2.70577, acc 0.546875')
(4, '2017-01-10T15:16:48.860536: step 14, loss 2.71115, acc 0.546875')
(4, '2017-01-10T15:16:50.200218: step 15, loss 2.20229, acc 0.59375')
(4, '2017-01-10T15:16:51.508719: step 16, loss 2.3355, acc 0.453125')
(4, '2017-01-10T15:16:52.818622: step 17, loss 2.01522, acc 0.578125')
(4, '2017-01-10T15:16:54.140489: step 18, loss 1.89881, acc 0.546875')
(4, '2017-01-10T15:16:55.457863: step 19, loss 3.16885, acc 0.46875')
(4, '2017-01-10T15:16:56.734828: step 20, loss 3.19921, acc 0.4375')
(4, '2017-01-10T15:16:58.060949: step 21, loss 2.61957, acc 0.59375')
(4, '2017-01-10T15:16:59.396107: step 22, loss 2.33609, acc 0.546875')
(4, '2017-01-10T15:17:00.731539: step 23, loss 2.95482, acc 0.484375')
(4, '2017-01-10T15:17:02.032525: step 24, loss 2.66179, acc 0.421875')
(4, '2017-01-10T15:17:03.328643: step 25, loss 2.2626, acc 0.390625')
(4, '2017-01-10T15:17:04.662703: step 26, loss 1.37291, acc 0.578125')
(4, '2017-01-10T15:17:05.958866: step 27, loss 2.01329, acc 0.5625')
(4, '2017-01-10T15:17:07.252664: step 28, loss 2.09117, acc 0.578125')
(4, '2017-01-10T15:17:08.581458: step 29, loss 2.01969, acc 0.578125')
(4, '2017-01-10T15:17:09.948952: step 30, loss 1.92361, acc 0.578125')
(4, '2017-01-10T15:17:11.248244: step 31, loss 1.19552, acc 0.65625')
(4, '2017-01-10T15:17:12.567330: step 32, loss 1.92633, acc 0.5')
(4, '2017-01-10T15:17:13.891486: step 33, loss 1.82767, acc 0.5625')
(4, '2017-01-10T15:17:15.358753: step 34, loss 2.07473, acc 0.625')
(4, '2017-01-10T15:17:16.685499: step 35, loss 1.60938, acc 0.609375')
(4, '2017-01-10T15:17:18.027952: step 36, loss 2.58652, acc 0.5')
(4, '2017-01-10T15:17:19.320411: step 37, loss 1.50991, acc 0.609375')
(4, '2017-01-10T15:17:20.695659: step 38, loss 1.71226, acc 0.609375')
(4, '2017-01-10T15:17:22.012807: step 39, loss 2.16104, acc 0.515625')
(4, '2017-01-10T15:17:23.338077: step 40, loss 1.46675, acc 0.625')
(4, '2017-01-10T15:17:24.619874: step 41, loss 2.11068, acc 0.5625')
(4, '2017-01-10T15:17:25.930686: step 42, loss 2.05527, acc 0.453125')
(4, '2017-01-10T15:17:27.245494: step 43, loss 1.64501, acc 0.609375')
(4, '2017-01-10T15:17:28.586576: step 44, loss 2.16618, acc 0.5')
(4, '2017-01-10T15:17:29.902349: step 45, loss 1.43518, acc 0.640625')
(4, '2017-01-10T15:17:31.270428: step 46, loss 1.99346, acc 0.640625')
(4, '2017-01-10T15:17:32.563243: step 47, loss 1.64969, acc 0.515625')
(4, '2017-01-10T15:17:33.883597: step 48, loss 1.46218, acc 0.578125')
(4, '2017-01-10T15:17:35.174323: step 49, loss 1.63298, acc 0.65625')
(4, '2017-01-10T15:17:36.495473: step 50, loss 1.48317, acc 0.609375')
(4, '2017-01-10T15:17:37.774254: step 51, loss 1.53012, acc 0.578125')
(4, '2017-01-10T15:17:39.104876: step 52, loss 1.098, acc 0.671875')
(4, '2017-01-10T15:17:40.430329: step 53, loss 1.35335, acc 0.578125')
(4, '2017-01-10T15:17:41.790630: step 54, loss 1.08741, acc 0.65625')
(4, '2017-01-10T15:17:43.080944: step 55, loss 1.07094, acc 0.671875')
(4, '2017-01-10T15:17:44.388971: step 56, loss 1.59968, acc 0.546875')
(4, '2017-01-10T15:17:45.718712: step 57, loss 1.83639, acc 0.5625')
(4, '2017-01-10T15:17:47.017828: step 58, loss 1.62544, acc 0.625')
(4, '2017-01-10T15:17:48.330287: step 59, loss 1.11261, acc 0.640625')
(4, '2017-01-10T15:17:49.688365: step 60, loss 2.08228, acc 0.59375')
(4, '2017-01-10T15:17:51.033883: step 61, loss 1.56672, acc 0.640625')
(4, '2017-01-10T15:17:52.358959: step 62, loss 1.79381, acc 0.515625')
(4, '2017-01-10T15:17:53.687005: step 63, loss 1.43898, acc 0.515625')
(4, '2017-01-10T15:17:55.005159: step 64, loss 1.38189, acc 0.625')
(4, '2017-01-10T15:17:56.294523: step 65, loss 1.85963, acc 0.578125')
(4, '2017-01-10T15:17:57.627101: step 66, loss 1.32032, acc 0.671875')
(4, '2017-01-10T15:17:58.928904: step 67, loss 1.47385, acc 0.609375')
(4, '2017-01-10T15:18:00.225075: step 68, loss 1.28973, acc 0.625')
(4, '2017-01-10T15:18:01.567659: step 69, loss 1.52699, acc 0.609375')
(4, '2017-01-10T15:18:02.869166: step 70, loss 1.11465, acc 0.6875')
(4, '2017-01-10T15:18:04.211338: step 71, loss 1.0817, acc 0.734375')
(4, '2017-01-10T15:18:05.498357: step 72, loss 1.04602, acc 0.6875')
(4, '2017-01-10T15:18:06.817072: step 73, loss 1.60371, acc 0.671875')
(4, '2017-01-10T15:18:08.123706: step 74, loss 1.51348, acc 0.609375')
(4, '2017-01-10T15:18:09.440159: step 75, loss 1.31914, acc 0.671875')
(4, '2017-01-10T15:18:10.763952: step 76, loss 1.3524, acc 0.65625')
(4, '2017-01-10T15:18:12.082002: step 77, loss 1.3536, acc 0.671875')
(4, '2017-01-10T15:18:13.411634: step 78, loss 1.27279, acc 0.65625')
(4, '2017-01-10T15:18:14.785586: step 79, loss 0.95822, acc 0.640625')
(4, '2017-01-10T15:18:16.175971: step 80, loss 1.11795, acc 0.703125')
(4, '2017-01-10T15:18:17.509481: step 81, loss 1.08805, acc 0.71875')
(4, '2017-01-10T15:18:18.800835: step 82, loss 1.51657, acc 0.640625')
(4, '2017-01-10T15:18:20.123687: step 83, loss 1.09858, acc 0.671875')
(4, '2017-01-10T15:18:21.427393: step 84, loss 0.997064, acc 0.6875')
(4, '2017-01-10T15:18:22.753881: step 85, loss 1.42107, acc 0.59375')
(4, '2017-01-10T15:18:24.081011: step 86, loss 0.972231, acc 0.734375')
(4, '2017-01-10T15:18:25.413095: step 87, loss 1.23828, acc 0.625')
(4, '2017-01-10T15:18:26.698215: step 88, loss 1.78567, acc 0.640625')
(4, '2017-01-10T15:18:28.013979: step 89, loss 0.914408, acc 0.78125')
(4, '2017-01-10T15:18:29.358448: step 90, loss 1.01616, acc 0.609375')
(4, '2017-01-10T15:18:30.659621: step 91, loss 1.24497, acc 0.65625')
(4, '2017-01-10T15:18:31.969995: step 92, loss 1.73531, acc 0.53125')
(4, '2017-01-10T15:18:33.336345: step 93, loss 1.60658, acc 0.59375')
(4, '2017-01-10T15:18:34.629047: step 94, loss 1.25982, acc 0.671875')
(4, '2017-01-10T15:18:35.917704: step 95, loss 0.952584, acc 0.703125')
(4, '2017-01-10T15:18:37.243432: step 96, loss 1.41873, acc 0.640625')
(4, '2017-01-10T15:18:38.540041: step 97, loss 1.4143, acc 0.59375')
(4, '2017-01-10T15:18:39.866699: step 98, loss 1.60971, acc 0.609375')
(4, '2017-01-10T15:18:41.160327: step 99, loss 1.35064, acc 0.625')
(4, '2017-01-10T15:18:42.482230: step 100, loss 1.08095, acc 0.65625')

Evaluation:
(4, '2017-01-10T15:18:45.110503: step 100, loss 0.75677, acc 0.605')

(4, '2017-01-10T15:18:46.439404: step 101, loss 1.01743, acc 0.703125')
(4, '2017-01-10T15:18:47.727747: step 102, loss 1.23041, acc 0.703125')
(4, '2017-01-10T15:18:49.053194: step 103, loss 1.09543, acc 0.6875')
(4, '2017-01-10T15:18:50.337401: step 104, loss 1.3038, acc 0.625')
(4, '2017-01-10T15:18:51.664185: step 105, loss 0.9489, acc 0.71875')
(4, '2017-01-10T15:18:52.958385: step 106, loss 1.19434, acc 0.703125')
(4, '2017-01-10T15:18:54.310910: step 107, loss 1.41791, acc 0.640625')
(4, '2017-01-10T15:18:55.601451: step 108, loss 1.14507, acc 0.71875')
(4, '2017-01-10T15:18:56.897283: step 109, loss 0.773892, acc 0.765625')
(4, '2017-01-10T15:18:58.240949: step 110, loss 1.53852, acc 0.625')
(4, '2017-01-10T15:18:59.537284: step 111, loss 1.24884, acc 0.640625')
(4, '2017-01-10T15:19:00.827761: step 112, loss 1.20247, acc 0.6875')
(4, '2017-01-10T15:19:02.152931: step 113, loss 0.863371, acc 0.703125')
(4, '2017-01-10T15:19:03.474221: step 114, loss 0.686883, acc 0.765625')
(4, '2017-01-10T15:19:04.786027: step 115, loss 1.15289, acc 0.578125')
(4, '2017-01-10T15:19:06.090934: step 116, loss 1.23111, acc 0.640625')
(4, '2017-01-10T15:19:07.434668: step 117, loss 0.880414, acc 0.734375')
(4, '2017-01-10T15:19:08.730807: step 118, loss 0.870709, acc 0.71875')
(4, '2017-01-10T15:19:10.036369: step 119, loss 0.97142, acc 0.65625')
(4, '2017-01-10T15:19:11.357438: step 120, loss 1.25067, acc 0.703125')
(4, '2017-01-10T15:19:12.692085: step 121, loss 0.893673, acc 0.765625')
(4, '2017-01-10T15:19:13.974342: step 122, loss 0.750564, acc 0.75')
(4, '2017-01-10T15:19:15.300776: step 123, loss 1.33712, acc 0.640625')
(4, '2017-01-10T15:19:16.620679: step 124, loss 0.652869, acc 0.78125')
(4, '2017-01-10T15:19:17.949465: step 125, loss 1.13359, acc 0.65625')
(4, '2017-01-10T15:19:19.238165: step 126, loss 1.35845, acc 0.625')
(4, '2017-01-10T15:19:20.713543: step 127, loss 0.983973, acc 0.6875')
(4, '2017-01-10T15:19:22.043326: step 128, loss 0.990973, acc 0.671875')
(4, '2017-01-10T15:19:23.333242: step 129, loss 1.42134, acc 0.59375')
(4, '2017-01-10T15:19:24.638483: step 130, loss 1.11067, acc 0.65625')
(4, '2017-01-10T15:19:25.960450: step 131, loss 0.758168, acc 0.765625')
(4, '2017-01-10T15:19:27.285499: step 132, loss 0.763076, acc 0.6875')
(4, '2017-01-10T15:19:28.587968: step 133, loss 0.872857, acc 0.625')
(4, '2017-01-10T15:19:29.913397: step 134, loss 0.975088, acc 0.75')
(4, '2017-01-10T15:19:31.248506: step 135, loss 0.788561, acc 0.75')
(4, '2017-01-10T15:19:32.530108: step 136, loss 0.977919, acc 0.75')
(4, '2017-01-10T15:19:33.850415: step 137, loss 0.859468, acc 0.71875')
(4, '2017-01-10T15:19:35.178818: step 138, loss 0.978428, acc 0.625')
(4, '2017-01-10T15:19:36.510488: step 139, loss 0.862228, acc 0.71875')
(4, '2017-01-10T15:19:37.830263: step 140, loss 1.17208, acc 0.65625')
(4, '2017-01-10T15:19:39.165071: step 141, loss 0.96714, acc 0.703125')
(4, '2017-01-10T15:19:40.454382: step 142, loss 0.911991, acc 0.71875')
(4, '2017-01-10T15:19:41.767301: step 143, loss 1.01408, acc 0.609375')
(4, '2017-01-10T15:19:43.082864: step 144, loss 1.22244, acc 0.609375')
(4, '2017-01-10T15:19:44.358578: step 145, loss 0.697429, acc 0.75')
(4, '2017-01-10T15:19:45.669434: step 146, loss 1.09733, acc 0.703125')
(4, '2017-01-10T15:19:47.022506: step 147, loss 1.1109, acc 0.6875')
(4, '2017-01-10T15:19:48.345949: step 148, loss 1.11754, acc 0.703125')
(4, '2017-01-10T15:19:49.680217: step 149, loss 1.36319, acc 0.703125')
(4, '2017-01-10T15:19:51.009756: step 150, loss 0.744012, acc 0.765625')
(4, '2017-01-10T15:19:52.335679: step 151, loss 0.770965, acc 0.75')
(4, '2017-01-10T15:19:53.657613: step 152, loss 0.588338, acc 0.78125')
(4, '2017-01-10T15:19:54.961930: step 153, loss 0.667516, acc 0.78125')
(4, '2017-01-10T15:19:56.264395: step 154, loss 0.857783, acc 0.703125')
(4, '2017-01-10T15:19:57.617889: step 155, loss 1.04495, acc 0.671875')
(4, '2017-01-10T15:19:58.942529: step 156, loss 0.926584, acc 0.671875')
(4, '2017-01-10T15:20:00.214890: step 157, loss 0.70688, acc 0.8125')
(4, '2017-01-10T15:20:01.543997: step 158, loss 0.78718, acc 0.765625')
(4, '2017-01-10T15:20:02.876937: step 159, loss 0.671813, acc 0.78125')
(4, '2017-01-10T15:20:04.160688: step 160, loss 0.679755, acc 0.796875')
(4, '2017-01-10T15:20:05.465094: step 161, loss 0.562163, acc 0.75')
(4, '2017-01-10T15:20:06.811454: step 162, loss 1.01422, acc 0.59375')
(4, '2017-01-10T15:20:08.095654: step 163, loss 0.825236, acc 0.796875')
(4, '2017-01-10T15:20:09.441710: step 164, loss 0.901938, acc 0.75')
(4, '2017-01-10T15:20:10.767337: step 165, loss 0.574827, acc 0.796875')
(4, '2017-01-10T15:20:12.083571: step 166, loss 0.99307, acc 0.640625')
(4, '2017-01-10T15:20:13.372989: step 167, loss 0.596623, acc 0.6875')
(4, '2017-01-10T15:20:14.714211: step 168, loss 1.07641, acc 0.65625')
(4, '2017-01-10T15:20:15.997641: step 169, loss 0.576198, acc 0.78125')
(4, '2017-01-10T15:20:17.314470: step 170, loss 0.549291, acc 0.828125')
(4, '2017-01-10T15:20:18.602337: step 171, loss 0.563978, acc 0.765625')
(4, '2017-01-10T15:20:20.122646: step 172, loss 0.482914, acc 0.828125')
(4, '2017-01-10T15:20:21.437795: step 173, loss 0.986683, acc 0.734375')
(4, '2017-01-10T15:20:22.721400: step 174, loss 0.722081, acc 0.734375')
(4, '2017-01-10T15:20:24.028405: step 175, loss 1.13835, acc 0.609375')
(4, '2017-01-10T15:20:25.357767: step 176, loss 0.728347, acc 0.75')
(4, '2017-01-10T15:20:26.649511: step 177, loss 0.839971, acc 0.65625')
(4, '2017-01-10T15:20:27.951087: step 178, loss 0.889912, acc 0.78125')
(4, '2017-01-10T15:20:29.297332: step 179, loss 0.56885, acc 0.796875')
(4, '2017-01-10T15:20:30.619256: step 180, loss 0.375519, acc 0.859375')
(4, '2017-01-10T15:20:31.905402: step 181, loss 0.994469, acc 0.6875')
(4, '2017-01-10T15:20:33.204441: step 182, loss 0.905097, acc 0.703125')
(4, '2017-01-10T15:20:34.531381: step 183, loss 0.722039, acc 0.75')
(4, '2017-01-10T15:20:35.850995: step 184, loss 0.768498, acc 0.734375')
(4, '2017-01-10T15:20:37.146277: step 185, loss 0.69764, acc 0.75')
(4, '2017-01-10T15:20:38.512502: step 186, loss 0.495248, acc 0.78125')
(4, '2017-01-10T15:20:39.807318: step 187, loss 0.799397, acc 0.71875')
(4, '2017-01-10T15:20:41.114583: step 188, loss 0.796462, acc 0.6875')
(4, '2017-01-10T15:20:42.455370: step 189, loss 1.05029, acc 0.703125')
(4, '2017-01-10T15:20:43.742476: step 190, loss 0.662877, acc 0.75')
(4, '2017-01-10T15:20:45.079309: step 191, loss 0.502987, acc 0.796875')
(4, '2017-01-10T15:20:46.383688: step 192, loss 0.302961, acc 0.921875')
(4, '2017-01-10T15:20:47.717780: step 193, loss 0.438314, acc 0.84375')
(4, '2017-01-10T15:20:49.122744: step 194, loss 1.11623, acc 0.59375')
(4, '2017-01-10T15:20:50.426117: step 195, loss 0.662287, acc 0.828125')
(4, '2017-01-10T15:20:51.762324: step 196, loss 0.653877, acc 0.765625')
(4, '2017-01-10T15:20:53.102834: step 197, loss 0.513862, acc 0.8125')
(4, '2017-01-10T15:20:54.404159: step 198, loss 0.641913, acc 0.78125')
(4, '2017-01-10T15:20:55.733887: step 199, loss 0.658253, acc 0.796875')
(4, '2017-01-10T15:20:57.033151: step 200, loss 0.785434, acc 0.703125')

Evaluation:
(4, '2017-01-10T15:20:59.814041: step 200, loss 0.56589, acc 0.695')

(4, '2017-01-10T15:21:01.106572: step 201, loss 0.42474, acc 0.875')
(4, '2017-01-10T15:21:02.402674: step 202, loss 0.916183, acc 0.75')
(4, '2017-01-10T15:21:03.725669: step 203, loss 0.892537, acc 0.6875')
(4, '2017-01-10T15:21:05.034474: step 204, loss 0.43581, acc 0.859375')
(4, '2017-01-10T15:21:06.369542: step 205, loss 0.909154, acc 0.6875')
(4, '2017-01-10T15:21:07.670934: step 206, loss 0.378138, acc 0.828125')
(4, '2017-01-10T15:21:08.958746: step 207, loss 0.603036, acc 0.765625')
(4, '2017-01-10T15:21:10.271085: step 208, loss 1.04361, acc 0.671875')
(4, '2017-01-10T15:21:11.618442: step 209, loss 0.685911, acc 0.8125')
(4, '2017-01-10T15:21:12.939542: step 210, loss 0.647391, acc 0.703125')
(4, '2017-01-10T15:21:14.230712: step 211, loss 0.569373, acc 0.8125')
(4, '2017-01-10T15:21:15.537553: step 212, loss 0.48652, acc 0.75')
(4, '2017-01-10T15:21:16.857039: step 213, loss 0.503304, acc 0.875')
(4, '2017-01-10T15:21:18.151957: step 214, loss 0.71496, acc 0.75')
(4, '2017-01-10T15:21:19.511787: step 215, loss 0.631056, acc 0.734375')
(4, '2017-01-10T15:21:21.018525: step 216, loss 0.422144, acc 0.8125')
(4, '2017-01-10T15:21:22.310110: step 217, loss 0.837275, acc 0.75')
(4, '2017-01-10T15:21:23.628838: step 218, loss 0.86436, acc 0.6875')
(4, '2017-01-10T15:21:24.944831: step 219, loss 0.761772, acc 0.71875')
(4, '2017-01-10T15:21:26.244844: step 220, loss 0.693139, acc 0.78125')
(4, '2017-01-10T15:21:27.583064: step 221, loss 0.561193, acc 0.828125')
(4, '2017-01-10T15:21:28.899622: step 222, loss 0.656405, acc 0.765625')
(4, '2017-01-10T15:21:30.223376: step 223, loss 0.579416, acc 0.765625')
(4, '2017-01-10T15:21:31.548905: step 224, loss 0.482677, acc 0.8125')
(4, '2017-01-10T15:21:32.867950: step 225, loss 0.598583, acc 0.78125')
(4, '2017-01-10T15:21:34.163205: step 226, loss 0.55652, acc 0.859375')
(4, '2017-01-10T15:21:35.497069: step 227, loss 0.285437, acc 0.890625')
(4, '2017-01-10T15:21:36.932700: step 228, loss 0.303967, acc 0.828125')
(4, '2017-01-10T15:21:38.259408: step 229, loss 0.43278, acc 0.859375')
(4, '2017-01-10T15:21:39.582959: step 230, loss 0.458927, acc 0.8125')
(4, '2017-01-10T15:21:40.881284: step 231, loss 0.774381, acc 0.78125')
(4, '2017-01-10T15:21:42.212538: step 232, loss 0.347744, acc 0.84375')
(4, '2017-01-10T15:21:43.499240: step 233, loss 0.691011, acc 0.734375')
(4, '2017-01-10T15:21:44.791352: step 234, loss 0.396137, acc 0.875')
(4, '2017-01-10T15:21:46.128737: step 235, loss 0.458653, acc 0.84375')
(4, '2017-01-10T15:21:47.402264: step 236, loss 0.625839, acc 0.765625')
(4, '2017-01-10T15:21:48.702112: step 237, loss 0.558379, acc 0.8125')
(4, '2017-01-10T15:21:50.030095: step 238, loss 0.670504, acc 0.8125')
(4, '2017-01-10T15:21:51.386904: step 239, loss 0.344241, acc 0.828125')
(4, '2017-01-10T15:21:52.730998: step 240, loss 0.678055, acc 0.765625')
(4, '2017-01-10T15:29:42.511733: step 241, loss 0.539611, acc 0.796875')
(4, '2017-01-10T15:29:43.760249: step 242, loss 0.762707, acc 0.796875')
(4, '2017-01-10T15:29:45.503435: step 243, loss 0.683177, acc 0.75')
(4, '2017-01-10T15:29:46.728998: step 244, loss 0.498001, acc 0.8125')
(4, '2017-01-10T15:29:47.932463: step 245, loss 0.429995, acc 0.84375')
(4, '2017-01-10T15:29:50.561168: step 246, loss 0.536466, acc 0.828125')
(4, '2017-01-10T15:29:51.951756: step 247, loss 0.67154, acc 0.796875')
(4, '2017-01-10T15:30:03.203188: step 248, loss 0.590205, acc 0.8125')
(4, '2017-01-10T15:30:04.199353: step 249, loss 0.479816, acc 0.8125')
(4, '2017-01-10T15:30:05.347837: step 250, loss 0.469398, acc 0.84375')
(4, '2017-01-10T15:30:06.491211: step 251, loss 0.669045, acc 0.84375')
(4, '2017-01-10T15:30:07.674213: step 252, loss 0.759159, acc 0.765625')
(4, '2017-01-10T15:30:09.051069: step 253, loss 0.442082, acc 0.8125')
(4, '2017-01-10T15:30:10.500606: step 254, loss 0.6145, acc 0.78125')
(4, '2017-01-10T15:30:11.895924: step 255, loss 0.50547, acc 0.75')
(4, '2017-01-10T15:30:13.119081: step 256, loss 0.554135, acc 0.71875')
(4, '2017-01-10T15:30:14.356288: step 257, loss 0.801644, acc 0.75')
(4, '2017-01-10T15:30:15.570305: step 258, loss 0.605071, acc 0.8125')
(4, '2017-01-10T15:30:16.801664: step 259, loss 0.332053, acc 0.84375')
(4, '2017-01-10T15:30:18.025986: step 260, loss 0.545526, acc 0.78125')
(4, '2017-01-10T15:30:19.300931: step 261, loss 0.356398, acc 0.828125')
(4, '2017-01-10T15:30:20.546452: step 262, loss 0.473406, acc 0.84375')
(4, '2017-01-10T15:30:21.908135: step 263, loss 0.582932, acc 0.78125')
(4, '2017-01-10T15:30:23.446648: step 264, loss 0.460945, acc 0.828125')
(4, '2017-01-10T15:30:24.935007: step 265, loss 0.541617, acc 0.75')
(4, '2017-01-10T15:30:26.273891: step 266, loss 0.472989, acc 0.828125')
(4, '2017-01-10T15:30:27.646119: step 267, loss 0.562547, acc 0.78125')
(4, '2017-01-10T15:30:28.933627: step 268, loss 0.730962, acc 0.796875')
(4, '2017-01-10T15:30:30.278827: step 269, loss 0.439616, acc 0.859375')
(4, '2017-01-10T15:30:31.578777: step 270, loss 0.455106, acc 0.84375')
(4, '2017-01-10T15:30:32.890333: step 271, loss 0.61183, acc 0.78125')
(4, '2017-01-10T15:30:34.223884: step 272, loss 0.703805, acc 0.765625')
(4, '2017-01-10T15:30:35.708132: step 273, loss 0.298393, acc 0.921875')
(4, '2017-01-10T15:30:37.150381: step 274, loss 0.429491, acc 0.8125')
(4, '2017-01-10T15:30:38.660872: step 275, loss 0.290367, acc 0.875')
(4, '2017-01-10T15:30:40.128930: step 276, loss 0.462875, acc 0.765625')
(4, '2017-01-10T15:30:41.516103: step 277, loss 0.51187, acc 0.828125')
(4, '2017-01-10T15:30:42.948413: step 278, loss 0.274601, acc 0.90625')
(4, '2017-01-10T15:30:44.409224: step 279, loss 0.743019, acc 0.734375')
(4, '2017-01-10T15:30:45.728433: step 280, loss 0.57093, acc 0.796875')
(4, '2017-01-10T15:30:47.035048: step 281, loss 0.534004, acc 0.875')
(4, '2017-01-10T15:30:48.444395: step 282, loss 0.268674, acc 0.890625')
(4, '2017-01-10T15:30:49.815927: step 283, loss 0.428249, acc 0.859375')
(4, '2017-01-10T15:30:51.372305: step 284, loss 0.548042, acc 0.84375')
(4, '2017-01-10T15:30:52.742755: step 285, loss 0.316738, acc 0.90625')
(4, '2017-01-10T15:30:54.162956: step 286, loss 0.575016, acc 0.828125')
(4, '2017-01-10T15:30:55.542831: step 287, loss 0.537362, acc 0.734375')
(4, '2017-01-10T15:30:56.974271: step 288, loss 0.545437, acc 0.8125')
(4, '2017-01-10T15:30:58.285936: step 289, loss 0.653196, acc 0.78125')
(4, '2017-01-10T15:30:59.636664: step 290, loss 0.240063, acc 0.90625')
(4, '2017-01-10T15:31:00.987661: step 291, loss 0.313277, acc 0.890625')
(4, '2017-01-10T15:31:02.356348: step 292, loss 0.529663, acc 0.859375')
(4, '2017-01-10T15:31:03.773396: step 293, loss 0.539839, acc 0.8125')
(4, '2017-01-10T15:31:05.174400: step 294, loss 0.475832, acc 0.84375')
(4, '2017-01-10T15:31:06.505020: step 295, loss 0.48012, acc 0.84375')
(4, '2017-01-10T15:31:07.835560: step 296, loss 0.413235, acc 0.84375')
(4, '2017-01-10T15:31:09.164182: step 297, loss 0.644441, acc 0.75')
(4, '2017-01-10T15:31:10.572224: step 298, loss 0.483107, acc 0.828125')
(4, '2017-01-10T15:31:12.073663: step 299, loss 0.349037, acc 0.90625')
(4, '2017-01-10T15:31:13.398364: step 300, loss 0.559118, acc 0.875')

Evaluation:
(4, '2017-01-10T15:31:16.057633: step 300, loss 0.537044, acc 0.72')

(4, '2017-01-10T15:31:17.475955: step 301, loss 0.241369, acc 0.890625')
(4, '2017-01-10T15:31:18.926980: step 302, loss 0.487139, acc 0.84375')
(4, '2017-01-10T15:31:20.301028: step 303, loss 0.406192, acc 0.828125')
(4, '2017-01-10T15:31:21.629642: step 304, loss 0.652727, acc 0.71875')
(4, '2017-01-10T15:31:22.985081: step 305, loss 0.443304, acc 0.875')
(4, '2017-01-10T15:31:24.292504: step 306, loss 0.462942, acc 0.78125')
(4, '2017-01-10T15:31:25.776060: step 307, loss 0.23703, acc 0.859375')
(4, '2017-01-10T15:31:27.125359: step 308, loss 0.267014, acc 0.890625')
(4, '2017-01-10T15:31:28.428650: step 309, loss 0.451847, acc 0.828125')
(4, '2017-01-10T15:31:29.735454: step 310, loss 0.360906, acc 0.859375')
(4, '2017-01-10T15:31:31.056127: step 311, loss 0.457526, acc 0.828125')
(4, '2017-01-10T15:31:32.335161: step 312, loss 0.368583, acc 0.890625')
(4, '2017-01-10T15:31:33.671025: step 313, loss 0.386904, acc 0.828125')
(4, '2017-01-10T15:31:34.994649: step 314, loss 0.407107, acc 0.84375')
(4, '2017-01-10T15:31:36.292807: step 315, loss 0.200396, acc 0.921875')
(4, '2017-01-10T15:31:37.594132: step 316, loss 0.412336, acc 0.859375')
(4, '2017-01-10T15:31:38.993289: step 317, loss 0.367081, acc 0.890625')
(4, '2017-01-10T15:31:40.442475: step 318, loss 0.325076, acc 0.875')
(4, '2017-01-10T15:31:41.827136: step 319, loss 0.490912, acc 0.859375')
(4, '2017-01-10T15:31:43.197594: step 320, loss 0.294937, acc 0.90625')
(4, '2017-01-10T15:31:44.739692: step 321, loss 0.451923, acc 0.828125')
(4, '2017-01-10T15:31:46.113449: step 322, loss 0.406267, acc 0.8125')
(4, '2017-01-10T15:31:47.441211: step 323, loss 0.617758, acc 0.734375')
(4, '2017-01-10T15:31:48.788501: step 324, loss 0.28345, acc 0.890625')
(4, '2017-01-10T15:31:50.140467: step 325, loss 0.381126, acc 0.859375')
(4, '2017-01-10T15:31:51.453085: step 326, loss 0.458047, acc 0.859375')
(4, '2017-01-10T15:31:52.761504: step 327, loss 0.519952, acc 0.875')
(4, '2017-01-10T15:31:54.062454: step 328, loss 0.353988, acc 0.8125')
(4, '2017-01-10T15:31:55.359108: step 329, loss 0.379406, acc 0.796875')
(4, '2017-01-10T15:31:56.660103: step 330, loss 0.200752, acc 0.921875')
(4, '2017-01-10T15:31:57.952737: step 331, loss 0.288786, acc 0.859375')
(4, '2017-01-10T15:31:59.316757: step 332, loss 0.230327, acc 0.90625')
(4, '2017-01-10T15:32:00.719248: step 333, loss 0.361251, acc 0.84375')
(4, '2017-01-10T15:32:02.056679: step 334, loss 0.298875, acc 0.875')
(4, '2017-01-10T15:32:03.554980: step 335, loss 0.374924, acc 0.78125')
(4, '2017-01-10T15:32:05.224400: step 336, loss 0.237335, acc 0.890625')
(4, '2017-01-10T15:32:06.893669: step 337, loss 0.429346, acc 0.875')
(4, '2017-01-10T15:32:08.647366: step 338, loss 0.411681, acc 0.875')
(4, '2017-01-10T15:32:10.245852: step 339, loss 0.203917, acc 0.90625')
(4, '2017-01-10T15:32:12.180091: step 340, loss 0.384981, acc 0.875')
(4, '2017-01-10T15:32:13.772946: step 341, loss 0.356229, acc 0.859375')
(4, '2017-01-10T15:32:15.442770: step 342, loss 0.701942, acc 0.8125')
(4, '2017-01-10T15:32:17.035647: step 343, loss 0.431784, acc 0.828125')
(4, '2017-01-10T15:32:18.604066: step 344, loss 0.263503, acc 0.90625')
(4, '2017-01-10T15:32:19.927646: step 345, loss 0.292738, acc 0.890625')
(4, '2017-01-10T15:32:21.239514: step 346, loss 0.290677, acc 0.890625')
(4, '2017-01-10T15:32:22.627854: step 347, loss 0.517132, acc 0.78125')
(4, '2017-01-10T15:32:24.133112: step 348, loss 0.47621, acc 0.84375')
(4, '2017-01-10T15:32:25.487422: step 349, loss 0.379541, acc 0.8125')
(4, '2017-01-10T15:32:26.806580: step 350, loss 0.394326, acc 0.84375')
(4, '2017-01-10T15:32:28.127693: step 351, loss 0.254233, acc 0.875')
(4, '2017-01-10T15:32:29.431024: step 352, loss 0.232204, acc 0.9375')
(4, '2017-01-10T15:32:30.740143: step 353, loss 0.379199, acc 0.84375')
(4, '2017-01-10T15:32:32.104978: step 354, loss 0.286676, acc 0.890625')
(4, '2017-01-10T15:32:33.497411: step 355, loss 0.332919, acc 0.84375')
(4, '2017-01-10T15:32:34.816645: step 356, loss 0.40743, acc 0.84375')
(4, '2017-01-10T15:32:36.189028: step 357, loss 0.600574, acc 0.8125')
(4, '2017-01-10T15:32:37.569203: step 358, loss 0.416033, acc 0.796875')
(4, '2017-01-10T15:32:38.945729: step 359, loss 0.326044, acc 0.890625')
(4, '2017-01-10T15:32:40.260581: step 360, loss 0.223274, acc 0.921875')
(4, '2017-01-10T15:32:41.592442: step 361, loss 0.470896, acc 0.828125')
(4, '2017-01-10T15:32:42.968691: step 362, loss 0.258616, acc 0.90625')
(4, '2017-01-10T15:32:44.315714: step 363, loss 0.492191, acc 0.8125')
(4, '2017-01-10T15:32:45.665950: step 364, loss 0.301692, acc 0.890625')
(4, '2017-01-10T15:32:47.004174: step 365, loss 0.401994, acc 0.828125')
(4, '2017-01-10T15:32:48.426864: step 366, loss 0.279765, acc 0.875')
(4, '2017-01-10T15:32:49.814507: step 367, loss 0.338137, acc 0.84375')
(4, '2017-01-10T15:32:51.170432: step 368, loss 0.382066, acc 0.84375')
(4, '2017-01-10T15:32:52.662654: step 369, loss 0.317498, acc 0.859375')
(4, '2017-01-10T15:32:54.343848: step 370, loss 0.415127, acc 0.828125')
(4, '2017-01-10T15:32:56.006022: step 371, loss 0.229604, acc 0.890625')
(4, '2017-01-10T15:32:57.640541: step 372, loss 0.314906, acc 0.859375')
(4, '2017-01-10T15:32:59.224373: step 373, loss 0.381737, acc 0.84375')
(4, '2017-01-10T15:33:00.638462: step 374, loss 0.472577, acc 0.8125')
(4, '2017-01-10T15:33:01.987603: step 375, loss 0.580896, acc 0.765625')
(4, '2017-01-10T15:33:03.317257: step 376, loss 0.205522, acc 0.921875')
(4, '2017-01-10T15:33:04.715377: step 377, loss 0.47765, acc 0.78125')
(4, '2017-01-10T15:33:06.098232: step 378, loss 0.38431, acc 0.875')
(4, '2017-01-10T15:33:07.449809: step 379, loss 0.339487, acc 0.875')
(4, '2017-01-10T15:33:08.783650: step 380, loss 0.426492, acc 0.859375')
(4, '2017-01-10T15:33:10.114633: step 381, loss 0.302915, acc 0.921875')
(4, '2017-01-10T15:33:11.650378: step 382, loss 0.446562, acc 0.859375')
(4, '2017-01-10T15:33:13.013516: step 383, loss 0.503478, acc 0.8125')
(4, '2017-01-10T15:33:14.383896: step 384, loss 0.431969, acc 0.859375')
(4, '2017-01-10T15:33:15.728507: step 385, loss 0.371513, acc 0.828125')
(4, '2017-01-10T15:33:17.090741: step 386, loss 0.548514, acc 0.84375')
(4, '2017-01-10T15:33:18.414021: step 387, loss 0.3799, acc 0.84375')
(4, '2017-01-10T15:33:19.814401: step 388, loss 0.533469, acc 0.859375')
(4, '2017-01-10T15:33:21.216965: step 389, loss 0.473686, acc 0.828125')
(4, '2017-01-10T15:33:22.577592: step 390, loss 0.506353, acc 0.828125')
(4, '2017-01-10T15:33:23.934481: step 391, loss 0.432221, acc 0.828125')
(4, '2017-01-10T15:33:25.271376: step 392, loss 0.268728, acc 0.890625')
(4, '2017-01-10T15:33:26.614764: step 393, loss 0.325749, acc 0.875')
(4, '2017-01-10T15:33:27.994171: step 394, loss 0.317128, acc 0.890625')
(4, '2017-01-10T15:33:29.353813: step 395, loss 0.413872, acc 0.828125')
(4, '2017-01-10T15:33:30.710984: step 396, loss 0.173116, acc 0.90625')
(4, '2017-01-10T15:33:32.036324: step 397, loss 0.247296, acc 0.90625')
(4, '2017-01-10T15:33:33.383275: step 398, loss 0.217578, acc 0.9375')
(4, '2017-01-10T15:33:34.786941: step 399, loss 0.387534, acc 0.796875')
(4, '2017-01-10T15:33:36.149790: step 400, loss 0.350773, acc 0.875')

Evaluation:
(4, '2017-01-10T15:33:39.113138: step 400, loss 0.514834, acc 0.7475')

(4, '2017-01-10T15:33:40.455690: step 401, loss 0.311939, acc 0.828125')
(4, '2017-01-10T15:33:41.959313: step 402, loss 0.271813, acc 0.9375')
(4, '2017-01-10T15:33:43.472844: step 403, loss 0.235996, acc 0.90625')
(4, '2017-01-10T15:33:44.889305: step 404, loss 0.337374, acc 0.828125')
(4, '2017-01-10T15:33:46.289153: step 405, loss 0.211493, acc 0.921875')
(4, '2017-01-10T15:33:47.607302: step 406, loss 0.431241, acc 0.8125')
(4, '2017-01-10T15:33:49.000799: step 407, loss 0.327528, acc 0.84375')
(4, '2017-01-10T15:33:50.443928: step 408, loss 0.341777, acc 0.875')
(4, '2017-01-10T15:33:51.891202: step 409, loss 0.319212, acc 0.9375')
(4, '2017-01-10T15:33:53.251321: step 410, loss 0.49297, acc 0.84375')
(4, '2017-01-10T15:33:54.850144: step 411, loss 0.147083, acc 0.9375')
(4, '2017-01-10T15:33:56.398857: step 412, loss 0.264738, acc 0.921875')
(4, '2017-01-10T15:33:57.763221: step 413, loss 0.430868, acc 0.796875')
(4, '2017-01-10T15:33:59.085184: step 414, loss 0.175369, acc 0.921875')
(4, '2017-01-10T15:34:00.431235: step 415, loss 0.260571, acc 0.921875')
(4, '2017-01-10T15:34:01.767332: step 416, loss 0.357612, acc 0.875')
(4, '2017-01-10T15:34:03.165187: step 417, loss 0.297452, acc 0.875')
(4, '2017-01-10T15:34:04.607655: step 418, loss 0.429374, acc 0.796875')
(4, '2017-01-10T15:34:06.012568: step 419, loss 0.400095, acc 0.84375')
(4, '2017-01-10T15:34:07.395094: step 420, loss 0.288509, acc 0.890625')
(4, '2017-01-10T15:34:08.756939: step 421, loss 0.287128, acc 0.890625')
(4, '2017-01-10T15:34:10.126109: step 422, loss 0.292854, acc 0.890625')
(4, '2017-01-10T15:34:11.685251: step 423, loss 0.378221, acc 0.828125')
(4, '2017-01-10T15:34:13.188664: step 424, loss 0.319704, acc 0.90625')
(4, '2017-01-10T15:34:14.721615: step 425, loss 0.322307, acc 0.875')
(4, '2017-01-10T15:34:16.323783: step 426, loss 0.488922, acc 0.828125')
(4, '2017-01-10T15:34:17.757090: step 427, loss 0.184443, acc 0.921875')
(4, '2017-01-10T15:34:19.153555: step 428, loss 0.292342, acc 0.859375')
(4, '2017-01-10T15:34:20.687899: step 429, loss 0.167705, acc 0.953125')
(4, '2017-01-10T15:34:22.231677: step 430, loss 0.21632, acc 0.90625')
(4, '2017-01-10T15:34:23.653742: step 431, loss 0.19539, acc 0.90625')
(4, '2017-01-10T15:34:25.088297: step 432, loss 0.249705, acc 0.875')
(4, '2017-01-10T15:34:26.528521: step 433, loss 0.224564, acc 0.890625')
(4, '2017-01-10T15:34:27.934017: step 434, loss 0.257984, acc 0.890625')
(4, '2017-01-10T15:34:29.291898: step 435, loss 0.24942, acc 0.90625')
(4, '2017-01-10T15:34:30.671756: step 436, loss 0.196639, acc 0.90625')
(4, '2017-01-10T15:34:32.022114: step 437, loss 0.341505, acc 0.90625')
(4, '2017-01-10T15:34:33.377969: step 438, loss 0.214791, acc 0.921875')
(4, '2017-01-10T15:34:34.778351: step 439, loss 0.268323, acc 0.84375')
(4, '2017-01-10T15:34:36.146669: step 440, loss 0.245849, acc 0.921875')
(4, '2017-01-10T15:34:37.546361: step 441, loss 0.167607, acc 0.921875')
(4, '2017-01-10T15:34:39.076494: step 442, loss 0.264182, acc 0.890625')
(4, '2017-01-10T15:34:40.437803: step 443, loss 0.226488, acc 0.875')
(4, '2017-01-10T15:34:41.813474: step 444, loss 0.292768, acc 0.859375')
(4, '2017-01-10T15:34:43.191175: step 445, loss 0.426401, acc 0.84375')
(4, '2017-01-10T15:34:44.571102: step 446, loss 0.355961, acc 0.859375')
(4, '2017-01-10T15:34:45.915210: step 447, loss 0.203367, acc 0.90625')
(4, '2017-01-10T15:34:47.240394: step 448, loss 0.475296, acc 0.84375')
(4, '2017-01-10T15:34:48.589722: step 449, loss 0.375542, acc 0.875')
(4, '2017-01-10T15:34:49.953000: step 450, loss 0.131783, acc 0.953125')
(4, '2017-01-10T15:34:51.352834: step 451, loss 0.22978, acc 0.921875')
(4, '2017-01-10T15:34:52.699754: step 452, loss 0.14199, acc 0.9375')
(4, '2017-01-10T15:34:54.029035: step 453, loss 0.276014, acc 0.84375')
(4, '2017-01-10T15:34:55.358001: step 454, loss 0.190714, acc 0.921875')
(4, '2017-01-10T15:34:56.696862: step 455, loss 0.293543, acc 0.84375')
(4, '2017-01-10T15:34:58.002135: step 456, loss 0.199239, acc 0.90625')
(4, '2017-01-10T15:34:59.336970: step 457, loss 0.239385, acc 0.890625')
(4, '2017-01-10T15:35:00.720973: step 458, loss 0.248862, acc 0.921875')
(4, '2017-01-10T15:35:02.042145: step 459, loss 0.29592, acc 0.890625')
(4, '2017-01-10T15:35:03.366297: step 460, loss 0.344336, acc 0.828125')
(4, '2017-01-10T15:35:04.692937: step 461, loss 0.194266, acc 0.90625')
(4, '2017-01-10T15:35:06.020350: step 462, loss 0.209766, acc 0.90625')
(4, '2017-01-10T15:35:07.339366: step 463, loss 0.184847, acc 0.9375')
(4, '2017-01-10T15:35:08.673759: step 464, loss 0.138748, acc 0.9375')
(4, '2017-01-10T15:35:10.008286: step 465, loss 0.298914, acc 0.890625')
(4, '2017-01-10T15:35:11.372641: step 466, loss 0.309423, acc 0.859375')
(4, '2017-01-10T15:35:12.695196: step 467, loss 0.23851, acc 0.90625')
(4, '2017-01-10T15:35:14.028398: step 468, loss 0.173834, acc 0.9375')
(4, '2017-01-10T15:35:15.365151: step 469, loss 0.216221, acc 0.90625')
(4, '2017-01-10T15:35:16.848654: step 470, loss 0.203877, acc 0.9375')
(4, '2017-01-10T15:35:18.172986: step 471, loss 0.255589, acc 0.9375')
(4, '2017-01-10T15:35:19.513591: step 472, loss 0.124742, acc 0.9375')
(4, '2017-01-10T15:35:20.874912: step 473, loss 0.143306, acc 0.921875')
(4, '2017-01-10T15:35:22.232036: step 474, loss 0.187299, acc 0.9375')
(4, '2017-01-10T15:35:23.563713: step 475, loss 0.312703, acc 0.796875')
(4, '2017-01-10T15:35:24.887933: step 476, loss 0.31136, acc 0.90625')
(4, '2017-01-10T15:35:26.211373: step 477, loss 0.195903, acc 0.90625')
(4, '2017-01-10T15:35:27.541054: step 478, loss 0.342223, acc 0.859375')
(4, '2017-01-10T15:35:28.845310: step 479, loss 0.300471, acc 0.875')
(4, '2017-01-10T15:35:30.161222: step 480, loss 0.260283, acc 0.859375')
(4, '2017-01-10T15:35:31.492129: step 481, loss 0.272157, acc 0.859375')
(4, '2017-01-10T15:35:32.856025: step 482, loss 0.2218, acc 0.9375')
(4, '2017-01-10T15:35:34.192523: step 483, loss 0.159074, acc 0.9375')
(4, '2017-01-10T15:35:35.526097: step 484, loss 0.151145, acc 0.921875')
(4, '2017-01-10T15:35:36.851080: step 485, loss 0.282307, acc 0.875')
(4, '2017-01-10T15:35:38.187375: step 486, loss 0.298503, acc 0.890625')
(4, '2017-01-10T15:35:39.512234: step 487, loss 0.240328, acc 0.90625')
(4, '2017-01-10T15:35:40.833233: step 488, loss 0.226175, acc 0.921875')
(4, '2017-01-10T15:35:42.138871: step 489, loss 0.227333, acc 0.875')
(4, '2017-01-10T15:35:43.508072: step 490, loss 0.358454, acc 0.859375')
(4, '2017-01-10T15:35:44.857005: step 491, loss 0.286072, acc 0.859375')
(4, '2017-01-10T15:35:46.194595: step 492, loss 0.29047, acc 0.890625')
(4, '2017-01-10T15:35:47.508055: step 493, loss 0.209155, acc 0.90625')
(4, '2017-01-10T15:35:48.841040: step 494, loss 0.237328, acc 0.890625')
(4, '2017-01-10T15:35:50.167383: step 495, loss 0.287431, acc 0.921875')
(4, '2017-01-10T15:35:51.516422: step 496, loss 0.190201, acc 0.90625')
(4, '2017-01-10T15:35:52.869780: step 497, loss 0.20381, acc 0.90625')
(4, '2017-01-10T15:35:54.290285: step 498, loss 0.189194, acc 0.9375')
(4, '2017-01-10T15:35:55.702391: step 499, loss 0.227356, acc 0.90625')
(4, '2017-01-10T15:35:57.272390: step 500, loss 0.166756, acc 0.90625')

Evaluation:
(4, '2017-01-10T15:36:00.406397: step 500, loss 0.558528, acc 0.7275')

(4, '2017-01-10T15:36:03.610874: step 500, loss 0.558528, acc 0.7275')
Vocabulary Size: 14319
Train/Dev split: 1600/400
Writing to /Users/amrkoura/Documents/workspace/newYorkerChallenge/runs/1484058963

(5, '2017-01-10T15:36:05.975300: step 1, loss 4.25361, acc 0.5625')
(5, '2017-01-10T15:36:07.300770: step 2, loss 3.0449, acc 0.53125')
(5, '2017-01-10T15:36:08.603223: step 3, loss 2.01342, acc 0.59375')
(5, '2017-01-10T15:36:09.922160: step 4, loss 1.98232, acc 0.5')
(5, '2017-01-10T15:36:11.303838: step 5, loss 2.86781, acc 0.484375')
(5, '2017-01-10T15:36:12.745641: step 6, loss 2.11541, acc 0.53125')
(5, '2017-01-10T15:36:14.086619: step 7, loss 2.11691, acc 0.5625')
(5, '2017-01-10T15:36:15.467699: step 8, loss 2.74956, acc 0.5')
(5, '2017-01-10T15:36:16.898651: step 9, loss 3.1441, acc 0.53125')
(5, '2017-01-10T15:36:18.429948: step 10, loss 3.16959, acc 0.453125')
(5, '2017-01-10T15:36:20.084696: step 11, loss 2.90394, acc 0.484375')
(5, '2017-01-10T15:36:21.775672: step 12, loss 2.21023, acc 0.546875')
(5, '2017-01-10T15:36:23.210836: step 13, loss 1.91061, acc 0.5625')
(5, '2017-01-10T15:36:24.636264: step 14, loss 1.83976, acc 0.625')
(5, '2017-01-10T15:36:25.962686: step 15, loss 2.58236, acc 0.5')
(5, '2017-01-10T15:36:27.287429: step 16, loss 3.29216, acc 0.46875')
(5, '2017-01-10T15:36:28.663096: step 17, loss 3.28478, acc 0.453125')
(5, '2017-01-10T15:36:30.017028: step 18, loss 2.07333, acc 0.609375')
(5, '2017-01-10T15:36:31.350938: step 19, loss 2.85546, acc 0.484375')
(5, '2017-01-10T15:36:32.685668: step 20, loss 2.78301, acc 0.5')
(5, '2017-01-10T15:36:34.007460: step 21, loss 2.28057, acc 0.609375')
(5, '2017-01-10T15:36:35.336065: step 22, loss 2.31568, acc 0.484375')
(5, '2017-01-10T15:36:36.655680: step 23, loss 2.31538, acc 0.53125')
(5, '2017-01-10T15:36:37.984957: step 24, loss 1.90619, acc 0.515625')
(5, '2017-01-10T15:36:39.348441: step 25, loss 2.22572, acc 0.546875')
(5, '2017-01-10T15:36:40.675432: step 26, loss 1.58683, acc 0.65625')
(5, '2017-01-10T15:36:41.992845: step 27, loss 2.41834, acc 0.5')
(5, '2017-01-10T15:36:43.308564: step 28, loss 2.43237, acc 0.546875')
(5, '2017-01-10T15:36:44.643394: step 29, loss 2.09581, acc 0.5')
(5, '2017-01-10T15:36:45.932703: step 30, loss 2.84266, acc 0.46875')
(5, '2017-01-10T15:36:47.253485: step 31, loss 1.66052, acc 0.578125')
(5, '2017-01-10T15:36:48.580388: step 32, loss 1.67123, acc 0.546875')
(5, '2017-01-10T15:36:50.031825: step 33, loss 1.47213, acc 0.609375')
(5, '2017-01-10T15:36:51.405997: step 34, loss 2.60521, acc 0.453125')
(5, '2017-01-10T15:36:52.726137: step 35, loss 1.2245, acc 0.65625')
(5, '2017-01-10T15:36:54.058100: step 36, loss 1.69286, acc 0.59375')
(5, '2017-01-10T15:36:55.398337: step 37, loss 1.64584, acc 0.609375')
(5, '2017-01-10T15:36:56.731354: step 38, loss 1.59403, acc 0.609375')
(5, '2017-01-10T15:36:58.057910: step 39, loss 1.80552, acc 0.59375')
(5, '2017-01-10T15:36:59.378191: step 40, loss 1.28131, acc 0.59375')
(5, '2017-01-10T15:37:00.732666: step 41, loss 1.80793, acc 0.546875')
(5, '2017-01-10T15:37:02.036074: step 42, loss 1.77406, acc 0.546875')
(5, '2017-01-10T15:37:03.375023: step 43, loss 1.45152, acc 0.609375')
(5, '2017-01-10T15:37:04.698295: step 44, loss 1.88425, acc 0.625')
(5, '2017-01-10T15:37:06.026632: step 45, loss 1.39665, acc 0.59375')
(5, '2017-01-10T15:37:07.340303: step 46, loss 1.41583, acc 0.5625')
(5, '2017-01-10T15:37:08.663737: step 47, loss 1.51131, acc 0.609375')
(5, '2017-01-10T15:37:09.979420: step 48, loss 1.44028, acc 0.6875')
(5, '2017-01-10T15:37:11.316948: step 49, loss 1.84233, acc 0.5625')
(5, '2017-01-10T15:37:12.646376: step 50, loss 1.22819, acc 0.671875')
(5, '2017-01-10T15:37:13.972144: step 51, loss 1.7973, acc 0.5625')
(5, '2017-01-10T15:37:15.299635: step 52, loss 1.43383, acc 0.578125')
(5, '2017-01-10T15:37:16.631708: step 53, loss 1.70154, acc 0.65625')
(5, '2017-01-10T15:37:17.947098: step 54, loss 1.17726, acc 0.6875')
(5, '2017-01-10T15:37:19.273487: step 55, loss 1.4035, acc 0.71875')
(5, '2017-01-10T15:37:20.605485: step 56, loss 1.31994, acc 0.6875')
(5, '2017-01-10T15:37:22.121942: step 57, loss 1.69002, acc 0.5625')
(5, '2017-01-10T15:37:23.497023: step 58, loss 1.6538, acc 0.640625')
(5, '2017-01-10T15:37:24.826911: step 59, loss 2.03382, acc 0.5625')
(5, '2017-01-10T15:37:26.167895: step 60, loss 1.87112, acc 0.578125')
(5, '2017-01-10T15:37:27.518201: step 61, loss 1.50836, acc 0.609375')
(5, '2017-01-10T15:37:28.951581: step 62, loss 2.26785, acc 0.5625')
(5, '2017-01-10T15:37:30.669330: step 63, loss 1.39594, acc 0.609375')
(5, '2017-01-10T15:37:32.144746: step 64, loss 1.41376, acc 0.640625')
(5, '2017-01-10T15:37:33.499837: step 65, loss 1.52358, acc 0.578125')
(5, '2017-01-10T15:37:34.857320: step 66, loss 1.65572, acc 0.703125')
(5, '2017-01-10T15:37:36.243232: step 67, loss 1.46558, acc 0.625')
(5, '2017-01-10T15:37:37.585270: step 68, loss 1.16506, acc 0.65625')
(5, '2017-01-10T15:37:38.923961: step 69, loss 1.30561, acc 0.703125')
(5, '2017-01-10T15:37:40.259555: step 70, loss 1.04536, acc 0.6875')
(5, '2017-01-10T15:37:41.610420: step 71, loss 1.59016, acc 0.671875')
(5, '2017-01-10T15:37:42.992906: step 72, loss 1.00629, acc 0.640625')
(5, '2017-01-10T15:37:44.328292: step 73, loss 1.25734, acc 0.578125')
(5, '2017-01-10T15:37:45.677933: step 74, loss 0.922163, acc 0.703125')
(5, '2017-01-10T15:37:47.007513: step 75, loss 1.19561, acc 0.609375')
(5, '2017-01-10T15:37:48.369204: step 76, loss 1.14922, acc 0.671875')
(5, '2017-01-10T15:37:49.699806: step 77, loss 1.15931, acc 0.640625')
(5, '2017-01-10T15:37:51.062678: step 78, loss 1.34182, acc 0.640625')
(5, '2017-01-10T15:37:52.375260: step 79, loss 1.02664, acc 0.71875')
(5, '2017-01-10T15:37:53.793447: step 80, loss 0.990165, acc 0.6875')
(5, '2017-01-10T15:37:55.115916: step 81, loss 1.60431, acc 0.578125')
(5, '2017-01-10T15:37:56.437786: step 82, loss 1.04304, acc 0.703125')
(5, '2017-01-10T15:37:57.759135: step 83, loss 1.19466, acc 0.6875')
(5, '2017-01-10T15:37:59.093676: step 84, loss 1.49148, acc 0.59375')
(5, '2017-01-10T15:38:00.445538: step 85, loss 0.827527, acc 0.734375')
(5, '2017-01-10T15:38:01.784656: step 86, loss 0.975292, acc 0.703125')
(5, '2017-01-10T15:38:03.103333: step 87, loss 1.14002, acc 0.65625')
(5, '2017-01-10T15:38:04.434232: step 88, loss 0.958728, acc 0.65625')
(5, '2017-01-10T15:38:05.782082: step 89, loss 1.52264, acc 0.671875')
(5, '2017-01-10T15:38:07.140722: step 90, loss 1.58853, acc 0.546875')
(5, '2017-01-10T15:38:08.488834: step 91, loss 1.44292, acc 0.578125')
(5, '2017-01-10T15:38:09.805840: step 92, loss 1.08969, acc 0.671875')
(5, '2017-01-10T15:38:11.157456: step 93, loss 1.51285, acc 0.609375')
(5, '2017-01-10T15:38:12.483213: step 94, loss 1.04719, acc 0.65625')
(5, '2017-01-10T15:38:13.830741: step 95, loss 1.2478, acc 0.59375')
(5, '2017-01-10T15:38:15.172807: step 96, loss 0.939669, acc 0.71875')
(5, '2017-01-10T15:38:16.521631: step 97, loss 1.2416, acc 0.625')
(5, '2017-01-10T15:38:17.914550: step 98, loss 0.990044, acc 0.765625')
(5, '2017-01-10T15:38:19.316366: step 99, loss 1.8494, acc 0.59375')
(5, '2017-01-10T15:38:20.707454: step 100, loss 1.56195, acc 0.5625')

Evaluation:
(5, '2017-01-10T15:38:23.683278: step 100, loss 0.587851, acc 0.7')

(5, '2017-01-10T15:38:25.043730: step 101, loss 1.17235, acc 0.703125')
(5, '2017-01-10T15:38:26.383078: step 102, loss 1.01811, acc 0.640625')
(5, '2017-01-10T15:38:27.804414: step 103, loss 1.0468, acc 0.5625')
(5, '2017-01-10T15:38:29.187317: step 104, loss 1.06201, acc 0.65625')
(5, '2017-01-10T15:38:30.589736: step 105, loss 0.63008, acc 0.828125')
(5, '2017-01-10T15:38:31.930028: step 106, loss 1.20885, acc 0.703125')
(5, '2017-01-10T15:38:33.276229: step 107, loss 0.775346, acc 0.734375')
(5, '2017-01-10T15:38:34.618934: step 108, loss 0.836906, acc 0.765625')
(5, '2017-01-10T15:38:35.947683: step 109, loss 0.970542, acc 0.65625')
(5, '2017-01-10T15:38:37.281158: step 110, loss 0.887538, acc 0.75')
(5, '2017-01-10T15:38:38.607207: step 111, loss 1.15336, acc 0.6875')
(5, '2017-01-10T15:38:39.954736: step 112, loss 0.969335, acc 0.65625')
(5, '2017-01-10T15:38:41.302073: step 113, loss 0.934323, acc 0.71875')
(5, '2017-01-10T15:38:42.639663: step 114, loss 1.05847, acc 0.671875')
(5, '2017-01-10T15:38:44.073462: step 115, loss 1.04228, acc 0.71875')
(5, '2017-01-10T15:38:45.474455: step 116, loss 1.0044, acc 0.671875')
(5, '2017-01-10T15:38:46.854816: step 117, loss 0.875912, acc 0.71875')
(5, '2017-01-10T15:38:48.183954: step 118, loss 1.09358, acc 0.765625')
(5, '2017-01-10T15:38:49.490611: step 119, loss 1.13677, acc 0.65625')
(5, '2017-01-10T15:38:50.793966: step 120, loss 0.780042, acc 0.796875')
(5, '2017-01-10T15:38:52.158326: step 121, loss 0.780754, acc 0.78125')
(5, '2017-01-10T15:38:53.807395: step 122, loss 1.16321, acc 0.65625')
(5, '2017-01-10T15:38:55.359514: step 123, loss 1.13788, acc 0.6875')
(5, '2017-01-10T15:38:56.742780: step 124, loss 1.03203, acc 0.75')
(5, '2017-01-10T15:38:58.106899: step 125, loss 1.29386, acc 0.625')
(5, '2017-01-10T15:38:59.460089: step 126, loss 0.630056, acc 0.78125')
(5, '2017-01-10T15:39:00.829774: step 127, loss 1.13075, acc 0.671875')
(5, '2017-01-10T15:39:02.184327: step 128, loss 0.903616, acc 0.75')
(5, '2017-01-10T15:39:03.548124: step 129, loss 1.08563, acc 0.625')
(5, '2017-01-10T15:39:04.904890: step 130, loss 0.690033, acc 0.78125')
(5, '2017-01-10T15:39:06.223817: step 131, loss 0.957168, acc 0.6875')
(5, '2017-01-10T15:39:07.592065: step 132, loss 0.930175, acc 0.65625')
(5, '2017-01-10T15:39:08.969718: step 133, loss 0.67892, acc 0.765625')
(5, '2017-01-10T15:39:10.358344: step 134, loss 0.758876, acc 0.75')
(5, '2017-01-10T15:39:11.733503: step 135, loss 1.08362, acc 0.671875')
(5, '2017-01-10T15:39:13.060651: step 136, loss 1.37664, acc 0.671875')
(5, '2017-01-10T15:39:14.382696: step 137, loss 0.828977, acc 0.78125')
(5, '2017-01-10T15:39:15.720737: step 138, loss 1.24266, acc 0.640625')
(5, '2017-01-10T15:39:17.129987: step 139, loss 1.12543, acc 0.625')
(5, '2017-01-10T15:39:18.550022: step 140, loss 0.54163, acc 0.796875')
(5, '2017-01-10T15:39:19.942148: step 141, loss 0.954714, acc 0.71875')
(5, '2017-01-10T15:39:21.722855: step 142, loss 0.612592, acc 0.8125')
(5, '2017-01-10T15:39:23.212407: step 143, loss 0.640868, acc 0.765625')
(5, '2017-01-10T15:39:24.559281: step 144, loss 0.763462, acc 0.734375')
(5, '2017-01-10T15:39:25.947117: step 145, loss 0.929913, acc 0.6875')
(5, '2017-01-10T15:39:27.333856: step 146, loss 0.542318, acc 0.796875')
(5, '2017-01-10T15:39:28.672848: step 147, loss 0.87501, acc 0.65625')
(5, '2017-01-10T15:39:30.023624: step 148, loss 0.675273, acc 0.796875')
(5, '2017-01-10T15:39:31.348557: step 149, loss 0.706194, acc 0.734375')
(5, '2017-01-10T15:39:32.683659: step 150, loss 0.960068, acc 0.71875')
(5, '2017-01-10T15:39:34.070117: step 151, loss 0.962217, acc 0.625')
(5, '2017-01-10T15:39:35.460495: step 152, loss 0.543, acc 0.765625')
(5, '2017-01-10T15:39:36.915960: step 153, loss 0.853603, acc 0.734375')
(5, '2017-01-10T15:39:38.300775: step 154, loss 0.751536, acc 0.8125')
(5, '2017-01-10T15:39:39.676676: step 155, loss 0.555097, acc 0.828125')
(5, '2017-01-10T15:39:41.077558: step 156, loss 0.634727, acc 0.765625')
(5, '2017-01-10T15:39:42.463692: step 157, loss 0.764378, acc 0.703125')
(5, '2017-01-10T15:39:43.881164: step 158, loss 0.729436, acc 0.78125')
(5, '2017-01-10T15:39:45.428720: step 159, loss 0.455551, acc 0.8125')
(5, '2017-01-10T15:39:46.990295: step 160, loss 0.810867, acc 0.734375')
(5, '2017-01-10T15:39:48.535391: step 161, loss 0.730033, acc 0.78125')
(5, '2017-01-10T15:39:50.067278: step 162, loss 0.826196, acc 0.671875')
(5, '2017-01-10T15:39:51.500114: step 163, loss 0.693535, acc 0.75')
(5, '2017-01-10T15:39:52.849552: step 164, loss 1.46074, acc 0.515625')
(5, '2017-01-10T15:39:54.203728: step 165, loss 1.12475, acc 0.6875')
(5, '2017-01-10T15:39:55.582925: step 166, loss 0.910155, acc 0.6875')
(5, '2017-01-10T15:39:56.946905: step 167, loss 1.29631, acc 0.65625')
(5, '2017-01-10T15:39:58.294763: step 168, loss 0.814952, acc 0.765625')
(5, '2017-01-10T15:39:59.628518: step 169, loss 0.688382, acc 0.75')
(5, '2017-01-10T15:40:00.978600: step 170, loss 0.765373, acc 0.765625')
(5, '2017-01-10T15:40:02.315194: step 171, loss 0.840404, acc 0.78125')
(5, '2017-01-10T15:40:03.673114: step 172, loss 0.806487, acc 0.71875')
(5, '2017-01-10T15:40:05.029204: step 173, loss 0.387421, acc 0.859375')
(5, '2017-01-10T15:40:06.392200: step 174, loss 1.03752, acc 0.734375')
(5, '2017-01-10T15:40:07.720889: step 175, loss 0.81279, acc 0.796875')
(5, '2017-01-10T15:40:09.192421: step 176, loss 0.72308, acc 0.8125')
(5, '2017-01-10T15:40:10.673961: step 177, loss 0.577784, acc 0.765625')
(5, '2017-01-10T15:40:12.109002: step 178, loss 0.560363, acc 0.78125')
(5, '2017-01-10T15:40:13.449488: step 179, loss 0.855101, acc 0.71875')
(5, '2017-01-10T15:40:14.842612: step 180, loss 0.740603, acc 0.78125')
(5, '2017-01-10T15:40:16.323450: step 181, loss 1.51589, acc 0.671875')
(5, '2017-01-10T15:40:17.681669: step 182, loss 0.477151, acc 0.75')
(5, '2017-01-10T15:40:19.037674: step 183, loss 0.959892, acc 0.703125')
(5, '2017-01-10T15:40:20.385243: step 184, loss 0.583814, acc 0.78125')
(5, '2017-01-10T15:40:22.009244: step 185, loss 0.754726, acc 0.765625')
(5, '2017-01-10T15:40:23.358224: step 186, loss 0.939825, acc 0.71875')
(5, '2017-01-10T15:40:24.701537: step 187, loss 0.824557, acc 0.734375')
(5, '2017-01-10T15:40:26.025439: step 188, loss 0.801365, acc 0.734375')
(5, '2017-01-10T15:40:27.367920: step 189, loss 0.698946, acc 0.734375')
(5, '2017-01-10T15:40:28.693851: step 190, loss 0.329229, acc 0.90625')
(5, '2017-01-10T15:40:30.017081: step 191, loss 0.867623, acc 0.71875')
(5, '2017-01-10T15:40:31.335684: step 192, loss 0.531394, acc 0.78125')
(5, '2017-01-10T15:40:32.663412: step 193, loss 0.783937, acc 0.796875')
(5, '2017-01-10T15:40:33.991630: step 194, loss 0.633076, acc 0.75')
(5, '2017-01-10T15:40:35.287892: step 195, loss 0.716426, acc 0.765625')
(5, '2017-01-10T15:40:36.625344: step 196, loss 0.716168, acc 0.765625')
(5, '2017-01-10T15:40:38.089488: step 197, loss 0.78189, acc 0.765625')
(5, '2017-01-10T15:40:39.508965: step 198, loss 0.608028, acc 0.796875')
(5, '2017-01-10T15:40:40.907359: step 199, loss 0.699851, acc 0.765625')
(5, '2017-01-10T15:40:42.245144: step 200, loss 0.719691, acc 0.78125')

Evaluation:
(5, '2017-01-10T15:40:45.311258: step 200, loss 0.579013, acc 0.7')

(5, '2017-01-10T15:40:46.805748: step 201, loss 0.707425, acc 0.765625')
(5, '2017-01-10T15:40:48.180761: step 202, loss 0.755267, acc 0.734375')
(5, '2017-01-10T15:40:49.559350: step 203, loss 0.950321, acc 0.734375')
(5, '2017-01-10T15:40:50.928668: step 204, loss 0.854444, acc 0.765625')
(5, '2017-01-10T15:40:52.258431: step 205, loss 0.430462, acc 0.796875')
(5, '2017-01-10T15:40:53.585363: step 206, loss 0.499803, acc 0.8125')
(5, '2017-01-10T15:40:54.911823: step 207, loss 0.475411, acc 0.84375')
(5, '2017-01-10T15:40:56.234162: step 208, loss 0.510352, acc 0.8125')
(5, '2017-01-10T15:40:57.591301: step 209, loss 0.524491, acc 0.734375')
(5, '2017-01-10T15:40:58.910779: step 210, loss 0.749902, acc 0.71875')
(5, '2017-01-10T15:41:00.240473: step 211, loss 0.696109, acc 0.703125')
(5, '2017-01-10T15:41:01.554307: step 212, loss 0.627115, acc 0.796875')
(5, '2017-01-10T15:41:02.884758: step 213, loss 0.427369, acc 0.84375')
(5, '2017-01-10T15:41:04.215889: step 214, loss 0.89981, acc 0.75')
(5, '2017-01-10T15:41:05.544350: step 215, loss 0.626177, acc 0.734375')
(5, '2017-01-10T15:41:06.898470: step 216, loss 0.799897, acc 0.71875')
(5, '2017-01-10T15:41:08.246500: step 217, loss 0.541066, acc 0.75')
(5, '2017-01-10T15:41:09.599820: step 218, loss 0.516914, acc 0.8125')
(5, '2017-01-10T15:41:10.935206: step 219, loss 0.44019, acc 0.828125')
(5, '2017-01-10T15:41:12.310488: step 220, loss 0.225348, acc 0.890625')
(5, '2017-01-10T15:41:13.767770: step 221, loss 0.807083, acc 0.734375')
(5, '2017-01-10T15:41:15.148775: step 222, loss 0.546706, acc 0.796875')
(5, '2017-01-10T15:41:16.509032: step 223, loss 0.641511, acc 0.734375')
(5, '2017-01-10T15:41:17.845824: step 224, loss 0.948541, acc 0.6875')
(5, '2017-01-10T15:41:19.229143: step 225, loss 0.863237, acc 0.71875')
(5, '2017-01-10T15:41:20.825859: step 226, loss 0.38175, acc 0.84375')
(5, '2017-01-10T15:41:22.184599: step 227, loss 0.833349, acc 0.703125')
(5, '2017-01-10T15:41:23.501035: step 228, loss 0.749457, acc 0.734375')
(5, '2017-01-10T15:41:24.841103: step 229, loss 0.618302, acc 0.8125')
(5, '2017-01-10T15:41:26.467493: step 230, loss 0.902988, acc 0.6875')
(5, '2017-01-10T15:41:27.832937: step 231, loss 0.689355, acc 0.765625')
(5, '2017-01-10T15:41:29.170174: step 232, loss 0.689787, acc 0.75')
(5, '2017-01-10T15:41:30.499233: step 233, loss 0.245238, acc 0.875')
(5, '2017-01-10T15:41:31.830355: step 234, loss 0.798632, acc 0.75')
(5, '2017-01-10T15:41:33.146729: step 235, loss 0.721043, acc 0.796875')
(5, '2017-01-10T15:41:34.477447: step 236, loss 0.430682, acc 0.828125')
(5, '2017-01-10T15:41:35.794360: step 237, loss 0.460049, acc 0.8125')
(5, '2017-01-10T15:41:37.164114: step 238, loss 0.52516, acc 0.765625')
(5, '2017-01-10T15:41:38.494987: step 239, loss 0.433528, acc 0.828125')
(5, '2017-01-10T15:41:39.793903: step 240, loss 0.342919, acc 0.84375')
(5, '2017-01-10T15:41:41.128825: step 241, loss 0.784671, acc 0.796875')
(5, '2017-01-10T15:41:42.492292: step 242, loss 0.622328, acc 0.828125')
(5, '2017-01-10T15:41:43.867413: step 243, loss 0.573772, acc 0.78125')
(5, '2017-01-10T15:41:45.269875: step 244, loss 0.618545, acc 0.734375')
(5, '2017-01-10T15:41:46.639199: step 245, loss 0.628783, acc 0.78125')
(5, '2017-01-10T15:41:47.979753: step 246, loss 0.535561, acc 0.78125')
(5, '2017-01-10T15:41:49.371503: step 247, loss 0.470961, acc 0.828125')
(5, '2017-01-10T15:41:50.702386: step 248, loss 0.529811, acc 0.8125')
(5, '2017-01-10T15:41:51.998180: step 249, loss 0.790018, acc 0.765625')
(5, '2017-01-10T15:41:53.341081: step 250, loss 0.609629, acc 0.78125')
(5, '2017-01-10T15:41:54.708807: step 251, loss 0.501053, acc 0.8125')
(5, '2017-01-10T15:41:56.061335: step 252, loss 0.443008, acc 0.828125')
(5, '2017-01-10T15:41:57.401997: step 253, loss 0.451758, acc 0.8125')
(5, '2017-01-10T15:41:58.769861: step 254, loss 0.61857, acc 0.734375')
(5, '2017-01-10T15:42:00.093266: step 255, loss 0.527333, acc 0.828125')
(5, '2017-01-10T15:42:01.429398: step 256, loss 0.523398, acc 0.828125')
(5, '2017-01-10T15:42:02.763839: step 257, loss 0.471441, acc 0.828125')
(5, '2017-01-10T15:42:04.129088: step 258, loss 0.751235, acc 0.765625')
(5, '2017-01-10T15:42:05.455635: step 259, loss 0.484661, acc 0.890625')
(5, '2017-01-10T15:42:06.793830: step 260, loss 0.494523, acc 0.828125')
(5, '2017-01-10T15:42:08.172452: step 261, loss 0.271637, acc 0.859375')
(5, '2017-01-10T15:42:09.545958: step 262, loss 0.223832, acc 0.890625')
(5, '2017-01-10T15:42:10.910317: step 263, loss 0.454783, acc 0.84375')
(5, '2017-01-10T15:42:12.249496: step 264, loss 0.482091, acc 0.828125')
(5, '2017-01-10T15:42:13.600924: step 265, loss 0.487811, acc 0.84375')
(5, '2017-01-10T15:42:14.930653: step 266, loss 0.570623, acc 0.8125')
(5, '2017-01-10T15:42:16.252795: step 267, loss 0.543139, acc 0.796875')
(5, '2017-01-10T15:42:17.605295: step 268, loss 0.324634, acc 0.875')
(5, '2017-01-10T15:42:18.970171: step 269, loss 0.604917, acc 0.78125')
(5, '2017-01-10T15:42:20.324693: step 270, loss 0.365677, acc 0.859375')
(5, '2017-01-10T15:42:21.683077: step 271, loss 0.594478, acc 0.859375')
(5, '2017-01-10T15:42:23.008082: step 272, loss 0.403183, acc 0.859375')
(5, '2017-01-10T15:42:24.328849: step 273, loss 0.378388, acc 0.859375')
(5, '2017-01-10T15:42:25.838003: step 274, loss 0.635018, acc 0.765625')
(5, '2017-01-10T15:42:27.192109: step 275, loss 0.453499, acc 0.828125')
(5, '2017-01-10T15:42:28.523573: step 276, loss 0.461506, acc 0.78125')
(5, '2017-01-10T15:42:29.836206: step 277, loss 0.288743, acc 0.875')
(5, '2017-01-10T15:42:31.189677: step 278, loss 0.4892, acc 0.84375')
(5, '2017-01-10T15:42:32.556761: step 279, loss 0.363275, acc 0.921875')
(5, '2017-01-10T15:42:33.902437: step 280, loss 0.306542, acc 0.890625')
(5, '2017-01-10T15:42:35.235957: step 281, loss 0.478967, acc 0.828125')
(5, '2017-01-10T15:42:36.597347: step 282, loss 0.337189, acc 0.890625')
(5, '2017-01-10T15:42:37.931008: step 283, loss 0.516103, acc 0.78125')
(5, '2017-01-10T15:42:39.277408: step 284, loss 0.240654, acc 0.921875')
(5, '2017-01-10T15:42:40.655285: step 285, loss 0.566673, acc 0.765625')
(5, '2017-01-10T15:42:41.975845: step 286, loss 0.475483, acc 0.828125')
(5, '2017-01-10T15:42:43.321131: step 287, loss 0.526147, acc 0.78125')
(5, '2017-01-10T15:42:44.664985: step 288, loss 0.445383, acc 0.796875')
(5, '2017-01-10T15:42:46.008380: step 289, loss 0.484126, acc 0.8125')
(5, '2017-01-10T15:42:47.346426: step 290, loss 0.443844, acc 0.828125')
(5, '2017-01-10T15:42:48.683735: step 291, loss 0.57441, acc 0.75')
(5, '2017-01-10T15:42:50.007377: step 292, loss 0.466828, acc 0.8125')
(5, '2017-01-10T15:42:51.308239: step 293, loss 0.527507, acc 0.828125')
(5, '2017-01-10T15:42:52.679177: step 294, loss 0.45979, acc 0.875')
(5, '2017-01-10T15:42:54.018318: step 295, loss 0.462555, acc 0.84375')
(5, '2017-01-10T15:42:55.345480: step 296, loss 0.341342, acc 0.875')
(5, '2017-01-10T15:42:56.636749: step 297, loss 0.65028, acc 0.8125')
(5, '2017-01-10T15:42:57.956988: step 298, loss 0.834196, acc 0.71875')
(5, '2017-01-10T15:42:59.310448: step 299, loss 0.446082, acc 0.84375')
(5, '2017-01-10T15:43:00.635659: step 300, loss 0.387003, acc 0.828125')

Evaluation:
(5, '2017-01-10T15:43:03.693179: step 300, loss 0.5773, acc 0.6825')

(5, '2017-01-10T15:43:04.990028: step 301, loss 0.406344, acc 0.828125')
(5, '2017-01-10T15:43:06.306769: step 302, loss 0.345301, acc 0.828125')
(5, '2017-01-10T15:43:07.625736: step 303, loss 0.618778, acc 0.765625')
(5, '2017-01-10T15:43:08.959629: step 304, loss 0.610232, acc 0.78125')
(5, '2017-01-10T15:43:10.405428: step 305, loss 0.367847, acc 0.859375')
(5, '2017-01-10T15:43:11.780545: step 306, loss 0.474272, acc 0.8125')
(5, '2017-01-10T15:43:13.187824: step 307, loss 0.289888, acc 0.859375')
(5, '2017-01-10T15:43:14.540203: step 308, loss 0.505716, acc 0.796875')
(5, '2017-01-10T15:43:15.943694: step 309, loss 0.357616, acc 0.8125')
(5, '2017-01-10T15:43:17.475105: step 310, loss 0.187358, acc 0.890625')
(5, '2017-01-10T15:43:19.059159: step 311, loss 0.338484, acc 0.859375')
(5, '2017-01-10T15:43:20.636452: step 312, loss 0.467144, acc 0.875')
(5, '2017-01-10T15:43:22.211486: step 313, loss 0.359221, acc 0.890625')
(5, '2017-01-10T15:43:23.788351: step 314, loss 0.364263, acc 0.84375')
(5, '2017-01-10T15:43:25.552962: step 315, loss 0.414657, acc 0.828125')
(5, '2017-01-10T15:43:27.094475: step 316, loss 0.432653, acc 0.828125')
(5, '2017-01-10T15:43:28.706867: step 317, loss 0.57752, acc 0.78125')
(5, '2017-01-10T15:43:30.302086: step 318, loss 0.675233, acc 0.796875')
(5, '2017-01-10T15:43:31.866929: step 319, loss 0.459428, acc 0.796875')
(5, '2017-01-10T15:43:33.468288: step 320, loss 0.422362, acc 0.859375')
(5, '2017-01-10T15:43:35.094178: step 321, loss 0.452887, acc 0.828125')
(5, '2017-01-10T15:43:36.655338: step 322, loss 0.280943, acc 0.875')
(5, '2017-01-10T15:43:38.240912: step 323, loss 0.495021, acc 0.84375')
(5, '2017-01-10T15:43:39.814965: step 324, loss 0.324164, acc 0.90625')
(5, '2017-01-10T15:43:41.340850: step 325, loss 0.360083, acc 0.8125')
(5, '2017-01-10T15:43:42.833524: step 326, loss 0.319936, acc 0.84375')
(5, '2017-01-10T15:43:44.373025: step 327, loss 0.324106, acc 0.875')
(5, '2017-01-10T15:43:45.895843: step 328, loss 0.330609, acc 0.859375')
(5, '2017-01-10T15:43:47.448631: step 329, loss 0.210717, acc 0.921875')
(5, '2017-01-10T15:43:48.922551: step 330, loss 0.546633, acc 0.796875')
(5, '2017-01-10T15:43:50.670194: step 331, loss 0.285024, acc 0.890625')
(5, '2017-01-10T15:43:52.492420: step 332, loss 0.180755, acc 0.9375')
(5, '2017-01-10T15:43:54.198028: step 333, loss 0.517825, acc 0.859375')
(5, '2017-01-10T15:43:56.007136: step 334, loss 0.402104, acc 0.78125')
(5, '2017-01-10T15:43:57.812686: step 335, loss 0.507373, acc 0.78125')
(5, '2017-01-10T15:43:59.538368: step 336, loss 0.283491, acc 0.890625')
(5, '2017-01-10T15:44:01.270689: step 337, loss 0.381116, acc 0.84375')
(5, '2017-01-10T15:44:03.062891: step 338, loss 0.295188, acc 0.875')
(5, '2017-01-10T15:44:04.791751: step 339, loss 0.397982, acc 0.84375')
(5, '2017-01-10T15:44:06.529216: step 340, loss 0.70575, acc 0.75')
(5, '2017-01-10T15:44:08.351943: step 341, loss 0.643709, acc 0.75')
(5, '2017-01-10T15:44:10.133488: step 342, loss 0.308848, acc 0.859375')
(5, '2017-01-10T15:44:11.881702: step 343, loss 0.320001, acc 0.859375')
(5, '2017-01-10T15:44:13.558744: step 344, loss 0.25054, acc 0.9375')
(5, '2017-01-10T15:44:15.154791: step 345, loss 0.393298, acc 0.796875')
(5, '2017-01-10T15:44:16.751064: step 346, loss 0.258902, acc 0.875')
(5, '2017-01-10T15:44:18.434928: step 347, loss 0.579584, acc 0.78125')
(5, '2017-01-10T15:44:20.049078: step 348, loss 0.459454, acc 0.8125')
(5, '2017-01-10T15:44:21.545831: step 349, loss 0.547667, acc 0.78125')
(5, '2017-01-10T15:44:23.048202: step 350, loss 0.507198, acc 0.78125')
(5, '2017-01-10T15:44:24.681134: step 351, loss 0.34217, acc 0.84375')
(5, '2017-01-10T15:44:26.367184: step 352, loss 0.310973, acc 0.84375')
(5, '2017-01-10T15:44:27.836942: step 353, loss 0.352125, acc 0.828125')
(5, '2017-01-10T15:44:29.322978: step 354, loss 0.339385, acc 0.796875')
(5, '2017-01-10T15:44:30.828575: step 355, loss 0.222531, acc 0.890625')
(5, '2017-01-10T15:44:32.418793: step 356, loss 0.723724, acc 0.8125')
(5, '2017-01-10T15:44:33.931103: step 357, loss 0.44511, acc 0.828125')
(5, '2017-01-10T15:44:35.432839: step 358, loss 0.425578, acc 0.828125')
(5, '2017-01-10T15:44:36.893632: step 359, loss 0.60222, acc 0.796875')
(5, '2017-01-10T15:44:38.398143: step 360, loss 0.33862, acc 0.875')
(5, '2017-01-10T15:44:39.876850: step 361, loss 0.34157, acc 0.875')
(5, '2017-01-10T15:44:41.370649: step 362, loss 0.281632, acc 0.90625')
(5, '2017-01-10T15:44:42.855451: step 363, loss 0.403998, acc 0.84375')
(5, '2017-01-10T15:44:44.310535: step 364, loss 0.619287, acc 0.84375')
(5, '2017-01-10T15:44:45.852254: step 365, loss 0.358927, acc 0.828125')
(5, '2017-01-10T15:44:47.329848: step 366, loss 0.327447, acc 0.875')
(5, '2017-01-10T15:44:48.876075: step 367, loss 0.45679, acc 0.828125')
(5, '2017-01-10T15:44:50.330799: step 368, loss 0.406938, acc 0.84375')
(5, '2017-01-10T15:44:51.819011: step 369, loss 0.450466, acc 0.796875')
(5, '2017-01-10T15:44:53.311917: step 370, loss 0.616555, acc 0.78125')
(5, '2017-01-10T15:44:54.752946: step 371, loss 0.593595, acc 0.8125')
(5, '2017-01-10T15:44:56.193379: step 372, loss 0.389064, acc 0.875')
(5, '2017-01-10T15:44:57.662719: step 373, loss 0.392242, acc 0.828125')
(5, '2017-01-10T15:44:59.187194: step 374, loss 0.433417, acc 0.8125')
(5, '2017-01-10T15:45:00.641723: step 375, loss 0.166825, acc 0.921875')
(5, '2017-01-10T15:45:02.142348: step 376, loss 0.295798, acc 0.875')
(5, '2017-01-10T15:45:03.611299: step 377, loss 0.265478, acc 0.890625')
(5, '2017-01-10T15:45:05.131373: step 378, loss 0.267303, acc 0.875')
(5, '2017-01-10T15:45:06.763514: step 379, loss 0.329269, acc 0.875')
(5, '2017-01-10T15:45:08.312539: step 380, loss 0.336226, acc 0.859375')
(5, '2017-01-10T15:45:09.921224: step 381, loss 0.295285, acc 0.875')
(5, '2017-01-10T15:45:11.439496: step 382, loss 0.391986, acc 0.890625')
(5, '2017-01-10T15:45:12.913923: step 383, loss 0.453854, acc 0.796875')
(5, '2017-01-10T15:45:14.403032: step 384, loss 0.350312, acc 0.859375')
(5, '2017-01-10T15:45:15.838888: step 385, loss 0.305967, acc 0.921875')
(5, '2017-01-10T15:45:17.335535: step 386, loss 0.28279, acc 0.890625')
(5, '2017-01-10T15:45:18.859198: step 387, loss 0.313295, acc 0.859375')
(5, '2017-01-10T15:45:20.472424: step 388, loss 0.218281, acc 0.90625')
(5, '2017-01-10T15:45:22.042732: step 389, loss 0.28295, acc 0.921875')
(5, '2017-01-10T15:45:23.705142: step 390, loss 0.189048, acc 0.9375')
(5, '2017-01-10T15:45:25.596402: step 391, loss 0.415168, acc 0.875')
(5, '2017-01-10T15:45:27.163779: step 392, loss 0.310031, acc 0.84375')
(5, '2017-01-10T15:45:28.675967: step 393, loss 0.200631, acc 0.953125')
(5, '2017-01-10T15:45:30.198348: step 394, loss 0.452524, acc 0.828125')
(5, '2017-01-10T15:45:31.701314: step 395, loss 0.315002, acc 0.859375')
(5, '2017-01-10T15:45:33.204743: step 396, loss 0.38138, acc 0.859375')
(5, '2017-01-10T15:45:34.741589: step 397, loss 0.271719, acc 0.875')
(5, '2017-01-10T15:45:36.226614: step 398, loss 0.292509, acc 0.90625')
(5, '2017-01-10T15:45:37.775725: step 399, loss 0.619269, acc 0.765625')
(5, '2017-01-10T15:45:39.312479: step 400, loss 0.297675, acc 0.84375')

Evaluation:
(5, '2017-01-10T15:45:42.518661: step 400, loss 0.487096, acc 0.7525')

(5, '2017-01-10T15:45:44.016993: step 401, loss 0.25463, acc 0.890625')
(5, '2017-01-10T15:45:45.550669: step 402, loss 0.280191, acc 0.890625')
(5, '2017-01-10T15:45:47.070070: step 403, loss 0.250545, acc 0.859375')
(5, '2017-01-10T15:45:48.624172: step 404, loss 0.126801, acc 0.953125')
(5, '2017-01-10T15:45:50.217181: step 405, loss 0.367165, acc 0.875')
(5, '2017-01-10T15:45:51.774971: step 406, loss 0.192869, acc 0.9375')
(5, '2017-01-10T15:45:53.359311: step 407, loss 0.2563, acc 0.921875')
(5, '2017-01-10T15:45:54.803243: step 408, loss 0.15123, acc 0.921875')
(5, '2017-01-10T15:45:56.258359: step 409, loss 0.315262, acc 0.890625')
(5, '2017-01-10T15:45:57.740427: step 410, loss 0.333797, acc 0.875')
(5, '2017-01-10T15:45:59.235379: step 411, loss 0.33146, acc 0.890625')
(5, '2017-01-10T15:46:00.704942: step 412, loss 0.238937, acc 0.890625')
(5, '2017-01-10T15:46:02.222958: step 413, loss 0.205874, acc 0.9375')
(5, '2017-01-10T15:46:03.704419: step 414, loss 0.262615, acc 0.859375')
(5, '2017-01-10T15:46:05.246771: step 415, loss 0.221304, acc 0.890625')
(5, '2017-01-10T15:46:06.816471: step 416, loss 0.210771, acc 0.90625')
(5, '2017-01-10T15:46:08.383731: step 417, loss 0.38944, acc 0.78125')
(5, '2017-01-10T15:46:09.937053: step 418, loss 0.198417, acc 0.90625')
(5, '2017-01-10T15:46:11.575755: step 419, loss 0.360915, acc 0.875')
(5, '2017-01-10T15:46:13.206946: step 420, loss 0.422494, acc 0.8125')
(5, '2017-01-10T15:46:14.831035: step 421, loss 0.25605, acc 0.90625')
(5, '2017-01-10T15:46:16.344461: step 422, loss 0.238376, acc 0.90625')
(5, '2017-01-10T15:46:17.903115: step 423, loss 0.445035, acc 0.8125')
(5, '2017-01-10T15:46:19.547216: step 424, loss 0.169901, acc 0.921875')
(5, '2017-01-10T15:46:21.076419: step 425, loss 0.318447, acc 0.859375')
(5, '2017-01-10T15:46:22.629550: step 426, loss 0.172653, acc 0.9375')
(5, '2017-01-10T15:46:24.261721: step 427, loss 0.394092, acc 0.828125')
(5, '2017-01-10T15:46:26.010421: step 428, loss 0.305314, acc 0.875')
(5, '2017-01-10T15:46:27.658995: step 429, loss 0.31287, acc 0.921875')
(5, '2017-01-10T15:46:29.310953: step 430, loss 0.230913, acc 0.875')
(5, '2017-01-10T15:46:30.881006: step 431, loss 0.123436, acc 0.953125')
(5, '2017-01-10T15:46:32.482565: step 432, loss 0.27414, acc 0.875')
(5, '2017-01-10T15:46:33.997589: step 433, loss 0.243597, acc 0.90625')
(5, '2017-01-10T15:46:35.343846: step 434, loss 0.21111, acc 0.9375')
(5, '2017-01-10T15:46:36.667552: step 435, loss 0.209323, acc 0.921875')
(5, '2017-01-10T15:46:37.999866: step 436, loss 0.313351, acc 0.890625')
(5, '2017-01-10T15:46:39.338104: step 437, loss 0.211452, acc 0.921875')
(5, '2017-01-10T15:46:40.664567: step 438, loss 0.285128, acc 0.90625')
(5, '2017-01-10T15:46:42.189831: step 439, loss 0.258959, acc 0.890625')
(5, '2017-01-10T15:46:43.872406: step 440, loss 0.214588, acc 0.875')
(5, '2017-01-10T15:46:45.360053: step 441, loss 0.299658, acc 0.875')
(5, '2017-01-10T15:46:46.795153: step 442, loss 0.230587, acc 0.875')
(5, '2017-01-10T15:46:48.158319: step 443, loss 0.425291, acc 0.828125')
(5, '2017-01-10T15:46:49.607662: step 444, loss 0.304379, acc 0.875')
(5, '2017-01-10T15:46:51.181166: step 445, loss 0.239789, acc 0.890625')
(5, '2017-01-10T15:46:52.792419: step 446, loss 0.287359, acc 0.859375')
(5, '2017-01-10T15:46:54.370456: step 447, loss 0.233388, acc 0.875')
(5, '2017-01-10T15:46:55.970108: step 448, loss 0.315888, acc 0.859375')
(5, '2017-01-10T15:46:57.600246: step 449, loss 0.228144, acc 0.875')
(5, '2017-01-10T15:46:59.149523: step 450, loss 0.288644, acc 0.84375')
(5, '2017-01-10T15:47:00.728697: step 451, loss 0.326494, acc 0.828125')
(5, '2017-01-10T15:47:02.303503: step 452, loss 0.2355, acc 0.90625')
(5, '2017-01-10T15:47:03.909558: step 453, loss 0.370755, acc 0.875')
(5, '2017-01-10T15:47:05.523057: step 454, loss 0.182494, acc 0.921875')
(5, '2017-01-10T15:47:07.065417: step 455, loss 0.28545, acc 0.890625')
(5, '2017-01-10T15:47:08.650908: step 456, loss 0.273261, acc 0.875')
(5, '2017-01-10T15:47:10.255868: step 457, loss 0.3462, acc 0.890625')
(5, '2017-01-10T15:47:11.824773: step 458, loss 0.254905, acc 0.890625')
(5, '2017-01-10T15:47:13.310025: step 459, loss 0.26104, acc 0.890625')
(5, '2017-01-10T15:47:14.754188: step 460, loss 0.292493, acc 0.875')
(5, '2017-01-10T15:47:16.227077: step 461, loss 0.218672, acc 0.921875')
(5, '2017-01-10T15:47:17.744304: step 462, loss 0.247686, acc 0.890625')
(5, '2017-01-10T15:47:19.217410: step 463, loss 0.189587, acc 0.921875')
(5, '2017-01-10T15:47:20.787097: step 464, loss 0.279086, acc 0.859375')
(5, '2017-01-10T15:47:22.292730: step 465, loss 0.196731, acc 0.90625')
(5, '2017-01-10T15:47:23.699595: step 466, loss 0.371939, acc 0.890625')
(5, '2017-01-10T15:47:25.361394: step 467, loss 0.138721, acc 0.921875')
(5, '2017-01-10T15:47:26.838253: step 468, loss 0.172553, acc 0.9375')
(5, '2017-01-10T15:47:28.308197: step 469, loss 0.316335, acc 0.890625')
(5, '2017-01-10T15:47:29.753904: step 470, loss 0.26155, acc 0.890625')
(5, '2017-01-10T15:47:31.234985: step 471, loss 0.248162, acc 0.890625')
(5, '2017-01-10T15:47:32.757756: step 472, loss 0.371079, acc 0.828125')
(5, '2017-01-10T15:47:34.190123: step 473, loss 0.209459, acc 0.9375')
(5, '2017-01-10T15:47:35.654505: step 474, loss 0.219859, acc 0.921875')
(5, '2017-01-10T15:47:37.129772: step 475, loss 0.275287, acc 0.875')
(5, '2017-01-10T15:47:38.609348: step 476, loss 0.320823, acc 0.875')
(5, '2017-01-10T15:47:40.081670: step 477, loss 0.3165, acc 0.859375')
(5, '2017-01-10T15:47:41.566252: step 478, loss 0.242659, acc 0.921875')
(5, '2017-01-10T15:47:43.059737: step 479, loss 0.420215, acc 0.828125')
(5, '2017-01-10T15:47:44.544610: step 480, loss 0.173754, acc 0.90625')
(5, '2017-01-10T15:47:46.041719: step 481, loss 0.124673, acc 0.9375')
(5, '2017-01-10T15:47:47.507315: step 482, loss 0.31092, acc 0.84375')
(5, '2017-01-10T15:47:49.021849: step 483, loss 0.14196, acc 0.9375')
(5, '2017-01-10T15:47:50.498152: step 484, loss 0.303134, acc 0.859375')
(5, '2017-01-10T15:47:52.074249: step 485, loss 0.262918, acc 0.90625')
(5, '2017-01-10T15:47:53.556076: step 486, loss 0.217314, acc 0.953125')
(5, '2017-01-10T15:47:54.991427: step 487, loss 0.306958, acc 0.875')
(5, '2017-01-10T15:47:56.477674: step 488, loss 0.125185, acc 0.953125')
(5, '2017-01-10T15:47:57.959156: step 489, loss 0.227099, acc 0.953125')
(5, '2017-01-10T15:47:59.610876: step 490, loss 0.197114, acc 0.921875')
(5, '2017-01-10T15:48:01.136291: step 491, loss 0.200537, acc 0.921875')
(5, '2017-01-10T15:48:02.666619: step 492, loss 0.182767, acc 0.9375')
(5, '2017-01-10T15:48:04.223004: step 493, loss 0.385692, acc 0.875')
(5, '2017-01-10T15:48:05.817465: step 494, loss 0.219086, acc 0.921875')
(5, '2017-01-10T15:48:07.299790: step 495, loss 0.27668, acc 0.890625')
(5, '2017-01-10T15:48:08.792683: step 496, loss 0.273294, acc 0.921875')
(5, '2017-01-10T15:48:10.295340: step 497, loss 0.326577, acc 0.859375')
(5, '2017-01-10T15:48:11.777794: step 498, loss 0.113305, acc 0.953125')
(5, '2017-01-10T15:48:13.332744: step 499, loss 0.232009, acc 0.875')
(5, '2017-01-10T15:48:14.851377: step 500, loss 0.151121, acc 0.921875')

Evaluation:
(5, '2017-01-10T15:48:17.935399: step 500, loss 0.508614, acc 0.7525')

(5, '2017-01-10T15:48:21.641741: step 500, loss 0.508614, acc 0.7525')
After cross validation 
('Accuracy=', 0.73549998)
